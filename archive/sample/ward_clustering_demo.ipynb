{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from joblib import Memory\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import tempfile\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.cluster import ward_tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "from radiomics import imageoperations\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first QSM and segmentation\n",
    "seg1 = nib.load('D:/Elements Drive 2020/datasets/PD/12_28_2022/_QSM/034/seg.nii.gz')\n",
    "qsm1 = nib.load('D:/Elements Drive 2020/datasets/PD/12_28_2022/_QSM/034/QSM.nii')\n",
    "voxel_size = qsm1.header['pixdim'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second QSM and segmentation\n",
    "seg2 = nib.load('D:/Elements Drive 2020/datasets/PD/12_28_2022/_QSM/035/seg.nii')\n",
    "qsm2 = nib.load('D:/Elements Drive 2020/datasets/PD/12_28_2022/_QSM/035/QSM.nii.gz')\n",
    "voxel_size = qsm2.header['pixdim'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seg = np.array([seg1.get_fdata(),seg2.get_fdata()])\n",
    "qsm = np.array([qsm1.get_fdata(),qsm2.get_fdata()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "segs = []\n",
    "qsms = []\n",
    "directory = 'D:/Elements Drive 2020/datasets/PD/12_28_2022/_QSM/'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory,filename)\n",
    "    try:\n",
    "        seg = nib.load(f+'/seg.nii')\n",
    "    except:\n",
    "        seg = nib.load(f+'/seg.nii.gz')\n",
    "    segs = segs.append(seg)\n",
    "    try:\n",
    "        qsm = nib.load(f+'/qsm.nii')\n",
    "    except:\n",
    "        qsm = nib.load(f+'/qsm.nii.gz')\n",
    "    qsms = qsms.append(qsm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = seg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature structure Phi from all ROIs and all cases\n",
    "\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.disableAllFeatures()\n",
    "extractor.enableFeatureClassByName('firstorder')\n",
    "Phi = []\n",
    "for i in range(n_cases):\n",
    "    seg_sitk = sitk.GetImageFromArray(seg[i])\n",
    "    seg_sitk.SetSpacing(voxel_size.tolist())\n",
    "    qsm_sitk = sitk.GetImageFromArray(qsm[i])\n",
    "    qsm_sitk.SetSpacing(voxel_size.tolist())\n",
    "    for j in range(1,int(np.max(seg))+1):\n",
    "        featureVector = extractor.execute(qsm_sitk,seg_sitk,label=j)\n",
    "        Phi.append(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = len(Phi)/n_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric feature values\n",
    "x_row = []\n",
    "loop_count = 0\n",
    "for i in range(n_cases):\n",
    "    for j in range(int(np.max(seg))):\n",
    "        featureVector = Phi[j]\n",
    "        loop_count = loop_count+1\n",
    "        for key, value in six.iteritems(featureVector):\n",
    "            if 'diagnostic' in key:\n",
    "                next\n",
    "            else:\n",
    "                x_row.append(value)\n",
    "\n",
    "\n",
    "X0 = np.array(x_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X0.reshape((n_cases,int(len(X0)/n_cases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAAsCAYAAABbjGLvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFMUlEQVR4nO3cW4hVVRzH8e/P0VFTulhhjlmZGkVaGln4VKGgD4n50IWsIKiklwqpjAqLECOo6PYQmCXUQ9FNkghDIogwLdOsDPIyhpdQUwQb79O/h7ONPXNu4zkn11x+H9gwa5211/qfmcOPfdaZfRQRmJnZ6dcvdQFmZn2VA9jMLBEHsJlZIg5gM7NEHMBmZok4gM3MEnEAm5kl4gA2q4GkXyXdmLoO69kcwH2cpG2SDkv6O3e0NGDOaY2q8XTrSv0RcWVEfF3j/GMkHZI0Itc3R9IuSaNqmdN6JgewAcyMiKG5Y1eqQiT1T7V2VzSivojYAiwHHsnmnAK8AcyKiO31zm89hwPYSpLUIuljSXsltUp6qNPjT0jaIumgpI2SZmf97wIXAcuzq+nHs/6QNDZ3/lJJC7Oft0maL2kD0Capf7X1S9S7TdJjkjZIapO0RNJwSV9kNa6UdE6l2svVX6a+/66Ssyva/ZKuyf3u9lbZongBmCtpPPAJMDcivq/+l7FeJSJ89OED2AZM69TXD1gLLACagUuBrcD03JhbgZZs7O1AGzCiwpwBjM21lwILc+PXA6OAwV1Zv8zz+A4YDowE9gA/ApOAQcBXwDPVai9Vf+f6yoy5H9gInAGsAF7swu/+y2ztBalfBz7SHL4CNoBlkg5kxzJgMnB+RDwXEcciYiuwGLjj5AkR8WFE7IqIfyLiA2ATcF0dNbwWEdsj4nBX1i/j9YjYHRE7gW+A1RGxLiKOAJ9SCONaa8/XVyQiFgObgdXACOCpSpNJ6ge0A/9QuBq2Pqhb77fZaXNLRKw82ZB0G9Ai6UBuTBOFUDs55h5gHnBJ1jUUOK+OGvJ7nxdXW7+M3bmfD5doD4Waa+/K3uxi4DPggYg4WmXsS8DZFMJ/DvB2F+a3XsYBbKVsB1ojYlypByVdTCFspgKrIqJd0npA2ZBS33F6iMLb85MuAHbk2vlzKq5fjy7U3rmWSn35eYcCrwBLgGclfRwR+8uMnQvMpnDVfVM2/p2I8HfD9jHegrBS1gAHsw+eBktqkjRe0uTs8SEUAmkvgKR7gfG583dT2LfNWw/cmc01A7ihjvXrUa32cvVX8yrwQ0TcB3wOvFlqUPbB3SLg5ojYA3xEYZ971imuZ72AA9iKREQ7cDMwEWgF/gLeAs7KHt9I4S30KgphNQH4NjfF88DT2Z7yo1nfw8BM4ACFt9zLal2/zudWrfZy9ZclaRYwA3gw65oHXCNpTqdxlwPvA3dHxC9ZPe3Ay8D8mp+U9Vjyux4zszR8BWxmlogD2MwsEQewmVkiDmAzs0QcwGZmiZzSjRjNGhiDGFJxzMgJbUV9O3+ufE5Pd3T04A7tga0l71atyWVXHSrq+33DGSVG9h7Hxwzq0B6w5UjD5taAAR3acfx4w+bujtS/qagvTrQ3boEhHV/7tDXutd8daWBzUV8cPVbxnGaa2cfuFRExo2i+U/k3tDM1LK7X1IpjFrWuKep7cnQ9XxHQ/W1+b1KH9ti71jVs7hW71hf1TW+Z2LD5u6M/l13RoT3ilt8aNnf/C0d2aJ/YsbNhc3dHTecOK+pr31fyBr2axJSrO7S16qeGzd0dNY0rvj+nfdPWquetjI/WRsS1nfu9BWFmlogD2MwsEQewmVkiDmAzs0QcwGZmiTiAzcwScQCbmSVySv8HLGkv8Mf/V46ZWa/zF0DdN2KYmVnjeAvCzCwRB7CZWSIOYDOzRBzAZmaJOIDNzBJxAJuZJeIANjNLxAFsZpaIA9jMLJF/ASrKFgk80HsCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize feature matrix X\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plt.style.use('dark_background')\n",
    "plt.imshow(X)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Feature matrix $X$');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = ward_tree(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([[3,8,32,4],\n",
    "\t[0,0,0,0],\n",
    "\t[0,10,33,4],\n",
    "\t[2,10,26,8],\n",
    "\t[0,0,0,0],\n",
    "\t[3,10,24,2],\n",
    "\t[0,0,0,0],\n",
    "\t[1,3,18,2],\n",
    "\t[2,13,30,6],\n",
    "\t[0,0,0,0],\n",
    "\t[0,0,0,0],\n",
    "\t[0,0,0,0],\n",
    "\t[0,0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.cluster._agglomerative.ward_tree...\n",
      "ward_tree(array([[0.],\n",
      "       ...,\n",
      "       [0.]]), connectivity=None, n_clusters=None, return_distance=False)\n",
      "________________________________________________________ward_tree - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.cluster._agglomerative.ward_tree...\n",
      "ward_tree(array([[0., 0.],\n",
      "       ...,\n",
      "       [0., 0.]]), connectivity=None, n_clusters=None, return_distance=False)\n",
      "________________________________________________________ward_tree - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:796: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  category=UserWarning,\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "c:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# u1 = np.expand_dims(np.array([0,1,24,1]).T,0)\n",
    "# u2 = np.expand_dims(np.array([0,3,21,3]).T,0)\n",
    "# u = np.vstack((u1,u2))\n",
    "cv = KFold(2)  # cross-validation generator for model selection\n",
    "cachedir = tempfile.mkdtemp()\n",
    "mem = Memory(location=cachedir, verbose=1)\n",
    "lasso = Lasso(alpha=0.1,fit_intercept=False,max_iter=10000,tol=0.1)\n",
    "ward = FeatureAgglomeration(n_clusters=10, memory=mem)\n",
    "clf = Pipeline([(\"ward\", ward), (\"LASSO\", lasso)])\n",
    "# Select the optimal number of parcels with grid search\n",
    "clf = GridSearchCV(clf, {\"ward__n_clusters\": [10, 20, 30]}, n_jobs=1, cv=cv)\n",
    "clf.fit(X,u)  # set the best parameters\n",
    "coef_ = clf.best_estimator_.steps[-1][1].coef_\n",
    "coef_ = clf.best_estimator_.steps[0][1].inverse_transform(coef_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
