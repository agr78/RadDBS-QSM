{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=6\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.neural_network as skn\n",
    "from celer import GroupLassoCV\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util_arch as util\n",
    "from scipy.spatial import cKDTree\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch import nn\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from adapt.feature_based import CORAL\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function ✓\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)\n",
    "# Combine CHH dataset ✓\n",
    "# Implement CV and test ✓\n",
    "# Print selected features ✓\n",
    "# Make magnitude templates\n",
    "# Sample weights ✓\n",
    "# Look at segmentations by error ✓ (Appears to have most difference in red nucleus, which includes surrounding (white?) matter for underperforming cases)\n",
    "# Extract features from current (1:6) eroded ROIs\n",
    "# Extract features from all ROIs\n",
    "# Plot segmentation variance against error for each case across all ROIs ✓\n",
    "# Why does excluding the subthalamic nucleus increase the correlation (r=0.5 -> r=0.6)?\n",
    "# Best performance with all ROIs: cvn=6, k=1800\n",
    "# Best performance with ROIs 0:4, excluding STN: cvn=6, k=1800\n",
    "# Should the pre-operative UPDRS be appended once or to each ROI? ✓\n",
    "# Plot histogram of features for successful and unsuccessful predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated arrays\n",
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n",
      "[[['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]\n",
      "\n",
      " [['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]\n",
      "\n",
      " [['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]\n",
      "\n",
      " ...\n",
      "\n",
      " [['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]\n",
      "\n",
      " [['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]\n",
      "\n",
      " [['Left red nucleus' 'Left red nucleus' 'Left red nucleus' ...\n",
      "   'Left red nucleus' 'Left red nucleus' 'Left red nucleus']\n",
      "  ['Right red nucleus' 'Right red nucleus' 'Right red nucleus' ...\n",
      "   'Right red nucleus' 'Right red nucleus' 'Right red nucleus']\n",
      "  ['Left substantia nigra' 'Left substantia nigra'\n",
      "   'Left substantia nigra' ... 'Left substantia nigra'\n",
      "   'Left substantia nigra' 'Left substantia nigra']\n",
      "  ['Right Substantia nigra' 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' ... 'Right Substantia nigra'\n",
      "   'Right Substantia nigra' 'Right Substantia nigra']]]\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,0:4,:]\n",
    "K_all_c = K_all[c_cases_idx,0:4,:]\n",
    "R_all_c = R_all[c_cases_idx,0:4,:]\n",
    "print(R_all_c)\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subsc = subs[s_cases_idx]\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp\n",
    "# Reshape keys and ROIs\n",
    "if all_rois == True:\n",
    "    K_all_cu = np.empty((K_all_c.shape[0],K_all_c.shape[1],K_all_c.shape[2]+1),dtype=object)\n",
    "    K_all_cu[:,:,:-1] = K_all_c\n",
    "    K_all_cu[:,:,-1] = 'pre_updrs'\n",
    "    K = K_all_cu.reshape((K_all_cu.shape[0],K_all_cu.shape[1]*K_all_cu.shape[2]))[0]\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "else:\n",
    "    K = K_all_c.reshape((K_all_c.shape[0],K_all_c.shape[1]*K_all_c.shape[2]))[0]\n",
    "    K = np.append(K,['pre_updrs'],0)\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Augment with CHH data\n",
    "# X0_gt = np.load('/home/ali/RadDBS-QSM/data/npy/old/X0_gt_chh_rois.npy')\n",
    "# df = pd.read_csv('/home/ali/RadDBS-QSM/data/xlxs/updrs_iii_chh.csv')\n",
    "# # Patient IDs\n",
    "# subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "# # Data\n",
    "# s_directory = open('/home/ali/RadDBS-QSM/data/roi/roi_list','r').read().splitlines()\n",
    "# # Load\n",
    "# with open('/home/ali/RadDBS-QSM/data/pickles/segs_chh', \"rb\") as fp:  \n",
    "#     segs = pickle.load(fp)\n",
    "#     n_cases = len(segs)\n",
    "# with open('/home/ali/RadDBS-QSM/data/pickles/qsms_chh', \"rb\") as fp:  \n",
    "#     qsms = pickle.load(fp)\n",
    "# with open('/home/ali/RadDBS-QSM/data/phi/chh/Phi_mcl_gt_roi_chh', \"rb\") as fp:  \n",
    "#         Phi_gt = pickle.load(fp)\n",
    "# L = int(len(X0_gt)/n_cases)\n",
    "# n_features = int(L/n_rois)\n",
    "# # Only extract ROI if it is present in all cases\n",
    "# seg_labels_all = segs[0]\n",
    "# case_number = np.zeros_like(np.asarray(s_directory))\n",
    "# for i in range(n_cases):\n",
    "#     case_number[i] = float(s_directory[i][-2:])\n",
    "# subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "# for i in range(n_cases):\n",
    "#     #try:\n",
    "#         print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "#     #except:\n",
    "#         print('Case',subject_id[i],'quarantined')\n",
    "# pre_updrs_iii_off =  np.asarray(df[df.columns[3]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])                                \n",
    "# pre_updrs_iii_on =  np.asarray(df[df.columns[4]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])\n",
    "# post_updrs_iii_off =  np.asarray(df[df.columns[6]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])\n",
    "\n",
    "# per_change = np.hstack((per_change,(np.asarray(pre_updrs_iii_off).astype(float)-np.asarray(post_updrs_iii_off).astype(float))/(np.asarray(pre_updrs_iii_off).astype(float))))\n",
    "# pre_updrs_off = np.hstack((pre_updrs_off, pre_updrs_iii_off))\n",
    "# X0_gt = X0_gt.reshape((n_cases,n_rois,n_features))[:,0:4,:]\n",
    "# X_all_c = np.vstack((X_all_c,X0_gt[:,:,:-1]))\n",
    "# lct_change = (np.asarray(pre_updrs_iii_off).astype(float)-(np.asarray(pre_updrs_iii_on)).astype(float))/(np.asarray(pre_updrs_iii_off).astype(float))\n",
    "# pre_imp = np.hstack((pre_imp,lct_change))\n",
    "# subject_id_corr=subject_id_corr+100\n",
    "# subsc = np.hstack((subsc,subject_id_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nii_dir = '/home/ali/RadDBS-QSM/data/nii'\n",
    "# qsms = []\n",
    "# segs = []\n",
    "# for j in np.arange(len(subsc)):\n",
    "#     if subsc[j] < 10:\n",
    "#         qsms.append(nii_dir+'/qsm/QSM_e10_imaginary_0'+str(int(subsc[j]))+'.nii.gz')\n",
    "#         segs.append(nii_dir+'/seg/labels_2iMag0'+str(int(subsc[j]))+'.nii.gz')\n",
    "#     else:\n",
    "#         qsms.append(nii_dir+'/qsm/QSM_e10_imaginary_'+str(int(subsc[j]))+'.nii.gz')\n",
    "#         segs.append(nii_dir+'/seg/labels_2iMag'+str(int(subsc[j]))+'.nii.gz')\n",
    "\n",
    "# V, M, subs_err = util.roi_var(qsms,segs,[1,2,3,4,5,6])\n",
    "# np.save('V.npy',V)\n",
    "# np.save('U.npy',M)\n",
    "# V = np.load('V.npy')\n",
    "# M = np.load('U.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'r2'\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_gls = np.zeros_like(per_change)\n",
    "gerror = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "err_var = np.zeros_like(per_change)\n",
    "alphas = np.logspace(-4,4,100)\n",
    "Ks = []\n",
    "Kstg = []\n",
    "w = []\n",
    "wg = []\n",
    "pcases = []\n",
    "pscores = []\n",
    "s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi = []\n",
    "# for j in np.arange(len(qsms)):\n",
    "#     data = nib.load(qsms[j]).get_fdata()\n",
    "#     if int(qsms[j][-9:-7]) == int(segs[j][-9:-7]):\n",
    "#         try:\n",
    "#             mask = nib.load(segs[j]).get_fdata()\n",
    "#             img = util.pad_to((data[:,:,~(mask==0).all((0,1))])[192:320,192:320,:],128,128,108)\n",
    "#             chi.append(img)\n",
    "#             print('Loading',qsms[j],'of shape',str(img.shape))\n",
    "#         except:\n",
    "#             print('Skipping',qsms[j])\n",
    "#             subsc = np.delete(subsc,j)\n",
    "#             per_change = np.delete(per_change,j)\n",
    "#             X_all_c = np.delete(X_all_c,j,axis=0)\n",
    "#             pre_updrs_off = np.delete(pre_updrs_off,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit transform...\n",
      "Previous covariance difference: 0.312461\n",
      "New covariance difference: 0.043434\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.42857143]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 1.43 with error 25.817079816\n",
      "Using nearest neighbor after estimating: 0.42857142857142855\n",
      "Lasso predicts 0.43 for case with 0.48 with reconstruction error 26.125350492 maximum error 14.748206205 and neighbor 0.43 and condition number 59060584331112.59\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.412861\n",
      "New covariance difference: 0.069163\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.87878788]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 10.82 with error 40.155004981\n",
      "Using nearest neighbor after estimating: 0.8787878787878788\n",
      "Lasso predicts 0.88 for case with 0.97 with reconstruction error 40.290203116 maximum error 14.665978569 and neighbor 0.88 and condition number 59957251004022.836\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.325105\n",
      "New covariance difference: 0.046726\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.1875]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -2.96 with error 33.03155856\n",
      "Using nearest neighbor after estimating: 0.1875\n",
      "Lasso predicts 0.19 for case with 0.75 with reconstruction error 32.475468816 maximum error 14.610306285 and neighbor 0.19 and condition number 59335357818837.11\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.474759\n",
      "New covariance difference: 0.077239\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.83928571]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 15.93 with error 26.033336754\n",
      "Using nearest neighbor after estimating: 0.8392857142857143\n",
      "Lasso predicts 0.84 for case with 0.66 with reconstruction error 25.930893145 maximum error 14.412996399 and neighbor 0.84 and condition number 59674204213263.63\n",
      "Fit transform...\n",
      "Previous covariance difference: 1117771.482216\n",
      "New covariance difference: 134940.000896\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.84615385]\n",
      "New neighbor [0.59259259]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -51.4 with error 45.439835004\n",
      "Using nearest neighbor after estimating: 0.8461538461538461\n",
      "Lasso predicts 0.85 for case with 0.74 with reconstruction error 45.693396258 maximum error 16.923446451 and neighbor 0.85 and condition number 3967502085898.752\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.293855\n",
      "New covariance difference: 0.032651\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.67241379]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -7.11 with error 26.662065241\n",
      "Using nearest neighbor after estimating: 0.6724137931034483\n",
      "Lasso predicts 0.67 for case with 0.15 with reconstruction error 26.726493553 maximum error 14.913010774 and neighbor 0.67 and condition number 58098948914144.18\n",
      "Fit transform...\n",
      "Previous covariance difference: 1.179763\n",
      "New covariance difference: 0.148054\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.19444444]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 8.74 with error 26.49251808\n",
      "Using nearest neighbor after estimating: 0.19444444444444445\n",
      "Lasso predicts 0.19 for case with 0.85 with reconstruction error 27.034915741 maximum error 14.115705521 and neighbor 0.19 and condition number 58692654660873.13\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.427252\n",
      "New covariance difference: 0.071110\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.30232558]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -35.87 with error 36.719654664\n",
      "Using nearest neighbor after estimating: 0.3023255813953488\n",
      "Lasso predicts 0.3 for case with 0.53 with reconstruction error 36.278390502 maximum error 14.691093453 and neighbor 0.3 and condition number 57304986330047.18\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.504763\n",
      "New covariance difference: 0.082588\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.26086957]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 11.38 with error 38.555713366\n",
      "Using nearest neighbor after estimating: 0.2608695652173913\n",
      "Lasso predicts 0.26 for case with 0.5 with reconstruction error 38.072993188 maximum error 14.288287147 and neighbor 0.26 and condition number 55506468993898.08\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.510890\n",
      "New covariance difference: 0.084765\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.55555556]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -18.26 with error 25.519986207\n",
      "Using nearest neighbor after estimating: 0.5555555555555556\n",
      "Lasso predicts 0.56 for case with 0.49 with reconstruction error 25.701272757 maximum error 13.986214148 and neighbor 0.56 and condition number 58924356731584.25\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.400489\n",
      "New covariance difference: 0.071843\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.88311688]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -0.87 with error 26.569254514\n",
      "Using nearest neighbor after estimating: 0.8831168831168831\n",
      "Lasso predicts 0.88 for case with 0.26 with reconstruction error 26.422979736 maximum error 15.553483158 and neighbor 0.88 and condition number 58711711627215.375\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.489572\n",
      "New covariance difference: 0.081272\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.65517241]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -11.38 with error 33.141078271\n",
      "Using nearest neighbor after estimating: 0.6551724137931034\n",
      "Lasso predicts 0.66 for case with 0.52 with reconstruction error 33.052660941 maximum error 14.126266107 and neighbor 0.66 and condition number 56933764885780.46\n",
      "Fit transform...\n",
      "Previous covariance difference: 6.269505\n",
      "New covariance difference: 0.792784\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.42857143]\n",
      "New neighbor [0.74358974]\n",
      "Lasso predicts 0.42 for case with 0.19 with reconstruction error 0.053938337 maximum error 0.163223622 and neighbor 0.74 and condition number 56843169510715.84\n",
      "Fit transform...\n",
      "Previous covariance difference: 2.523633\n",
      "New covariance difference: 0.303111\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.87301587]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -5.5 with error 35.303434239\n",
      "Using nearest neighbor after estimating: 0.873015873015873\n",
      "Lasso predicts 0.87 for case with 0.56 with reconstruction error 35.432860369 maximum error 13.918308658 and neighbor 0.87 and condition number 57759907299905.53\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.509009\n",
      "New covariance difference: 0.081482\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.5]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 4.68 with error 33.791952444\n",
      "Using nearest neighbor after estimating: 0.5\n",
      "Lasso predicts 0.5 for case with 0.66 with reconstruction error 33.548362701 maximum error 14.558354183 and neighbor 0.5 and condition number 57212049122612.5\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.351056\n",
      "New covariance difference: 0.053704\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.65517241]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 1.63 with error 25.504854996\n",
      "Using nearest neighbor after estimating: 0.6551724137931034\n",
      "Lasso predicts 0.66 for case with 0.84 with reconstruction error 25.586524688 maximum error 14.123659535 and neighbor 0.66 and condition number 59298576975345.27\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.325862\n",
      "New covariance difference: 0.049103\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.42857143]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -11.67 with error 25.753307009\n",
      "Using nearest neighbor after estimating: 0.42857142857142855\n",
      "Lasso predicts 0.43 for case with 0.47 with reconstruction error 26.061577685 maximum error 14.435393796 and neighbor 0.43 and condition number 58241807534456.6\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.340155\n",
      "New covariance difference: 0.048014\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.1875]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -10.12 with error 28.257703046\n",
      "Using nearest neighbor after estimating: 0.1875\n",
      "Lasso predicts 0.19 for case with 0.09 with reconstruction error 27.701613302 maximum error 13.861454502 and neighbor 0.19 and condition number 59057926059487.664\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.315915\n",
      "New covariance difference: 0.044423\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.67241379]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -1.31 with error 25.866032416\n",
      "Using nearest neighbor after estimating: 0.6724137931034483\n",
      "Lasso predicts 0.67 for case with 0.52 with reconstruction error 25.930460728 maximum error 14.71006586 and neighbor 0.67 and condition number 57194770718727.336\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.326267\n",
      "New covariance difference: 0.047029\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.14705882]\n",
      "New neighbor [0.73684211]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: -19.09 with error 25.693573763\n",
      "Using nearest neighbor after estimating: 0.14705882352941177\n",
      "Lasso predicts 0.15 for case with 0.36 with reconstruction error 26.283357045 maximum error 14.314433857 and neighbor 0.15 and condition number 57943094213256.6\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.317399\n",
      "New covariance difference: 0.044702\n",
      "Fit Estimator...\n",
      "Previous neighbor [0.1875]\n",
      "New neighbor [0.74358974]\n",
      "Refitting due to high reconstruction error after CORAL which estimated: 4.51 with error 33.407822016\n",
      "Using nearest neighbor after estimating: 0.1875\n",
      "Lasso predicts 0.19 for case with 0.82 with reconstruction error 32.851732273 maximum error 14.517288517 and neighbor 0.19 and condition number 60190026825106.02\n",
      "Fit transform...\n",
      "Previous covariance difference: 0.342288\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Js = []\n",
    "err_var = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    idy = y_train[y_train<=0.3]\n",
    "    \n",
    "    # Cross validation\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,test_index,pre_updrs_off,False,False,False)\n",
    "    cvn = len(X0_ss0-1)\n",
    "    lasso = slm.LassoLarsCV(max_iter=1000,cv=cvn,normalize=False,eps=0.1,n_jobs=1)\n",
    "\n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "      # Feature selection\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      sel = skf.SelectKBest(skf.r_regression,k=2925)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_sst = sel.transform(X_test_ss0)\n",
    "      #gel = skf.RFECV(lasso,verbose=0,cv=cvn,step=100,n_jobs=-1)\n",
    "      X0_ss = X0_sst#gel.fit_transform(X0_sst,y_train)\n",
    "      kappa.append(np.linalg.cond(X0_ss0))\n",
    "      X_test_ss = X_test_sst#gel.transform(X_test_sst)\n",
    "     #Ks.append(sel.transform(K.reshape(1, -1)))\n",
    "      dx, y_n0 = cKDTree(X0_ss).query(X_test_ss, k=1)\n",
    "\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=cvn,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      try:\n",
    "        lassoc = CORAL(lasso, Xt=X_test_ss, random_state=0)\n",
    "        est_ls = lassoc.fit(X0_ss,y_train)\n",
    "        print('Previous neighbor',str(y_train[y_n0]))\n",
    "        # If domain='tgt', apply transform to X0_ss (source data)\n",
    "        dx, y_n = cKDTree(X0_ss).query(lassoc.transform(X_test_ss,domain='src'), k=1)\n",
    "        print('New neighbor',str(y_train[y_n]))\n",
    "        coral = 1\n",
    "      except:\n",
    "        y_n = y_n0\n",
    "        print('CORAL failed on test case with covariance:',np.cov(X_test_ss0))\n",
    "        est_ls = lasso.fit(X0_ss,y_train)\n",
    "        coral = 0\n",
    "    # Reconstruct nearest neighbor\n",
    "    r[j] = est_ls.predict(X0_ss[y_n,:])\n",
    "    err_var[j] = np.mean(abs(est_ls.predict(X0_ss)-y_train))\n",
    "    rerror[j] = np.abs(r[j]-y_train[y_n])\n",
    "    #s.append(est_ls.score(X0_ss,y_train))\n",
    "    results_ls[j] = est_ls.predict(X_test_ss)\n",
    "    # If reconstruction error is too high, use nearest neighbor\n",
    "    if rerror[j] > 1 and coral == 1:\n",
    "      y_n = y_n0\n",
    "      print('Refitting due to high reconstruction error after CORAL which estimated:',\n",
    "            str(np.round(results_ls[j],2)),'with error',str(np.round(rerror[j],9)))\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "      results_ls[j] = est_ls.predict(X_test_ss)\n",
    "      rerror[j] = np.abs(r[j]-y_train[y_n])\n",
    "      if rerror[j] > 0.1: \n",
    "        results_ls[j] = y_train[y_n]\n",
    "        print('Using nearest neighbor after estimating:',str(results_ls[j]))\n",
    "    else:\n",
    "      if rerror[j] > 0.1:\n",
    "        print('Using nearest neighbor after high reconstruction error and CORAL failure')\n",
    "        y_n = y_n0\n",
    "        results_ls[j] = y_train[y_n]\n",
    "\n",
    "    print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "              'for case with',str(np.round(per_change[j],2)),\n",
    "             # 'with regularization',str(est_ls.alpha_),\n",
    "              'with reconstruction error',str(np.round(rerror[j],9)),\n",
    "              'maximum error',str(np.round(err_var[j],9)),\n",
    "              'and neighbor',str(np.round(y_train[y_n],2).item()),\n",
    "              'and condition number',str(kappa[j]))\n",
    "    gerror[j] = (abs(results_ls[j]-y_test))\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(kappa,gerror)\n",
    "plt.xlabel('Condition number')\n",
    "plt.ylabel('True error')\n",
    "plt.title('Error estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots()\n",
    "# df = pd.DataFrame({'Feature':(Kstg[wg != 0]).tolist()})\n",
    "# hist = df['Feature'].value_counts()#.plot(kind='bar',ax=ax)\n",
    "# ax.plot(hist[hist>1])\n",
    "#ax.get_legend().remove()\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Case ' + str(int(j)) + ', subject ' + str(subsc[j]) + ' with error ' + str(np.round(gerror[j],2)))\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "# plt.style.use('dark_background')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls[results_ls>1] = 1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(20,10))\n",
    "plt.ylim([0,1.5])\n",
    "plt.xlim([0,1.5])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(3,2,sharex=True,sharey=True)\n",
    "# plt.style.use('dark_background')\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "# ax[0,0].scatter(V[:,0]/1000,gerror)\n",
    "# ax[0,0].set_title('Right red nucleus')\n",
    "# ax[0,1].scatter(V[:,1]/1000,gerror)\n",
    "# ax[0,1].set_title('Left red nucleus')\n",
    "# ax[1,0].scatter(V[:,2]/1000,gerror)\n",
    "# ax[1,0].set_title('Right substantia nigra')\n",
    "# ax[1,1].scatter(V[:,3]/1000,gerror)\n",
    "# ax[1,1].set_title('Left substantia nigra')\n",
    "# ax[2,0].scatter(V[:,4]/1000,gerror)\n",
    "# ax[2,0].set_title('Right subthalamic nuclei')\n",
    "# ax[2,1].scatter(V[:,5]/1000,gerror)\n",
    "# ax[2,1].set_title('Left subthalamic nuclei')\n",
    "# plt.setp(ax[-1, :], xlabel='Variance');\n",
    "# plt.setp(ax[:, 0], ylabel='Error');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
