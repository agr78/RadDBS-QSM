{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "from mlp.datasets import QSM_slices\n",
    "import os\n",
    "import numpy as np\n",
    "import util\n",
    "import sklearn.preprocessing as skp\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                PRE-OP           Unnamed: 2  \\\n",
      "0      CORNELL ID  Apathy Off (pre-dbs)  Apathy ON (pre-dbs)   \n",
      "1              67                    na                   13   \n",
      "2   only Ct data                     na                   na   \n",
      "3              74                    na                   na   \n",
      "4              84                    na                   22   \n",
      "..            ...                   ...                  ...   \n",
      "87             52                   NaN                  NaN   \n",
      "88             53                   NaN                  NaN   \n",
      "89             54                   NaN                  NaN   \n",
      "90             55                   NaN                  NaN   \n",
      "91             56                   NaN                  NaN   \n",
      "\n",
      "             Unnamed: 3          Unnamed: 4    Unnamed: 5  \\\n",
      "0   OFF (pre-dbs updrs)  ON (pre-dbs updrs)  mri (pre-op)   \n",
      "1                    60                  41      3/9/2020   \n",
      "2                    43                  12            na   \n",
      "3                    34                  11     2/10/2020   \n",
      "4                    53                  13      6/1/2020   \n",
      "..                  ...                 ...           ...   \n",
      "87                   58                  27           NaN   \n",
      "88                   77                  47           NaN   \n",
      "89                   63                  36           NaN   \n",
      "90                   40                  29           NaN   \n",
      "91                   81                  20           NaN   \n",
      "\n",
      "                              Unnamed: 6                  POST-OP (6 MONTHS)  \\\n",
      "0   pre op levadopa equivalent dose (mg)  6 mo levadopa equivalent dose (mg)   \n",
      "1                                    500                                 500   \n",
      "2                                   2304                                 819   \n",
      "3                                   1200                                 600   \n",
      "4                                    350                                 150   \n",
      "..                                   ...                                 ...   \n",
      "87                                  1804                                1804   \n",
      "88                                   575                                 250   \n",
      "89                                  1400                                 400   \n",
      "90                                   400                                 450   \n",
      "91                                  2162                                1050   \n",
      "\n",
      "              Unnamed: 8           Unnamed: 9          Unnamed: 10  \\\n",
      "0   OFF meds ON stim 6mo  ON meds ON stim 6mo  off stim on med 6mo   \n",
      "1                     31                   29                  NaN   \n",
      "2                     na                   20                   18   \n",
      "3                     na                   17                   na   \n",
      "4                     na                   34                   na   \n",
      "..                   ...                  ...                  ...   \n",
      "87                    19                   12                  NaN   \n",
      "88                   NaN                   19                   26   \n",
      "89                     8                  NaN                  NaN   \n",
      "90                   NaN                   13                  NaN   \n",
      "91                   NaN                    7                  NaN   \n",
      "\n",
      "             Unnamed: 11     Unnamed: 12     Unnamed: 13 Unnamed: 14  \n",
      "0   off stim off med 6mo  apathy off 6mo  apathy on 6 mo        ledd  \n",
      "1                    NaN              na              na         NaN  \n",
      "2                    NaN              na              na         NaN  \n",
      "3                    NaN              na              na     1021.00  \n",
      "4                    NaN              na              na         NaN  \n",
      "..                   ...             ...             ...         ...  \n",
      "87                   NaN             NaN             NaN      500.00  \n",
      "88                   NaN             NaN             NaN      100.00  \n",
      "89                   NaN             NaN             NaN      550.00  \n",
      "90                    37             NaN             NaN      400.00  \n",
      "91                   NaN             NaN             NaN         NaN  \n",
      "\n",
      "[92 rows x 15 columns]\n",
      "       CORNELL ID OFF (pre-dbs updrs) ON (pre-dbs updrs)  \\\n",
      "1              67                  60                 41   \n",
      "2   only Ct data                   43                 12   \n",
      "3              74                  34                 11   \n",
      "4              84                  53                 13   \n",
      "5              75                  62                  8   \n",
      "..            ...                 ...                ...   \n",
      "87             52                  58                 27   \n",
      "88             53                  77                 47   \n",
      "89             54                  63                 36   \n",
      "90             55                  40                 29   \n",
      "91             56                  81                 20   \n",
      "\n",
      "   pre op levadopa equivalent dose (mg) OFF meds ON stim 6mo  \\\n",
      "1                                   500                   31   \n",
      "2                                  2304                  NaN   \n",
      "3                                  1200                  NaN   \n",
      "4                                   350                  NaN   \n",
      "5                                     0                    2   \n",
      "..                                  ...                  ...   \n",
      "87                                 1804                   19   \n",
      "88                                  575                  NaN   \n",
      "89                                 1400                    8   \n",
      "90                                  400                  NaN   \n",
      "91                                 2162                  NaN   \n",
      "\n",
      "   ON meds ON stim 6mo  off stim on med 6mo  off stim off med 6mo  \n",
      "1                   29                  NaN                   NaN  \n",
      "2                   20                   18                   NaN  \n",
      "3                   17                  NaN                   NaN  \n",
      "4                   34                  NaN                   NaN  \n",
      "5                  NaN                  NaN                   NaN  \n",
      "..                 ...                  ...                   ...  \n",
      "87                  12                  NaN                   NaN  \n",
      "88                  19                   26                   NaN  \n",
      "89                 NaN                  NaN                   NaN  \n",
      "90                  13                  NaN                    37  \n",
      "91                   7                  NaN                   NaN  \n",
      "\n",
      "[91 rows x 8 columns]\n",
      "[ 500.     0.   900.   700.   988.   902.   450.  1401.   900.   712.\n",
      " 1950.  1300.  1400.   875.   949.  1100.  1427.   325.  1924.  1000.\n",
      "  800.  1700.  1866.   875.  1506.  1404.   181.8 1200.   750.   200.\n",
      " 1153.  2088.   369.5  798.  1719.     0.   450.  2269.   600.  1032.\n",
      " 1625.   400.  1230.   849.   360.  1064.   456.   600.   100.   711.\n",
      " 1804.  1400. ]\n",
      "Allocated arrays\n",
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n",
      "['Left red nucleus' 'Left substantia nigra' 'Right Substantia nigra'\n",
      " 'Right red nucleus']\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528_wldd.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','pre op levadopa equivalent dose (mg)','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off,ledd = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo',\n",
    "                                                          'pre op levadopa equivalent dose (mg)')\n",
    "print(ledd)\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,False)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,0:4,:]\n",
    "K_all_c = K_all[c_cases_idx,0:4,:]\n",
    "R_all_c = R_all[c_cases_idx,0:4,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subs_init = subs[s_cases_idx]\n",
    "pre_imp_init = pre_imp[s_cases_idx]\n",
    "post_imp_init = post_imp[s_cases_idx]\n",
    "pre_updrs_off_init = pre_updrs_off[s_cases_idx]\n",
    "ledd_init = ledd[s_cases_idx]\n",
    "per_change_init = post_imp_init\n",
    "subs = np.asarray(ID_all,dtype=float)[np.in1d(np.asarray(ID_all,dtype=float),subs_init)]\n",
    "subs0 = subs_init\n",
    "pre_imp = np.zeros((1,len(subs))).T\n",
    "post_imp = np.zeros((1,len(subs))).T\n",
    "pre_updrs_off = np.zeros((1,len(subs))).T\n",
    "ledd = np.zeros((1,len(subs))).T\n",
    "per_change = np.zeros((1,len(subs))).T\n",
    "for j in np.arange(len(subs)):\n",
    "    pre_imp[j] = pre_imp_init[subs_init == subs[j]]\n",
    "    post_imp[j] = post_imp_init[subs_init == subs[j]]\n",
    "    pre_updrs_off[j] = pre_updrs_off_init[subs_init == subs[j]]\n",
    "    ledd[j] = ledd_init[subs_init == subs[j]]\n",
    "    per_change[j] = per_change_init[subs_init == subs[j]]\n",
    "\n",
    "subsc = subs\n",
    "X_all_c = X_all_c.reshape(X_all_c.shape[0],-1)\n",
    "X_all_c = np.append(X_all_c,pre_updrs_off,axis=1)\n",
    "X_all_c = np.append(X_all_c,ledd,axis=1)\n",
    "print(np.unique(R_all_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.listdir('../mlp/tensor_slices_0')\n",
    "scaler = skp.StandardScaler()\n",
    "X = scaler.fit_transform(X_all_c)\n",
    "train_dataset = QSM_slices(data_dir=data_dir,aug_state=1, factor=0, X=X,subsc=subsc,targets=per_change,prefix='../mlp/')\n",
    "data_loader = DataLoader(train_dataset, batch_size=X.shape[0], shuffle=True)\n",
    "img_size = 64 # Image size\n",
    "batch_size = 45  # Batch size\n",
    "\n",
    "# Model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "z_size = 128\n",
    "generator_layer_size = [256, 512, 1024]\n",
    "discriminator_layer_size = [1024, 512, 256]\n",
    "class_num = 0\n",
    "N = len(np.unique(np.round(per_change,1)))\n",
    "# Training\n",
    "epochs = 30\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, generator_layer_size, z_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.z_size = z_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.z_size + class_num, generator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[0], generator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[1], generator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(generator_layer_size[2], self.img_size * self.img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        \n",
    "        # Reshape z\n",
    "        z = z.view(-1, self.z_size)\n",
    "        # One-hot vector to embedding vector\n",
    "        c = labels.reshape(-1,1)\n",
    "        # Concat image & label\n",
    "        x = z\n",
    "        #x = torch.cat([z, c], 1)\n",
    "        # Generator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.view(-1, self.img_size, self.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, discriminator_layer_size, img_size, class_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(class_num, class_num)\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.img_size * self.img_size + class_num, discriminator_layer_size[0]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[0], discriminator_layer_size[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[1], discriminator_layer_size[2]),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(discriminator_layer_size[2], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        \n",
    "        # Reshape fake image\n",
    "        x = x.view(-1, self.img_size * self.img_size)\n",
    "        # One-hot vector to embedding vector\n",
    "        c = labels.reshape(-1,1)\n",
    "\n",
    "        # Concat image & label\n",
    "        #x = torch.cat([x, c], 1)\n",
    "\n",
    "        # Discriminator out\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator\n",
    "generator = Generator(generator_layer_size, z_size, img_size, class_num).to(device)\n",
    "# Define discriminator\n",
    "discriminator = Discriminator(discriminator_layer_size, img_size, class_num).to(device)\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    \n",
    "    # Init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    \n",
    "    # Backword propagation\n",
    "    g_loss.backward()\n",
    "    \n",
    "    #  Optimizing generator\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return g_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    \n",
    "    # Init gradient \n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # Disciminating real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    \n",
    "    # Calculating discrimination loss (real images)\n",
    "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    \n",
    "    # Building z\n",
    "    z = Variable(torch.randn(batch_size, z_size)).to(device)\n",
    "    \n",
    "    # Building fake labels\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, class_num, batch_size))).to(device)\n",
    "    \n",
    "    # Generating fake images\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    \n",
    "    # Disciminating fake images\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    \n",
    "    # Calculating discrimination loss (fake images)\n",
    "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).to(device))\n",
    "    \n",
    "    # Sum two losses\n",
    "    d_loss = real_loss + fake_loss\n",
    "    \n",
    "    # Backword propagation\n",
    "    d_loss.backward()\n",
    "    \n",
    "    # Optimizing discriminator\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    return d_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7a7102063c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         d_loss = discriminator_train_step(len(real_images), discriminator,\n\u001b[1;32m     17\u001b[0m                                           \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                           real_images, labels)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-69b21efb18d9>\u001b[0m in \u001b[0;36mdiscriminator_train_step\u001b[0;34m(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Building fake labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Generating fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print('Starting epoch {}...'.format(epoch+1))\n",
    "    \n",
    "    for i, (images, X, labels) in enumerate(data_loader):\n",
    "        \n",
    "        # Train data\n",
    "        real_images = Variable(images).to(device)\n",
    "        labels = torch.zeros_like(labels)\n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        # Set generator train\n",
    "        generator.train()\n",
    "        \n",
    "        # Train discriminator\n",
    "        d_loss = discriminator_train_step(len(real_images), discriminator,\n",
    "                                          generator, d_optimizer, criterion,\n",
    "                                          real_images, labels)\n",
    "        \n",
    "        # Train generator\n",
    "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "    \n",
    "    # Set generator eval\n",
    "    generator.eval()\n",
    "    \n",
    "    print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
    "    \n",
    "    # Building z \n",
    "    z = Variable(torch.randn(len(data_loader.dataset), z_size)).to(device)\n",
    "\n",
    "    # Labels\n",
    "    labels = Variable(torch.Tensor((np.round(per_change.reshape(-1,1),1)))).to(device)\n",
    "    labels = torch.zeros_like(labels)\n",
    "    # Generating images\n",
    "    print('Passing sample images to generator:')\n",
    "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
    "\n",
    "\n",
    "# Show images\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "grid = make_grid(torch.vstack((250*sample_images,real_images.cpu())), nrow=9, normalize=True).permute(1,2,0).numpy()\n",
    "ax.imshow(np.rot90(grid))\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
