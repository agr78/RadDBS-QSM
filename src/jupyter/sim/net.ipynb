{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from scipy.stats import linregress\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import util\n",
    "from fds import FDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated arrays\n",
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,False)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "K_all_c = K_all[c_cases_idx,:,:]\n",
    "R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subsc = subs[s_cases_idx]\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,train_index,test_index = util.set_split(X_all_c,per_change,1,6/len(X_all_c))\n",
    "X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                             X_train,train_index,X_test,test_index,pre_updrs_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X_train,y_train,n_epochs,alpha,beta):   \n",
    "    # Convert to 2D PyTorch tensors\n",
    "    idx_val = np.random.randint(0,len(y_train))\n",
    "    print(idx_val)\n",
    "    X_val = torch.tensor(X_train[idx_val,:], dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_train[idx_val], dtype=torch.float32).reshape(-1, 1)\n",
    "    X_train = torch.tensor(np.delete(X_train,idx_val,axis=0), dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.delete(y_train,idx_val), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    # Define the model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1],X_train.shape[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(X_train.shape[1], X_train.shape[1]//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(X_train.shape[1]//2, X_train.shape[1]//4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(X_train.shape[1]//4,X_train.shape[1]//8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(X_train.shape[1]//8,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1,1)\n",
    "    )\n",
    "    #model.apply(init_weights)\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.MSELoss()  # mean square error\n",
    "    optimizer = optim.SGD(model.parameters(),lr=alpha,momentum=beta)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=1e-1,patience=5,min_lr=1e-12)\n",
    "    batch_size = 1  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "    \n",
    "    # Hold the best model\n",
    "    best_mse = np.inf   # init to infinity\n",
    "    best_weights = None\n",
    "    history = []\n",
    "    training_loss = []\n",
    "    batch_loss = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # if best_mse > 0.05:\n",
    "            model.train()\n",
    "            with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "                bar.set_description(f\"Epoch {epoch}\")\n",
    "                for start in bar:\n",
    "                    # take a batch\n",
    "                    X_batch = X_train[start:start+batch_size]\n",
    "                    y_batch = y_train[start:start+batch_size]\n",
    "                    # forward pass\n",
    "                    y_pred = model(X_batch.ravel())\n",
    "                    loss = loss_fn(y_pred.ravel(), y_batch.ravel())\n",
    "                    batch_loss.append(loss.detach())\n",
    "                    # backward pass\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    # update weights\n",
    "                    optimizer.step()\n",
    "                    # print progress\n",
    "                    bar.set_postfix(mse=float(loss))\n",
    "    \n",
    "            # evaluate accuracy at end of each epoch\n",
    "            model.eval()\n",
    "            training_loss.append(np.mean(batch_loss))\n",
    "            y_pred = model(X_val.ravel())\n",
    "            mse = loss_fn(y_pred.ravel(), y_val.ravel())\n",
    "            mse = float(mse)\n",
    "            history.append(mse)\n",
    "            scheduler.step(mse)\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                print('Best MSE:',best_mse,'at learning rate',optimizer.param_groups[0]['lr'])\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "                print(y_val)\n",
    "    \n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    print(\"MSE: %.2f\" % best_mse)\n",
    "    print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "\n",
    "    plt.plot(history)\n",
    "    plt.plot(training_loss)\n",
    "    \n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(per_change.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 440496 into shape (1,9576)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8789061113be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#                                             X_test_ss0.shape[1]*X_test_ss0.shape[2]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_ss0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_ss0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_ss0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_test_ss0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_ss0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 440496 into shape (1,9576)"
     ]
    }
   ],
   "source": [
    "for j in np.arange(len(subsc)):\n",
    "    # Split the data\n",
    "    Js = []\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    # Cross validation\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,test_index,pre_updrs_off)\n",
    "\n",
    "    # # Feature selection\n",
    "    # with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    #     sel = skf.SelectKBest(skf.r_regression,k=2000)\n",
    "    #     X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "    #     X_test_ss = sel.transform(X_test_ss0.reshape([X_test_ss0.shape[0],\n",
    "    #                                             X_test_ss0.shape[1]*X_test_ss0.shape[2]]))\n",
    "\n",
    "    model = net(X0_ss0.reshape(X_test_ss0.shape[0],X_test_ss0.shape[1]*X_test_ss0.shape[2]),y_train,20,0.1,0.9)\n",
    "    \n",
    "    results[j] = model(torch.tensor(X_test_ss0,dtype=torch.float32))\n",
    "    # Output results\n",
    "    print('Model predicts',str(results[j]),'for case',str(test_id),'with actual improvement',str(per_change[j]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fig,ax] = plt.subplots()\n",
    "lr_prepost = linregress(results,per_change)\n",
    "ax.scatter(results,per_change)\n",
    "ax.plot(results,results*lr_prepost.slope+lr_prepost.intercept,'-r')\n",
    "ax.set_title('Model performance')\n",
    "ax.set_ylabel(\"DBS improvement\")\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "text = f\"$y={lr_prepost.slope:0.2f}\\; x{lr_prepost.intercept:+0.2f}$\\n$r = {lr_prepost.rvalue:0.2f}$\\n$p = {lr_prepost.pvalue:0.3f}$\"\n",
    "ax.text(0.35, 0.75, text,transform=ax.transAxes,\n",
    "    fontsize=14, verticalalignment='top')\n",
    "ax.hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax.vlines(0.3,0,2,linestyle='dashed',color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
