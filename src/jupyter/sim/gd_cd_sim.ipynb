{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(rho,lamda):\n",
    "    '''Soft threshold function used for normalized data and lasso regression'''\n",
    "    if rho < - lamda:\n",
    "        return (rho + lamda)\n",
    "    elif rho >  lamda:\n",
    "        return (rho - lamda)\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def soft_thresholdv(rho,lamda):\n",
    "    '''Array version of soft threshold function'''\n",
    "    s = np.zeros_like(rho)\n",
    "    s[rho < -lamda] = rho[rho < -lamda]+lamda\n",
    "    s[rho > lamda] = rho[rho > lamda]-lamda\n",
    "    return s\n",
    "    \n",
    "\n",
    "def coordinate_descent_lasso(theta,X,y,lamda,num_iters,intercept):\n",
    "    '''Coordinate gradient descent for lasso regression - for normalized data. \n",
    "    The intercept parameter allows to specify whether or not to regularize theta_0'''\n",
    "    # Helpful dimensions \n",
    "    m,n = X.shape\n",
    "    # Normalizing X in case it was not done before\n",
    "    X = X / (np.linalg.norm(X,axis = 0))\n",
    "    # Looping until max number of iterations\n",
    "    for i in range(num_iters): \n",
    "        # Looping through each coordinate\n",
    "        for j in range(n):\n",
    "            # Vectorized implementation\n",
    "            X_j = X[:,j].reshape(-1,1)\n",
    "            y_pred = X @ theta\n",
    "            rho = X_j.T @ (y-y_pred+theta[j]*X_j)\n",
    "            # Checking intercept parameter\n",
    "            if intercept == True:  \n",
    "                if j == 0: \n",
    "                    theta[j] = rho \n",
    "                else:\n",
    "                    theta[j] = soft_threshold(rho, lamda)  \n",
    "            if intercept == False:\n",
    "                theta[j] = soft_threshold(rho, lamda)   \n",
    "    return theta.flatten()\n",
    "\n",
    "def gradient_descent_reg(theta,X,y,alpha,lamda,num_iters):\n",
    "    '''Gradient descent for lasso regression'''\n",
    "    # Helpful dimensions \n",
    "    m = np.size(y)\n",
    "    for i in range(num_iters):\n",
    "        # Prediction\n",
    "        h = np.dot(X,theta)\n",
    "        rho = np.dot(X.T,(h-y))\n",
    "        # Gradient function in vectorized form\n",
    "        theta = theta-alpha*(1/m)*(soft_thresholdv(rho,lamda))\n",
    "    return theta.flatten()\n",
    "\n",
    "def conjugate_gradient_descent(X, y, theta0, lamda, num_iters):\n",
    "    theta = theta0\n",
    "    m = len(y)\n",
    "    for k in np.arange(num_iters):\n",
    "        F = (1/m)*(X*theta-y)**2+lamda*np.sum(np.abs(theta))\n",
    "        h = np.dot(X,theta)\n",
    "        rho = np.dot(X.T,(h-y))\n",
    "        p = -soft_thresholdv(rho,lamda)    \n",
    "        alpha = 1e-4\n",
    "        theta = theta+alpha*p\n",
    "    return np.array(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "('CORNELL ID', 'OFF (pre-dbs updrs)', 'ON (pre-dbs updrs)', 'OFF meds ON stim 6mo')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59111c986712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                           \u001b[0;34m'OFF (pre-dbs updrs)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                           \u001b[0;34m'ON (pre-dbs updrs)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                           'OFF meds ON stim 6mo')\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load extracted features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnpy_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/ali/RadDBS-QSM/data/npy/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RadDBS-QSM/src/jupyter/util.py\u001b[0m in \u001b[0;36mget_full_cases\u001b[0;34m(df, *arg)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0mh0a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0mh1a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0mh2a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h0' is not defined"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_data(file_dir,'pre-dbs updrs','stim')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "\n",
    "X_all_c, K, R, subsc, pre_imp, pre_updrs_off, per_change = util.re_index(X_all,K_all,R_all,c_cases_idx,subs,ids,all_rois,pre_imp,pre_updrs_off,post_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = K.reshape(1,-1)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "cvn = 5\n",
    "alphas = np.logspace(-4,-1,10)\n",
    "gd_cd = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(len(subsc)):\n",
    "      test_id = subsc[j]\n",
    "      test_index = subsc == test_id\n",
    "      train_index = subsc != test_id\n",
    "      X_train = X_all_c[train_index,:,:]\n",
    "      X_test = X_all_c[test_index,:,:]\n",
    "      y_train = per_change[train_index]\n",
    "      y_test = per_change[test_index]\n",
    "      # Cross validation\n",
    "      X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                  X_train,train_index,X_test,\n",
    "                                                  test_index,pre_updrs_off,all_rois,False,False)\n",
    "      with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Feature selection, make sure A is square\n",
    "        sel = skf.SelectKBest(skf.r_regression,k=X0_ss0.shape[0])\n",
    "        X0_ss = (sel.fit_transform(X0_ss0,y_train))\n",
    "        X_test_ss = (sel.transform(X_test_ss0))\n",
    "        K = sel.transform(K0)\n",
    "        y_n = cKDTree(X0_ss).query(X_test_ss, k=1)[1]\n",
    "\n",
    "      # Initialize variables\n",
    "      X = X0_ss\n",
    "      m,n = X.shape\n",
    "      initial_theta = np.zeros((n,1))\n",
    "      bnds = []\n",
    "      for j in np.arange(len(initial_theta)): \n",
    "        bnds.append((-1e1, 1e1))\n",
    "      theta_list_cd = []\n",
    "      theta_list_gd = []\n",
    "      theta_list_cg = []\n",
    "      lamda = np.flip(np.logspace(-4,1,100)) # Range of lambda values\n",
    "      y = y_train.reshape(-1,1)\n",
    "\n",
    "      \n",
    "      #Run lasso regression for each lambda\n",
    "      if gd_cd == True:\n",
    "        for l in lamda:\n",
    "            theta_cd = coordinate_descent_lasso(initial_theta,X,y,lamda = l,num_iters=100,intercept=False)\n",
    "            theta_list_cd.append(theta_cd)\n",
    "            theta_gd = gradient_descent_reg(initial_theta,X,y,alpha=1e-3,lamda = l,num_iters=100)\n",
    "            theta_list_gd.append(theta_gd)\n",
    "            theta_cg = conjugate_gradient_descent(X,y,np.ones((n,1)),l,num_iters=100)\n",
    "            theta_list_cg.append(theta_cg)\n",
    "      #Stack into numpy array\n",
    "      theta_lasso_cd = np.stack(theta_list_cd).T\n",
    "      theta_lasso_gd = np.squeeze(np.stack(theta_list_gd).T)\n",
    "      theta_lasso_cg = np.stack(theta_list_cg).T\n",
    "      try:\n",
    "         np.linalg.cholesky(X0_ss)\n",
    "      except:\n",
    "         print('Matrix is not positive definite')\n",
    "      kappa = np.linalg.cond(X0_ss)\n",
    "      print('Condition number',str(kappa))\n",
    "      print('Mean weights:',str(np.mean(theta_lasso_cd)),str(np.mean(theta_lasso_gd)),str(np.mean(theta_lasso_cg)))\n",
    "      print('CG-CD error',np.mean((theta_lasso_cd-theta_lasso_cg)**2))\n",
    "      print('CG-GD error',np.mean((theta_lasso_gd-theta_lasso_cg)**2))\n",
    "      print('GD-CD error',np.mean((theta_lasso_cd-theta_lasso_gd)**2))\n",
    "      if np.mean((theta_lasso_cd-theta_lasso_cg)**2) < 1e-6:\n",
    "        #Plot results\n",
    "        n,_ = theta_lasso_cd.shape\n",
    "        fig,ax = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(10,5))\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[0].plot(lamda, theta_lasso_cd[i])#,label = K[:,i])\n",
    "\n",
    "        ax[0].set_xscale('log')\n",
    "        ax[0].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[0].set_ylabel('Coefficients')\n",
    "        ax[0].set_title('Coordinate descent')\n",
    "        plt.axis('tight')\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[1].plot(lamda, theta_lasso_gd[i])#label = K[:,i])\n",
    "\n",
    "        ax[1].set_xscale('log')\n",
    "        ax[1].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[1].set_title('Gradient descent')\n",
    "        plt.axis('tight')\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[2].plot(lamda, theta_lasso_cg[i])#label = K[:,i])\n",
    "\n",
    "        ax[2].set_xscale('log')\n",
    "        ax[2].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[2].set_title('Conjugate gradient descent')\n",
    "        plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "n,_ = theta_lasso_cd.shape\n",
    "fig,ax = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(10,5))\n",
    "\n",
    "for i in range(10):\n",
    "    ax[0].plot(lamda, theta_lasso_cd[i])#,label = K[:,i])\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[0].set_ylabel('Coefficients')\n",
    "ax[0].set_title('Coordinate descent')\n",
    "plt.axis('tight')\n",
    "\n",
    "for i in range(10):\n",
    "    ax[1].plot(lamda, theta_lasso_gd[i])#label = K[:,i])\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[1].set_title('Gradient descent')\n",
    "plt.axis('tight')\n",
    "\n",
    "for i in range(10):\n",
    "    ax[2].plot(lamda, theta_lasso_cg[i])#label = K[:,i])\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[2].set_title('Conjugate gradient descent')\n",
    "plt.axis('tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
