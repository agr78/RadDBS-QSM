{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(rho,lamda):\n",
    "    '''Soft threshold function used for normalized data and lasso regression'''\n",
    "    if rho < - lamda:\n",
    "        return (rho + lamda)\n",
    "    elif rho >  lamda:\n",
    "        return (rho - lamda)\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def soft_thresholdv(rho,lamda):\n",
    "    '''Array version of soft threshold function'''\n",
    "    s = np.zeros_like(rho)\n",
    "    s[rho < -lamda] = rho[rho < -lamda]+lamda\n",
    "    s[rho > lamda] = rho[rho > lamda]-lamda\n",
    "    return s\n",
    "    \n",
    "\n",
    "def coordinate_descent_lasso(theta,X,y,lamda,num_iters,intercept):\n",
    "    '''Coordinate gradient descent for lasso regression - for normalized data. \n",
    "    The intercept parameter allows to specify whether or not to regularize theta_0'''\n",
    "    # Helpful dimensions \n",
    "    m,n = X.shape\n",
    "    # Normalizing X in case it was not done before\n",
    "    X = X / (np.linalg.norm(X,axis = 0))\n",
    "    # Looping until max number of iterations\n",
    "    for i in range(num_iters): \n",
    "        # Looping through each coordinate\n",
    "        for j in range(n):\n",
    "            # Vectorized implementation\n",
    "            X_j = X[:,j].reshape(-1,1)\n",
    "            y_pred = X @ theta\n",
    "            rho = X_j.T @ (y-y_pred+theta[j]*X_j)\n",
    "            # Checking intercept parameter\n",
    "            if intercept == True:  \n",
    "                if j == 0: \n",
    "                    theta[j] = rho \n",
    "                else:\n",
    "                    theta[j] = soft_threshold(rho, lamda)  \n",
    "            if intercept == False:\n",
    "                theta[j] = soft_threshold(rho, lamda)   \n",
    "    return theta.flatten()\n",
    "\n",
    "def gradient_descent_reg(theta,X,y,alpha,lamda,num_iters):\n",
    "    '''Gradient descent for lasso regression'''\n",
    "    # Helpful dimensions \n",
    "    m = np.size(y)\n",
    "    for i in range(num_iters):\n",
    "        # Prediction\n",
    "        h = np.dot(X,theta)\n",
    "        rho = np.dot(X.T,(h-y))\n",
    "        # Gradient function in vectorized form\n",
    "        theta = theta-alpha*(1/m)*(soft_thresholdv(rho,lamda))\n",
    "    return theta.flatten()\n",
    "\n",
    "def conjugate_gradient_descent(X, y, theta0, lamda, num_iters):\n",
    "    theta = theta0\n",
    "    m = len(y)\n",
    "    for k in np.arange(num_iters):\n",
    "        F = (1/m)*(X*theta-y)**2+lamda*np.sum(np.abs(theta))\n",
    "        h = np.dot(X,theta)\n",
    "        rho = np.dot(X.T,(h-y))\n",
    "        p = -soft_thresholdv(rho,lamda)    \n",
    "        alpha = 1e-4\n",
    "        theta = theta+alpha*p\n",
    "    return np.array(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated arrays\n",
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n",
      "['Left red nucleus' 'Left substantia nigra' 'Left subthalamic nucleus'\n",
      " 'Right Substantia nigra' 'Right red nucleus' 'Right subthalamic nucleus']\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "\n",
    "X_all_c, K, R, subsc, pre_imp, pre_updrs_off, per_change = util.re_index(X_all,K_all,R_all,c_cases_idx,subs,ids,all_rois,pre_imp,pre_updrs_off,post_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = K.reshape(1,-1)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "cvn = 5\n",
    "alphas = np.logspace(-4,-1,10)\n",
    "gd_cd = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is not positive definite\n",
      "Condition number 1.4541472431871534e+16\n",
      "Mean weights: 0.04934980011471685 0.03565967638586432 0.07499044275143162\n",
      "CG-CD error 0.41747910638699187\n",
      "CG-GD error 0.4178688309527355\n",
      "GD-CD error 0.0003426026557911316\n",
      "Matrix is not positive definite\n",
      "Condition number 3.948728506346811e+16\n",
      "Mean weights: 0.04452460990701553 0.030707399307759283 0.06194834960632852\n",
      "CG-CD error 0.7071285138313635\n",
      "CG-GD error 0.7071644853217224\n",
      "GD-CD error 0.00033941702060467514\n",
      "Matrix is not positive definite\n",
      "Condition number 6.958544759433592e+16\n",
      "Mean weights: 0.04363742240443696 0.03100982861417763 0.061098446704076985\n",
      "CG-CD error 0.7164776876769233\n",
      "CG-GD error 0.7166208311464509\n",
      "GD-CD error 0.00030640209646254357\n",
      "Matrix is not positive definite\n",
      "Condition number 1.3848083366834926e+16\n",
      "Mean weights: 0.044165982469287234 0.031764600523686876 0.06346327815065027\n",
      "CG-CD error 0.8576360116685983\n",
      "CG-GD error 0.8578193823367358\n",
      "GD-CD error 0.0002955319950107758\n",
      "Matrix is not positive definite\n",
      "Condition number 4.1506723072695763e+17\n",
      "Mean weights: 0.040385616886998085 0.02831705583669557 0.0568522120441887\n",
      "CG-CD error 1.1832775533810556\n",
      "CG-GD error 1.1835397810894792\n",
      "GD-CD error 0.00027992804980834216\n",
      "Matrix is not positive definite\n",
      "Condition number 1.2170472494468501e+129\n",
      "Mean weights: 0.10401994802588233 0.09686651971322119 0.7234400627115174\n",
      "CG-CD error 0.925884031867387\n",
      "CG-GD error 0.9255969715497733\n",
      "GD-CD error 0.0002559032280737431\n",
      "Matrix is not positive definite\n",
      "Condition number 6379324910236294.0\n",
      "Mean weights: 0.051082301238642255 0.036725962058655956 0.07236857878067131\n",
      "CG-CD error 0.34563900114124885\n",
      "CG-GD error 0.34592747529142687\n",
      "GD-CD error 0.0003637180359853131\n",
      "Matrix is not positive definite\n",
      "Condition number 1.38784135351238e+98\n",
      "Mean weights: 0.11198646508218645 0.10416366759559804 0.7461447306624498\n",
      "CG-CD error 0.8898499119720391\n",
      "CG-GD error 0.8901461218801496\n",
      "GD-CD error 0.00030733198597612745\n",
      "Matrix is not positive definite\n",
      "Condition number 1.4014642604801706e+16\n",
      "Mean weights: 0.049628317075917014 0.035517431009835634 0.07788482772973244\n",
      "CG-CD error 0.24574984302565703\n",
      "CG-GD error 0.24634051026568649\n",
      "GD-CD error 0.00036302636375533934\n",
      "Matrix is not positive definite\n",
      "Condition number 3.6440528785597076e+81\n",
      "Mean weights: 0.11004207737869436 0.10221808859032451 0.7405033028235761\n",
      "CG-CD error 1.0077633203147696\n",
      "CG-GD error 1.0078536829259044\n",
      "GD-CD error 0.00030546399804356783\n",
      "Matrix is not positive definite\n",
      "Condition number 5930205762359226.0\n",
      "Mean weights: 0.04567427912297989 0.03361944654785751 0.06465251434973979\n",
      "CG-CD error 0.5716169082081435\n",
      "CG-GD error 0.5718423557200001\n",
      "GD-CD error 0.0002746024465790816\n",
      "Matrix is not positive definite\n",
      "Condition number 3.98879746231493e+80\n",
      "Mean weights: 0.10542912184704768 0.09772479506182331 0.7316965605398803\n",
      "CG-CD error 0.9099434872144763\n",
      "CG-GD error 0.9099357748221183\n",
      "GD-CD error 0.00029698189423187576\n",
      "Matrix is not positive definite\n",
      "Condition number 9565760463719410.0\n",
      "Mean weights: 0.049186389779579696 0.03568389212301067 0.07397783115580864\n",
      "CG-CD error 0.4552474315859853\n",
      "CG-GD error 0.45578563285819446\n",
      "GD-CD error 0.00033322159578776903\n",
      "Matrix is not positive definite\n",
      "Condition number 2.3146774373457492e+16\n",
      "Mean weights: 0.038770484303558825 0.025994485517187655 0.06185607297512639\n",
      "CG-CD error 1.0725181443121348\n",
      "CG-GD error 1.0726400766080897\n",
      "GD-CD error 0.00030752050426149176\n",
      "Matrix is not positive definite\n",
      "Condition number 2.2394238486995972e+16\n",
      "Mean weights: 0.048791053283935196 0.035752681183235456 0.06827822898010533\n",
      "CG-CD error 0.4913991402538274\n",
      "CG-GD error 0.49166274525575276\n",
      "GD-CD error 0.00032723821371448555\n",
      "Matrix is not positive definite\n",
      "Condition number 2.1597855271027036e+80\n",
      "Mean weights: 0.10528491078919816 0.09769100566502545 0.7359590974165275\n",
      "CG-CD error 0.9215512684915063\n",
      "CG-GD error 0.9216762758473375\n",
      "GD-CD error 0.00028871392313118316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6b8acfe10775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtheta_cd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_descent_lasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtheta_list_cd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_cd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtheta_gd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtheta_list_gd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_gd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtheta_cg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconjugate_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-361ddd0d9566>\u001b[0m in \u001b[0;36mgradient_descent_reg\u001b[0;34m(theta, X, y, alpha, lamda, num_iters)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mrho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Gradient function in vectorized form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_thresholdv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-361ddd0d9566>\u001b[0m in \u001b[0;36msoft_thresholdv\u001b[0;34m(rho, lamda)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m'''Array version of soft threshold function'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrho\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in np.arange(len(subsc)):\n",
    "      test_id = subsc[j]\n",
    "      test_index = subsc == test_id\n",
    "      train_index = subsc != test_id\n",
    "      X_train = X_all_c[train_index,:,:]\n",
    "      X_test = X_all_c[test_index,:,:]\n",
    "      y_train = per_change[train_index]\n",
    "      y_test = per_change[test_index]\n",
    "      # Cross validation\n",
    "      X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                  X_train,train_index,X_test,\n",
    "                                                  test_index,pre_updrs_off,all_rois,False,False)\n",
    "      with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Feature selection, make sure A is square\n",
    "        sel = skf.SelectKBest(skf.r_regression,k=X0_ss0.shape[0])\n",
    "        X0_ss = (sel.fit_transform(X0_ss0,y_train))\n",
    "        X_test_ss = (sel.transform(X_test_ss0))\n",
    "        K = sel.transform(K0)\n",
    "        y_n = cKDTree(X0_ss).query(X_test_ss, k=1)[1]\n",
    "\n",
    "      # Initialize variables\n",
    "      X = X0_ss\n",
    "      m,n = X.shape\n",
    "      initial_theta = np.zeros((n,1))\n",
    "      bnds = []\n",
    "      for j in np.arange(len(initial_theta)): \n",
    "        bnds.append((-1e1, 1e1))\n",
    "      theta_list_cd = []\n",
    "      theta_list_gd = []\n",
    "      theta_list_cg = []\n",
    "      lamda = np.flip(np.logspace(-4,1,100)) # Range of lambda values\n",
    "      y = y_train.reshape(-1,1)\n",
    "\n",
    "      \n",
    "      #Run lasso regression for each lambda\n",
    "      if gd_cd == True:\n",
    "        for l in lamda:\n",
    "            theta_cd = coordinate_descent_lasso(initial_theta,X,y,lamda = l,num_iters=100,intercept=False)\n",
    "            theta_list_cd.append(theta_cd)\n",
    "            theta_gd = gradient_descent_reg(initial_theta,X,y,alpha=1e-3,lamda = l,num_iters=100)\n",
    "            theta_list_gd.append(theta_gd)\n",
    "            theta_cg = conjugate_gradient_descent(X,y,np.ones((n,1)),l,num_iters=100)\n",
    "            theta_list_cg.append(theta_cg)\n",
    "      #Stack into numpy array\n",
    "      theta_lasso_cd = np.stack(theta_list_cd).T\n",
    "      theta_lasso_gd = np.squeeze(np.stack(theta_list_gd).T)\n",
    "      theta_lasso_cg = np.stack(theta_list_cg).T\n",
    "      try:\n",
    "         np.linalg.cholesky(X0_ss)\n",
    "      except:\n",
    "         print('Matrix is not positive definite')\n",
    "      kappa = np.linalg.cond(X0_ss)\n",
    "      print('Condition number',str(kappa))\n",
    "      print('Mean weights:',str(np.mean(theta_lasso_cd)),str(np.mean(theta_lasso_gd)),str(np.mean(theta_lasso_cg)))\n",
    "      print('CG-CD error',np.mean((theta_lasso_cd-theta_lasso_cg)**2))\n",
    "      print('CG-GD error',np.mean((theta_lasso_gd-theta_lasso_cg)**2))\n",
    "      print('GD-CD error',np.mean((theta_lasso_cd-theta_lasso_gd)**2))\n",
    "      if np.mean((theta_lasso_cd-theta_lasso_cg)**2) < 1e-6:\n",
    "        #Plot results\n",
    "        n,_ = theta_lasso_cd.shape\n",
    "        fig,ax = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(10,5))\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[0].plot(lamda, theta_lasso_cd[i])#,label = K[:,i])\n",
    "\n",
    "        ax[0].set_xscale('log')\n",
    "        ax[0].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[0].set_ylabel('Coefficients')\n",
    "        ax[0].set_title('Coordinate descent')\n",
    "        plt.axis('tight')\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[1].plot(lamda, theta_lasso_gd[i])#label = K[:,i])\n",
    "\n",
    "        ax[1].set_xscale('log')\n",
    "        ax[1].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[1].set_title('Gradient descent')\n",
    "        plt.axis('tight')\n",
    "\n",
    "        for i in range(10):\n",
    "            ax[2].plot(lamda, theta_lasso_cg[i])#label = K[:,i])\n",
    "\n",
    "        ax[2].set_xscale('log')\n",
    "        ax[2].set_xlabel('Log($\\\\lambda$)')\n",
    "        ax[2].set_title('Conjugate gradient descent')\n",
    "        plt.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "n,_ = theta_lasso_cd.shape\n",
    "fig,ax = plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(10,5))\n",
    "\n",
    "for i in range(10):\n",
    "    ax[0].plot(lamda, theta_lasso_cd[i])#,label = K[:,i])\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[0].set_ylabel('Coefficients')\n",
    "ax[0].set_title('Coordinate descent')\n",
    "plt.axis('tight')\n",
    "\n",
    "for i in range(10):\n",
    "    ax[1].plot(lamda, theta_lasso_gd[i])#label = K[:,i])\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[1].set_title('Gradient descent')\n",
    "plt.axis('tight')\n",
    "\n",
    "for i in range(10):\n",
    "    ax[2].plot(lamda, theta_lasso_cg[i])#label = K[:,i])\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].set_xlabel('Log($\\\\lambda$)')\n",
    "ax[2].set_title('Conjugate gradient descent')\n",
    "plt.axis('tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
