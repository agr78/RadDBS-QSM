{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from scipy.stats import linregress\n",
    "import smogn\n",
    "import pandas\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from notebook import notebookapp\n",
    "from numpy import matlib\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from util import pyvis\n",
    "from util import extract\n",
    "from loader import data_loader\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "import smogn\n",
    "from smogn.phi import phi\n",
    "from smogn.phi_ctrl_pts import phi_ctrl_pts\n",
    "import warnings\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/data/Ali/RadDBS-QSM/src/jupyter/pickles/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/data/Ali/RadDBS-QSM/src/csv/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/media/mts_dbs/dbs/all/npy/'\n",
    "phi_dir = '/media/mts_dbs/dbs/all/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "K_all_c = K_all[c_cases_idx,:,:]\n",
    "R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,train_index,test_index = util.set_split(X_all_c,per_change,1,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_tt,scaler0 = util.make_feature_matrix(X_all_c,pre_updrs_off)\n",
    "X0_t = X0_tt.reshape(X_all_c.shape[0],X_all_c.shape[1],X_all_c.shape[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LarsCV\n",
    "n = X0_t.shape[0]\n",
    "def loop(j):\n",
    "        # Reload training data\n",
    "        X_in = X0_t[:n,:,:]\n",
    "        per_change_in = per_change[:n]\n",
    "        pre_updrs_off_in = pre_updrs_off[:n]\n",
    "        # Delete test case\n",
    "        X_in = np.delete(X_in,j,axis=0)\n",
    "        pre_updrs_off_in = np.delete(pre_updrs_off[:n],j)\n",
    "        per_change_in = np.delete(per_change[:n],j)\n",
    "        # Concatenate pre-updrs, scale, and reshape\n",
    "        X_in_t = X_in.reshape(X_in.shape[0],X_in.shape[1]*X_in.shape[2]) #scaler = util.make_feature_matrix(X_in,pre_updrs_off_in)\n",
    "        # Perform SMOGN on training data\n",
    "        # VERIFY threshold default\n",
    "        # X_in_s,y_in_s,idx_kept,sscaler = util.rad_smogn(X0_tt,per_change.ravel(),\n",
    "        #                                                 np.min(per_change),\n",
    "        #                                                 np.max(per_change),\n",
    "        #                                                 np.mean(per_change),1,0,0.5,'extreme')\n",
    "        # X_in_s = np.delete(X_in_s,j,axis=0)\n",
    "        # y_in_s = np.delete(y_in_s,j,axis=0)\n",
    "        # Rescale synthetic feature matrices and test feature matrix together\n",
    "        # scalerj = StandardScaler()\n",
    "        # X_s = scalerj.fit_transform(np.vstack((X_in_s,X0_t[j,:,:].reshape(X0_t.shape[1]*X0_t.shape[2]))))\n",
    "        # X_test = X_s[-1,:]\n",
    "        # X_train = X_s[:-1,:]\n",
    "        # Fit\n",
    "        cvs = KFold(n_splits=X_in.shape[0],shuffle=True)\n",
    "        # Specify epsilon at 0.5\n",
    "        reg = LarsCV(max_iter=10000,cv=cvs,verbose=True).fit(X_in,per_change_in)\n",
    "        # Predict\n",
    "        X_test = X0_tt[j,:]#util.scale_feature_matrix(np.expand_dims(X0_t[j,:,:],axis=0),pre_updrs_off[j],sscaler)\n",
    "        ut_ls = reg.predict(X_test.reshape(1, -1))\n",
    "        print('Predicted improvement of ',ut_ls, 'with true improvement', per_change[j])\n",
    "        return ut_ls\n",
    "pool = Pool(os.cpu_count())\n",
    "packet = [*zip(np.arange(n))]\n",
    "results = pool.map(loop,np.arange(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 6\n",
    "# def loop(j):\n",
    "#         # Reload training data\n",
    "#         X_in = X0_t[:n,:,:]\n",
    "#         per_change_in = per_change[:n]\n",
    "#         pre_updrs_off_in = pre_updrs_off[:n]\n",
    "#         # Delete test case\n",
    "#         X_in = np.delete(X_in,j,axis=0)\n",
    "#         pre_updrs_off_in = np.delete(pre_updrs_off[:n],j)\n",
    "#         per_change_in = np.delete(per_change[:n],j)\n",
    "#         # Concatenate pre-updrs, scale, and reshape\n",
    "#         X_in_t,scaler = util.make_feature_matrix(X_in,pre_updrs_off_in)\n",
    "#         # Perform SMOGN on training data\n",
    "#         # VERIFY threshold default\n",
    "#         X_in_s,y_in_s,idx_kept,sscaler = util.rad_smogn(X_in_t[:,:-6],per_change_in,\n",
    "#                                                         np.min(per_change_in),\n",
    "#                                                         np.max(per_change_in),\n",
    "#                                                         np.mean(per_change_in),1,0,0.5)\n",
    "#         # Fit\n",
    "#         cvs = KFold(n_splits=X_in_s.shape[0],shuffle=True)\n",
    "#         reg = LassoCV(max_iter=10000,cv=cvs,eps=0.5,verbose=True).fit(X_in_s,y_in_s)\n",
    "#         # Predict\n",
    "#         X_test = util.scale_feature_matrix(np.expand_dims(X0_t[j,:,:],axis=0),pre_updrs_off[j],scaler)\n",
    "#         print(X_test.shape)\n",
    "#         ut_ls = reg.predict(X_test[:-6].reshape(1, -1))\n",
    "#         print('Predicted improvement of ',ut_ls, 'with true improvement', per_change[j])\n",
    "#         return ut_ls\n",
    "# pool = Pool(os.cpu_count())\n",
    "# packet = [*zip(np.arange(n))]\n",
    "# results = pool.map(loop,np.arange(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 6\n",
    "# ut_ls = np.zeros(n)\n",
    "# def loop(j):\n",
    "#         # Reload training data\n",
    "#         X_in = X0_t[:n,:,:]\n",
    "#         print(X_in.shape)\n",
    "#         per_change_in = per_change[:n]\n",
    "#         pre_updrs_off_in = pre_updrs_off[:n]\n",
    "#         # Delete test case\n",
    "#         X_in = np.delete(X_in,j,axis=0)\n",
    "#         print(X_in.shape)\n",
    "#         print(j)\n",
    "#         pre_updrs_off_in = np.delete(pre_updrs_off[:n],j)\n",
    "#         per_change_in = np.delete(per_change[:n],j)\n",
    "#         print(pre_updrs_off_in.shape)\n",
    "#         # Concatenate pre-updrs, scale, and reshape\n",
    "#         X_in_t,scaler = util.make_feature_matrix(X_in,pre_updrs_off_in)\n",
    "#         print(X_in_t.shape)\n",
    "#         # Perform SMOGN on training data\n",
    "#         # VERIFY threshold default\n",
    "#         X_in_s,y_in_s,idx_kept,sscaler = util.rad_smogn(X_in_t[:,:-6],per_change_in,\n",
    "#                                                         np.min(per_change_in),\n",
    "#                                                         np.max(per_change_in),\n",
    "#                                                         np.mean(per_change_in),1,0,0.5)\n",
    "#         # Fit\n",
    "#         cvs = KFold(n_splits=X_in_s.shape[0],shuffle=True)\n",
    "#         reg = LassoCV(max_iter=10000,cv=cvs,eps=0.5,verbose=True,n_jobs=-1).fit(X_in_s,y_in_s)\n",
    "#         # Predict\n",
    "#         print(X0_t[j,:,:].shape)\n",
    "#         X_test = util.scale_feature_matrix(np.expand_dims(X0_t[j,:,:],axis=0),pre_updrs_off[j],scaler)\n",
    "#         print(X_test.shape)\n",
    "#         ut_ls = reg.predict(X_test[:-6].reshape(1, -1))\n",
    "#         print('Predicted improvement of ',ut_ls, 'with true improvement', per_change[j])\n",
    "#         return ut_ls\n",
    "# pool = Pool(os.cpu_count())\n",
    "# packet = [*zip(np.arange(n))]\n",
    "# for k in np.arange(n): \n",
    "#           ut_ls[k] = loop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "# Cross validation results\n",
    "[fig,ax] = plt.subplots(1,2,sharex=True, sharey=True)\n",
    "lr_prepost = linregress(pre_imp[:n],per_change[:n])\n",
    "ax[0].scatter(pre_imp[:n],per_change[:n],)\n",
    "ax[0].plot(pre_imp[:n],pre_imp[:n]*lr_prepost.slope+lr_prepost.intercept,'-r')\n",
    "ax[0].set_title('LCT')\n",
    "ax[0].set_ylabel(\"DBS improvement\")\n",
    "ax[0].set_xlabel(\"Prediction\")\n",
    "# ax[0].set_ylim([0, 1])\n",
    "# ax[0].set_xlim([0, 1])\n",
    "text = f\"$y={lr_prepost.slope:0.3f}\\;x{lr_prepost.intercept:+0.3f}$\\n$r = {lr_prepost.rvalue:0.3f}$\\n$p = {lr_prepost.pvalue:0.3f}$\"\n",
    "ax[0].text(0.35, 0.25, text,transform=ax[0].transAxes,\n",
    "     fontsize=14, verticalalignment='top')\n",
    "ax[0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "\n",
    "lr_pred_qr = linregress(np.asarray(results).ravel(),per_change[:n])\n",
    "ax[1].scatter(np.asarray(results).ravel(),per_change[:n])\n",
    "ax[1].plot(np.asarray(results).ravel(),np.asarray(results).ravel()*lr_pred_qr.slope+lr_pred_qr.intercept,'-r')\n",
    "ax[1].set_title('LASSO with SMOGN')\n",
    "ax[1].set_ylabel(\"DBS improvement\")\n",
    "ax[1].set_xlabel(\"Prediction\")\n",
    "text = f\"$y={lr_pred_qr.slope:0.3f}\\;x{lr_pred_qr.intercept:+0.3f}$\\n$r = {lr_pred_qr.rvalue:0.3f}$\\n$p = {lr_pred_qr.pvalue:0.10f}$\"\n",
    "ax[1].text(0.35, 0.25, text,transform=ax[1].transAxes,\n",
    "     fontsize=14, verticalalignment='top')\n",
    "ax[1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
