{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "import sklearn.pipeline as spl\n",
    "import sklearn.kernel_ridge as skr\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.neural_network as snn\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.decomposition as sdc\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "from sklearn.utils import resample\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "#     Performed poorly using Standard and MinMax scalers. Trying with LOOCV to see if predictions stabilize.\n",
    "#     Does not appear to stabilize predictions with LOOCV (using StandardScaler())\n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function?\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 1000 slices\n",
      "Appended 2000 slices\n",
      "Appended 3000 slices\n",
      "Appended 4000 slices\n",
      "Appended 5000 slices\n",
      "Appended 6000 slices\n",
      "Allocated arrays\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs_init,pre_imp_init,post_imp_init,pre_updrs_off_init = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/slices/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/slices/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,939,True)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs_init).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "# K_all_c = K_all[c_cases_idx,:,:]\n",
    "# R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs_init,ids[c_cases_idx])\n",
    "subs_init = subs_init[s_cases_idx]\n",
    "pre_imp_init = pre_imp_init[s_cases_idx]\n",
    "post_imp_init = post_imp_init[s_cases_idx]\n",
    "pre_updrs_off_init = pre_updrs_off_init[s_cases_idx]\n",
    "per_change_init = post_imp_init\n",
    "subs = np.asarray(ID_all,dtype=float)[np.in1d(np.asarray(ID_all,dtype=float),subs_init)]\n",
    "subsc = subs\n",
    "pre_imp = np.zeros((1,len(subs))).T\n",
    "post_imp = np.zeros((1,len(subs))).T\n",
    "pre_updrs_off = np.zeros((1,len(subs))).T\n",
    "per_change = np.zeros((1,len(subs))).T\n",
    "for j in np.arange(len(subs)):\n",
    "    pre_imp[j] = pre_imp_init[subs_init == subs[j]]\n",
    "    post_imp[j] = post_imp_init[subs_init == subs[j]]\n",
    "    pre_updrs_off[j] = pre_updrs_off_init[subs_init == subs[j]]\n",
    "    per_change[j] = per_change_init[subs_init == subs[j]]\n",
    "\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_en = np.zeros_like(per_change)\n",
    "results_mlp = np.zeros_like(per_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso predicts [0.72594711] with regularization 0.006823313583042418 for case 1.0 with actual improvement [0.83076923]\n",
      "Lasso predicts [0.52012964] with regularization 0.010003793771010532 for case 2.0 with actual improvement [0.90909091]\n",
      "Lasso predicts [0.64509633] with regularization 0.004742222809976233 for case 3.0 with actual improvement [0.55555556]\n",
      "Lasso predicts [0.71107172] with regularization 0.006553959885338278 for case 6.0 with actual improvement [0.95238095]\n",
      "Lasso predicts [0.71451823] with regularization 0.006722728380966948 for case 9.0 with actual improvement [0.88888889]\n",
      "Lasso predicts [0.55999933] with regularization 0.006257328043364847 for case 10.0 with actual improvement [0.59259259]\n",
      "Lasso predicts [0.69572006] with regularization 0.00620317436730984 for case 11.0 with actual improvement [0.73684211]\n",
      "Lasso predicts [0.63133886] with regularization 0.005033319874095925 for case 12.0 with actual improvement [0.5]\n",
      "Lasso predicts [0.68303593] with regularization 0.005832890204043254 for case 13.0 with actual improvement [0.7037037]\n",
      "Lasso predicts [0.74426128] with regularization 0.006276228491630495 for case 15.0 with actual improvement [0.68656716]\n",
      "Lasso predicts [0.57690828] with regularization 0.006736779042702262 for case 16.0 with actual improvement [0.87878788]\n",
      "Lasso predicts [0.55756014] with regularization 0.0059216677538481335 for case 20.0 with actual improvement [0.66666667]\n",
      "Lasso predicts [0.66433277] with regularization 0.007209048391148052 for case 25.0 with actual improvement [0.7]\n",
      "Lasso predicts [0.77256564] with regularization 0.007445761891110989 for case 26.0 with actual improvement [0.88311688]\n",
      "Lasso predicts [0.63123427] with regularization 0.007287698266434002 for case 27.0 with actual improvement [0.74418605]\n",
      "Lasso predicts [0.68766209] with regularization 0.008099719024220166 for case 29.0 with actual improvement [0.80357143]\n",
      "Lasso predicts [0.58561781] with regularization 0.006373519072204327 for case 32.0 with actual improvement [0.66666667]\n",
      "Lasso predicts [0.82492397] with regularization 0.006063008597626374 for case 34.0 with actual improvement [0.69135802]\n",
      "Lasso predicts [0.56997952] with regularization 0.006515856286265271 for case 41.0 with actual improvement [0.42857143]\n",
      "Lasso predicts [0.60263499] with regularization 0.009830914635832057 for case 44.0 with actual improvement [0.1875]\n",
      "Lasso predicts [0.57308307] with regularization 0.005970097201593245 for case 45.0 with actual improvement [0.93939394]\n",
      "Lasso predicts [0.51365663] with regularization 0.004686496727067195 for case 46.0 with actual improvement [0.55555556]\n",
      "Lasso predicts [0.70062864] with regularization 0.008919639585581274 for case 52.0 with actual improvement [0.67241379]\n",
      "Lasso predicts [0.71382126] with regularization 0.00834862073268751 for case 54.0 with actual improvement [0.87301587]\n",
      "Lasso predicts [0.70358982] with regularization 0.006778580292997482 for case 58.0 with actual improvement [0.51724138]\n",
      "Lasso predicts [0.61365922] with regularization 0.0072946357155113705 for case 59.0 with actual improvement [0.74358974]\n",
      "Lasso predicts [0.53591849] with regularization 0.004547819128529894 for case 61.0 with actual improvement [0.84615385]\n",
      "Lasso predicts [0.73040973] with regularization 0.008317526267120642 for case 62.0 with actual improvement [0.46774194]\n",
      "Lasso predicts [0.58359773] with regularization 0.009565586601257085 for case 63.0 with actual improvement [0.85294118]\n",
      "Lasso predicts [0.73752127] with regularization 0.0063747353968728075 for case 64.0 with actual improvement [0.66153846]\n",
      "Lasso predicts [0.58873448] with regularization 0.008096932261154759 for case 66.0 with actual improvement [0.53125]\n",
      "Lasso predicts [0.71975627] with regularization 0.007118542189217958 for case 67.0 with actual improvement [0.48333333]\n",
      "Lasso predicts [0.6863351] with regularization 0.005785348769029061 for case 68.0 with actual improvement [0.74545455]\n",
      "Lasso predicts [0.60312823] with regularization 0.00749962598132624 for case 69.0 with actual improvement [0.48571429]\n",
      "Lasso predicts [0.64519807] with regularization 0.006278427318333028 for case 71.0 with actual improvement [0.76086957]\n",
      "Lasso predicts [0.56937839] with regularization 0.0059421120147371475 for case 72.0 with actual improvement [0.26086957]\n",
      "Lasso predicts [0.71396064] with regularization 7.075797506418865e-05 for case 75.0 with actual improvement [0.96774194]\n",
      "Lasso predicts [0.7087052] with regularization 0.005485014060412137 for case 77.0 with actual improvement [0.55932203]\n",
      "Lasso predicts [0.61724402] with regularization 0.005502643788052353 for case 78.0 with actual improvement [0.825]\n",
      "Lasso predicts [0.57044848] with regularization 0.007763027777110492 for case 79.0 with actual improvement [0.65517241]\n",
      "Lasso predicts [0.64048994] with regularization 0.004717795927291655 for case 80.0 with actual improvement [0.52272727]\n",
      "Lasso predicts [0.61471135] with regularization 0.00500416130575017 for case 81.0 with actual improvement [0.19444444]\n",
      "Lasso predicts [0.69091419] with regularization 0.00045967799238006904 for case 83.0 with actual improvement [0.83928571]\n",
      "Lasso predicts [0.60695939] with regularization 0.004919388309057151 for case 85.0 with actual improvement [0.14705882]\n",
      "Lasso predicts [0.70542731] with regularization 0.00553232992784204 for case 86.0 with actual improvement [0.5]\n",
      "Lasso predicts [0.61004763] with regularization 0.004982562948655862 for case 87.0 with actual improvement [0.08571429]\n",
      "Lasso predicts [0.61839971] with regularization 0.0057308953115600796 for case 89.0 with actual improvement [0.35897436]\n"
     ]
    }
   ],
   "source": [
    "for j in np.arange(len(subsc)):\n",
    "    # Split the data\n",
    "    Js = []\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    # Cross validation\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,test_index,pre_updrs_off.ravel())\n",
    "\n",
    "    # Feature selection\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        sel = skf.SelectKBest(skf.r_regression,k=2000)\n",
    "        X0_ss = sel.fit_transform(X0_ss0,y_train.ravel())\n",
    "        X_test_ss = sel.transform(X_test_ss0.reshape([X_test_ss0.shape[0],\n",
    "                                                X_test_ss0.shape[1]*X_test_ss0.shape[2]]))\n",
    "    \n",
    "    # Nx = np.random.normal(0,np.var(y_train),X0_ss.shape)\n",
    "    # Ny = np.random.normal(0,np.var(y_train),y_train.shape)\n",
    "    # LASSO\n",
    "    lasso = slm.LassoCV(max_iter=1e4,n_jobs=-1,verbose=False) \n",
    "    est_ls = lasso.fit(X0_ss,y_train.ravel())\n",
    "    results_ls[j] = np.mean(est_ls.predict(X_test_ss))\n",
    "\n",
    "    # ElasticNet\n",
    "    en = slm.ElasticNetCV(max_iter=1e4,n_jobs=-1,verbose=False) \n",
    "    est_en = en.fit(X0_ss,y_train.ravel())\n",
    "    results_en[j] = np.mean(est_en.predict(X_test_ss))\n",
    "\n",
    "    # # Output results\n",
    "    if test_id != subsc[j+1]:\n",
    "        print('Lasso predicts',str(results_ls[j]),'with regularization',\n",
    "            str(est_ls.alpha_),'for case',str(test_id),'with actual improvement',str(per_change[j]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_en,\n",
    "                               results_ls)),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'ElasticNet',\n",
    "                                'Lasso',\n",
    "                                ],(30,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
