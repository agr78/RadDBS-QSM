{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary data notebook for\n",
    "# NIH: Imaging Guided Intervention Surgery Study Section\n",
    "\n",
    "# Exploratory aim: evaluate presurgical scans between STN and GPi targets\n",
    "#   Given retrospective GPi acquisitions?\n",
    "#   Search for radiomic differentiators for STN versus GPi selection in presurgical scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from time import time\n",
    "from joblib import Memory\n",
    "from joblib import parallel_backend\n",
    "from scipy import sparse\n",
    "from scipy import linalg\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "import tempfile\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.cluster import ward_tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "from radiomics import imageoperations\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import os\n",
    "import pywt\n",
    "from util import IndexTracker\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\dbs\\outcome_predictor\\snrn_cases\\044\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\046\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\040\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\029\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\032\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\039\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\012\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\007\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\001\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\047\n",
      "F:\\dbs\\outcome_predictor\\snrn_cases\\034\n"
     ]
    }
   ],
   "source": [
    "# Set window level\n",
    "level = 0\n",
    "window = 500\n",
    "m1=level-window/2\n",
    "m2=level+window/2\n",
    "\n",
    "# Load data\n",
    "# fig, ax = plt.subplots(2,5)\n",
    "segs = []\n",
    "qsms = []\n",
    "voxel_sizes = []\n",
    "trackers = []\n",
    "directory = 'F:\\dbs\\outcome_predictor\\snrn_cases'\n",
    "case_list = []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory,filename)\n",
    "    print(f)\n",
    "    # Training cases\n",
    "    if '47' not in filename:\n",
    "        try:\n",
    "            seg = nib.load(f+'/seg.nii')\n",
    "        except:\n",
    "            seg = nib.load(f+'/seg.nii.gz')\n",
    "            \n",
    "        voxel_size = seg.header['pixdim'][0:3]\n",
    "        voxel_sizes.append(voxel_size)\n",
    "        segs.append(seg.get_fdata())\n",
    "\n",
    "        try:\n",
    "            qsm = nib.load(f+'/qsm.nii')\n",
    "        except:\n",
    "            qsm = nib.load(f+'/qsm.nii.gz')\n",
    "        qsms.append(qsm.get_fdata())\n",
    "    # Test case\n",
    "    else:\n",
    "        try:\n",
    "            seg_t = nib.load(f+'/seg.nii')\n",
    "        except:\n",
    "            seg_t = nib.load(f+'/seg.nii.gz')\n",
    "        voxel_size_t = seg_t.header['pixdim'][0:3]\n",
    "        try:\n",
    "            qsm_t = nib.load(f+'/qsm.nii')\n",
    "        except:\n",
    "            qsm_t = nib.load(f+'/qsm.nii.gz')\n",
    "    case_list.append(filename)\n",
    "    n_cases = len(segs)\n",
    "# qsm_plots = qsms\n",
    "# seg_plots = segs\n",
    "# qsm_plots.append(qsm_t.get_fdata())\n",
    "# seg_plots.append(seg_t.get_fdata())\n",
    "# count = 1\n",
    "# r1_col_idx = 0\n",
    "# r2_col_idx = 0\n",
    "# for cases in range(n_cases-1):\n",
    "#     # Set window/level\n",
    "#     seg_tmp = seg_plots[count-1]\n",
    "#     seg_tmp[seg_tmp>0] = 1\n",
    "#     qsm_tmp = qsm_plots[count-1]\n",
    "#     qsm_tmp[qsm_tmp<m1] = m1\n",
    "#     qsm_tmp[qsm_tmp>m2] = m2\n",
    "#     if np.mod(n_cases-1,count) == 0 or np.mod(n_cases-1,count)>3:\n",
    "#         trackers.append(IndexTracker(ax[0][r1_col_idx],seg_tmp))\n",
    "#         fig.canvas.mpl_connect('scroll_event', trackers[count-1].onscroll)   \n",
    "#         ax[0][r1_col_idx].set_title(case_list[count-1])\n",
    "#         r1_col_idx = r1_col_idx+1\n",
    "#     else:\n",
    "#         trackers.append(IndexTracker(ax[1][r2_col_idx],seg_tmp))\n",
    "#         fig.canvas.mpl_connect('scroll_event', trackers[count-1].onscroll)   \n",
    "#         ax[1][r2_col_idx].set_title(case_list[count-1])\n",
    "#         r2_col_idx = r2_col_idx+1\n",
    "#     count = count+1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parameter force2D must be set to True to enable shape2D extraction\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n",
      "Calculating Local Binary Pattern in 2D, but extracting features in 3D. Use with caution!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37712\\2967109020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Create separate feature vector for test case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfeatureVector_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqsm_t_sitk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseg_t_sitk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Training cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\radiomics\\featureextractor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, imageFilepath, maskFilepath, label, label_channel, voxelBased)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Extracting features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# Calculate features for all (filtered) images in the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0minputImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageTypeName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputKwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimageGenerators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m       \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calculating features for %s image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageTypeName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m       \u001b[0minputImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputMask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageoperations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcropToTumorMask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundingBox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadDistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernelRadius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\radiomics\\imageoperations.py\u001b[0m in \u001b[0;36mgetLBP2DImage\u001b[1;34m(inputImage, inputMask, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[0mim_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbp_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m       \u001b[0mim_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_binary_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbp_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbp_radius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlbp_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m     \u001b[0mim_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbp_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mNd\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\agr78\\Anaconda3\\envs\\pdradenv\\lib\\site-packages\\skimage\\feature\\texture.py\u001b[0m in \u001b[0;36mlocal_binary_pattern\u001b[1;34m(image, P, R, method)\u001b[0m\n\u001b[0;32m    341\u001b[0m     }\n\u001b[0;32m    342\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_local_binary_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate feature structure Phi from all ROIs and all cases\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.enableAllFeatures()\n",
    "extractor.enableAllImageTypes()\n",
    "Phi = []\n",
    "seg_t_sitk = sitk.GetImageFromArray(seg_t.get_fdata())\n",
    "seg_t_sitk.SetSpacing(voxel_size_t.tolist())\n",
    "qsm_t_sitk = sitk.GetImageFromArray(qsm_t.get_fdata())\n",
    "qsm_t_sitk.SetSpacing(voxel_size_t.tolist())\n",
    "# Create separate feature vector for test case\n",
    "for j in range(1,int(np.max(segs[0]))+1):\n",
    "    featureVector_t = extractor.execute(qsm_t_sitk,seg_t_sitk,label=j)\n",
    "\n",
    "# Training cases\n",
    "for i in range(n_cases):\n",
    "    seg_sitk = sitk.GetImageFromArray(segs[i])\n",
    "    seg_sitk.SetSpacing(voxel_sizes[i].tolist())\n",
    "    qsm_sitk = sitk.GetImageFromArray(qsms[i])\n",
    "    qsm_sitk.SetSpacing(voxel_sizes[i].tolist())\n",
    "    for j in range(1,int(np.max(segs[i]))+1):\n",
    "        featureVector = extractor.execute(qsm_sitk,seg_sitk,label=j)\n",
    "        Phi.append(featureVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric feature values\n",
    "n_ROIs = int(np.max(segs[i]))\n",
    "x_row = []\n",
    "loop_count = 0\n",
    "for i in range(Phi.__len__()):\n",
    "        featureVector = Phi[i]\n",
    "        loop_count = loop_count+1\n",
    "        for key, value in six.iteritems(featureVector):\n",
    "            if 'diagnostic' in key:\n",
    "                next\n",
    "            else:\n",
    "                x_row.append(value)\n",
    "X0 = np.array(x_row)\n",
    "\n",
    "# Test case\n",
    "x_row_t = []\n",
    "for j in range(int(np.max(segs[0]))):\n",
    "        featureVector = featureVector_t\n",
    "        loop_count = loop_count+1\n",
    "        for key, value in six.iteritems(featureVector):\n",
    "            if 'diagnostic' in key:\n",
    "                next\n",
    "            else:\n",
    "                x_row_t.append(value)\n",
    "X0_t = np.array(x_row_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature matrix X\n",
    "X = X0.reshape((n_cases,int(len(X0)/n_cases)))\n",
    "fig,ax = plt.subplots(2,1)\n",
    "plt.style.use('dark_background')\n",
    "im0 = ax[0].imshow(X[:,0:100])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[0].set_title('Initial feature matrix')\n",
    "ax[0].set_xlabel('Feature index')\n",
    "ax[0].set_ylabel('Case')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im0, cax=cax, orientation='vertical')\n",
    "# Normalize testing and training cases together\n",
    "#   Otherwise the scale during clf.predict() is wrong\n",
    "#   Set with_mean=False to preserve data sparsity\n",
    "#   And with_std=False \n",
    "#   However, need a significant number of samples to do this\n",
    "scaler = StandardScaler()\n",
    "X_all = np.vstack((X,X0_t))\n",
    "X_all_t = scaler.fit_transform(X_all)\n",
    "X_t = X_all_t[X.shape[0]:,:]\n",
    "X = X_all_t[:X.shape[0]]\n",
    "im1 = ax[1].imshow(X[:,0:100])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlabel('Feature index')\n",
    "ax[1].set_ylabel('Case')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im1, cax=cax, orientation='vertical')\n",
    "ax[1].set_title('Standardized feature matrix')\n",
    "plt.suptitle('Feature matrix $X$');\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDRS targets\n",
    "#   Must be ordered according to list-generating loop\n",
    "#   Larger data arrays will need a text file in each directory\n",
    "#   So targets and inputs can be read simultaneously\n",
    "\n",
    "u = np.array([[3,10,24,2],\n",
    "[1,3,18,2],\n",
    "[2,10,26,8],\n",
    "[3,3,25,0],\n",
    "[0,0,13,0],\n",
    "[0,10,33,4],\n",
    "[1,4,11,1],\n",
    "[0,7,25,1],\n",
    "[0,1,24,1],\n",
    "[3,8,32,4]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for model selection\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    cv = KFold(X.shape[0])\n",
    "    cachedir = tempfile.mkdtemp()\n",
    "    mem = Memory(location=cachedir, verbose=1)\n",
    "\n",
    "    # Dimensionality reduction\n",
    "    ward = FeatureAgglomeration(n_clusters=1, linkage='ward',memory=mem)\n",
    "    # Feature selection\n",
    "    lasso = Lasso(alpha=0,fit_intercept=False,max_iter=100000,tol=0.001)\n",
    "    # Initialize classifier pipeline\n",
    "    clf_in = Pipeline([('ward',ward),('Lasso',SelectFromModel(estimator=lasso,threshold='mean')),('SVM',OneVsRestClassifier(lasso))])\n",
    "    # Select the optimal number of clusters with grid search\n",
    "    alphas = ((1e-9,1e-6,1e-3,10e0,10e1,10e2))\n",
    "    N_clusters = [100,1000]\n",
    "    clf = GridSearchCV(clf_in, {'ward__n_clusters': N_clusters,'Lasso__estimator__alpha' : alphas, 'SVM__estimator__alpha' : alphas}, n_jobs=1, cv=cv, scoring='accuracy')\n",
    "    ut = []\n",
    "    for k in range(u.shape[1]):\n",
    "        clf.fit(X,u[:,k])\n",
    "        # make predictions\n",
    "        ut.append(clf.best_estimator_.predict(X_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set best parameters from cross-validation\n",
    "# # Ward-Lasso w* of length reduced number of features in Xw\n",
    "\n",
    "# # Lasso w* of length of original number of features in X\n",
    "#coef_ = clf.best_estimator_.steps[0][1].inverse_transform(coef_lasso)\n",
    "\n",
    "X_SVM = clf.best_estimator_.steps[2][1].coef_;\n",
    "fig,ax = plt.subplots(1,1)\n",
    "im_svm = plt.imshow(X_SVM)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('Selected feature index')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Support vector machine weights');\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "plt.colorbar(im_svm,cax=cax,orientation='vertical')\n",
    "print(clf.best_estimator_.steps[2][1].n_classes_)\n",
    "print(X_SVM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Lasso = np.nonzero(clf.best_estimator_.steps[1][1].inverse_transform(X_SVM))\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plt.stem(X_Lasso[1][0:X_SVM.shape[1]])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('Selected feature index')\n",
    "plt.ylabel('Feature weight index')\n",
    "plt.title('Lasso feature weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.steps[1][1].inverse_transform(X_SVM).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward = FeatureAgglomeration(clf.best_estimator_.steps[0][1].n_clusters, linkage='ward',memory=mem)\n",
    "Xw = linkage(X_t.T,'ward')\n",
    "fig,ax = plt.subplots(1,1)\n",
    "dendrogram(Xw)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('Cluster index')\n",
    "plt.ylabel('Cluster variance')\n",
    "plt.title('Ward clustering of test feature matrix $X_t$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut0 = np.array((2,13,30,6))\n",
    "ut = np.array(ut).T\n",
    "u0 = np.mean(u,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE for the constructed estimator output '+str(ut)+ ' is '+ str(np.mean((ut0-ut)**2)))\n",
    "print('MSE for the sample mean '+str(np.round(u0))+ ' is '+ str(np.mean((ut0-u0)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MRE for the constructed estimator output ' + str(np.mean((abs(ut0-ut.T)/(ut0)),axis=1)))\n",
    "print('MRE for the sample mean ' + str(np.mean((abs(ut0-u0.T)/(ut0)),axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(clf.estimator.steps[2][1]))\n",
    "clf.best_estimator_.steps[2][1].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.steps[2][1].coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform.br import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "Xs = Xw.ravel()\n",
    "up = u[:,1]\n",
    "X0 = X[:,np.where(np.sort(Xs)[-1]==Xw)[0]]\n",
    "X1 = X[:,np.where(np.sort(Xs)[-2]==Xw)[0]]\n",
    "\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clfp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# title for the plots\n",
    "title = ('Decision surface of SVM by feature weight')\n",
    "# Set-up grid for plotting.\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "clfp = OneVsRestClassifier(Lasso(alpha=clf.best_estimator_.steps[1][1].estimator.alpha)).fit(np.hstack((X0,X1)),u[:,1])\n",
    "plot_contours(ax, clfp, xx, yy, cmap=plt.cm.viridis, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=u[:,1], cmap=plt.cm.viridis, s=20, edgecolors='k')\n",
    "ax.set_ylabel('$X_0$')\n",
    "ax.set_xlabel('$X_1$')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
