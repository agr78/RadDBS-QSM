{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53760/3179577717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;31m# Running the Pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_OF_WORKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqsms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import datetime\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "import radiomics\n",
    "from radiomics import featureextractor \n",
    "import os\n",
    "from os import cpu_count\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Parallel processing variables\n",
    "TEMP_DIR = '_TEMP'\n",
    "REMOVE_TEMP_DIR = True  # Remove temporary directory when results have been successfully stored into 1 file\n",
    "NUM_OF_WORKERS = cpu_count()-1  # Number of processors to use, keep one processor free for other work\n",
    "if NUM_OF_WORKERS < 1:  # in case only one processor is available, ensure that it is used\n",
    "  NUM_OF_WORKERS = 1\n",
    "HEADERS = None  # headers of all extracted features\n",
    "ROOT = '/media/mts_dbs/mclaro/pyradiomics_parallel'\n",
    "OUTPUTCSV = 'out_csvs'\n",
    "INPUTCSV = 'in_csvs'\n",
    "\n",
    "with open('./pickles/segs', \"rb\") as fp:  \n",
    "    segs = pickle.load(fp)\n",
    "\n",
    "with open('./pickles/qsms', \"rb\") as fp:  \n",
    "    qsms = pickle.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run(case):\n",
    "  global ROOT, TEMP_DIR\n",
    "  ptLogger = logging.getLogger('radiomics.batch')\n",
    "\n",
    "  feature_vector = OrderedDict(case)\n",
    "\n",
    "  try:\n",
    "    # set thread name to patient name\n",
    "    threading.current_thread().name = case['Patient']\n",
    "\n",
    "    filename = r'features_' + str(case['Reader']) + '_' + str(case['Patient']) + '.csv'\n",
    "    output_filename = os.path.join(ROOT, TEMP_DIR, filename)\n",
    "\n",
    "    if os.path.isfile(output_filename):\n",
    "      # Output already generated, load result (prevents re-extraction in case of interrupted process)\n",
    "      with open(output_filename, 'w') as outputFile:\n",
    "        reader = csv.reader(outputFile)\n",
    "        headers = reader.rows[0]\n",
    "        values = reader.rows[1]\n",
    "        feature_vector = OrderedDict(zip(headers, values))\n",
    "\n",
    "      ptLogger.info('Patient %s read by %s already processed...', case['Patient'], case['Reader'])\n",
    "\n",
    "    else:\n",
    "      t = datetime.now()\n",
    "\n",
    "      imageFilepath = case['Image']  # Required\n",
    "      maskFilepath = case['Mask']  # Required\n",
    "      label = case.get('Label', None)  # Optional\n",
    "\n",
    "      # Instantiate Radiomics Feature extractor\n",
    "      # Generate feature structure Phi from all ROIs and all cases\n",
    "      extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "      extractor.enableAllFeatures()\n",
    "      extractor.enableAllImageTypes()\n",
    "      extractor.enableFeatureClassByName('shape2D',enabled = False)\n",
    "\n",
    "\n",
    "      # Extract features\n",
    "      voxel_size = ((0.5,0.5,0.5))\n",
    "      seg_sitk = sitk.GetImageFromArray(segs[case])\n",
    "      seg_sitk.SetSpacing(voxel_size)\n",
    "      qsm_sitk_gt = sitk.GetImageFromArray(qsms[case])\n",
    "      qsm_sitk_gt.SetSpacing(voxel_size)\n",
    "      feature_vector.update(extractor.execute(qsm_sitk_gt, seg_sitk, label=label))\n",
    "\n",
    "      # Store results in temporary separate files to prevent write conflicts\n",
    "      # This allows for the extraction to be interrupted. Upon restarting, already processed cases are found in the\n",
    "      # TEMP_DIR directory and loaded instead of re-extracted\n",
    "      with open(output_filename, 'w') as outputFile:\n",
    "        writer = csv.DictWriter(outputFile, fieldnames=list(feature_vector.keys()), lineterminator='\\n')\n",
    "        writer.writeheader()\n",
    "        writer.writerow(feature_vector)\n",
    "\n",
    "      # Display message\n",
    "\n",
    "      delta_t = datetime.now() - t\n",
    "\n",
    "      ptLogger.info('Patient %s read by %s processed in %s', case['Patient'], case['Reader'], delta_t)\n",
    "\n",
    "  except Exception:\n",
    "    ptLogger.error('Feature extraction failed!', exc_info=True)\n",
    "\n",
    "  return feature_vector\n",
    "\n",
    "\n",
    "def _writeResults(featureVector):\n",
    "  global HEADERS, OUTPUTCSV\n",
    "\n",
    "  # Use the lock to prevent write access conflicts\n",
    "  try:\n",
    "    with open(OUTPUTCSV, 'a') as outputFile:\n",
    "      writer = csv.writer(outputFile, lineterminator='\\n')\n",
    "      if HEADERS is None:\n",
    "        HEADERS = list(featureVector.keys())\n",
    "        writer.writerow(HEADERS)\n",
    "\n",
    "      row = []\n",
    "      for h in HEADERS:\n",
    "        row.append(featureVector.get(h, \"N/A\"))\n",
    "      writer.writerow(row)\n",
    "  except Exception:\n",
    "    logging.getLogger('radiomics.batch').error('Error writing the results!', exc_info=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  logger = logging.getLogger('radiomics.batch')\n",
    "\n",
    "  # Ensure the entire extraction is handled on 1 thread\n",
    "  #####################################################\n",
    "\n",
    "  sitk.ProcessObject_SetGlobalDefaultNumberOfThreads(1)\n",
    "\n",
    "  # Set up the pool processing\n",
    "  ############################\n",
    "\n",
    "  logger.info('pyradiomics version: %s', radiomics.__version__)\n",
    "  logger.info('Loading CSV...')\n",
    "\n",
    "  # Extract List of cases\n",
    "  cases = np.arange(segs.__len__())\n",
    "\n",
    "\n",
    "  logger.info('Loaded %d jobs', len(qsms))\n",
    "\n",
    "  # Make output directory if necessary\n",
    "  if not os.path.isdir(os.path.join(ROOT, TEMP_DIR)):\n",
    "    logger.info('Creating temporary output directory %s', os.path.join(ROOT, TEMP_DIR))\n",
    "    os.mkdir(os.path.join(ROOT, TEMP_DIR))\n",
    "\n",
    "  # Start parallel processing\n",
    "  ###########################\n",
    "\n",
    "  logger.info('Starting parralel pool with %d workers out of %d CPUs', NUM_OF_WORKERS, cpu_count())\n",
    "  # Running the Pool\n",
    "  pool = Pool(NUM_OF_WORKERS)\n",
    "  results = pool.map(run, qsms)\n",
    "\n",
    "  try:\n",
    "    # Store all results into 1 file\n",
    "    with open(OUTPUTCSV, mode='w') as outputFile:\n",
    "      writer = csv.DictWriter(outputFile,\n",
    "                              fieldnames=list(results[0].keys()),\n",
    "                              restval='',\n",
    "                              extrasaction='raise',  # raise error when a case contains more headers than first case\n",
    "                              lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(results)\n",
    "\n",
    "    if REMOVE_TEMP_DIR:\n",
    "      logger.info('Removing temporary directory %s (contains individual case results files)',\n",
    "                  os.path.join(ROOT, TEMP_DIR))\n",
    "      shutil.rmtree(os.path.join(ROOT, TEMP_DIR))\n",
    "  except Exception:\n",
    "    logger.error('Error storing results into single file!', exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
