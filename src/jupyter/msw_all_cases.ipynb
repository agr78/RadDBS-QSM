{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary data notebook for\n",
    "# NIH: Imaging Guided Intervention Surgery Study Section\n",
    "\n",
    "# Exploratory aim: evaluate presurgical scans between STN and GPi targets\n",
    "#   Given retrospective GPi acquisitions?\n",
    "#   Search for radiomic differentiators for STN versus GPi selection in presurgical scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import smogn\n",
    "import pandas\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from notebook import notebookapp\n",
    "from numpy import matlib\n",
    "from scipy import ndimage\n",
    "from util import pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending arrays with segmentation labels2_iMag01.nii.gz and QSM qsm_01.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag02.nii.gz and QSM qsm_02.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag03.nii.gz and QSM qsm_03.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag06.nii.gz and QSM qsm_06.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag09.nii.gz and QSM qsm_09.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag10.nii.gz and QSM qsm_10.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag11.nii.gz and QSM qsm_11.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag12.nii.gz and QSM qsm_12.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag13.nii.gz and QSM qsm_13.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag15.nii.gz and QSM qsm_15.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag16.nii.gz and QSM qsm_16.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag20.nii.gz and QSM qsm_20.nii.gz\n",
      "Skipping missing case 25\n",
      "Appending arrays with segmentation labels2_iMag26.nii.gz and QSM qsm_26.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag27.nii.gz and QSM qsm_27.nii.gz\n",
      "Skipping missing case 28\n",
      "Appending arrays with segmentation labels2_iMag29.nii.gz and QSM qsm_29.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag32.nii.gz and QSM qsm_32.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag34.nii.gz and QSM qsm_34.nii.gz\n",
      "Skipping missing case 35\n",
      "Appending arrays with segmentation labels2_iMag41.nii.gz and QSM qsm_41.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag44.nii.gz and QSM qsm_44.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag45.nii.gz and QSM qsm_45.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag46.nii.gz and QSM qsm_46.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag52.nii.gz and QSM qsm_52.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag58.nii.gz and QSM qsm_58.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag62.nii.gz and QSM qsm_62.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag63.nii.gz and QSM qsm_63.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag64.nii.gz and QSM qsm_64.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag65.nii.gz and QSM qsm_65.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag66.nii.gz and QSM qsm_66.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag67.nii.gz and QSM qsm_67.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag68.nii.gz and QSM qsm_68.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag69.nii.gz and QSM qsm_69.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag70.nii.gz and QSM qsm_70.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag71.nii.gz and QSM qsm_71.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag72.nii.gz and QSM qsm_72.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag75.nii.gz and QSM qsm_75.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag77.nii.gz and QSM qsm_77.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag78.nii.gz and QSM qsm_78.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag79.nii.gz and QSM qsm_79.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag80.nii.gz and QSM qsm_80.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag81.nii.gz and QSM qsm_81.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag83.nii.gz and QSM qsm_83.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag85.nii.gz and QSM qsm_85.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag86.nii.gz and QSM qsm_86.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag87.nii.gz and QSM qsm_87.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag89.nii.gz and QSM qsm_89.nii.gz\n",
      "Appending arrays with segmentation labels2_iMag90.nii.gz and QSM qsm_90.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Set window level\n",
    "level = 0\n",
    "window = 500\n",
    "m1=level-window/2\n",
    "m2=level+window/2\n",
    "visualize = 1\n",
    "reextract = 1\n",
    "reload = 0\n",
    "segs = []\n",
    "qsms = []\n",
    "laros = []\n",
    "voxel_sizes = []\n",
    "trackers = []\n",
    "q_directory = '/media/mts_dbs/dbs/complete_cases/nii/qsm/'\n",
    "s_directory = '/media/mts_dbs/dbs/complete_cases/nii/seg/'\n",
    "s_directory = os.listdir(s_directory)\n",
    "s_directory = sorted(s_directory)\n",
    "q_directory = os.listdir(q_directory)\n",
    "q_directory = sorted(q_directory)\n",
    "\n",
    "case_list = []\n",
    "d_count = 0\n",
    "if reload == 1:\n",
    "    for qsm_filename in q_directory:\n",
    "        id = qsm_filename[4:6]\n",
    "        seg_filepath = '/media/mts_dbs/dbs/complete_cases/nii/seg/labels_2iMag'+str(id)+'.nii.gz'\n",
    "        qsm_filepath = '/media/mts_dbs/dbs/complete_cases/nii/qsm/qsm_'+str(id)+'.nii.gz'\n",
    "        if os.path.isfile(qsm_filepath) and os.path.isfile(seg_filepath):\n",
    "  \n",
    "            qsm = nib.load('/media/mts_dbs/dbs/complete_cases/nii/qsm/'+qsm_filename)\n",
    "            seg = nib.load(seg_filepath)\n",
    "            voxel_size = seg.header['pixdim'][0:3]\n",
    "            voxel_sizes.append(voxel_size)\n",
    "            segs.append(seg.get_fdata())\n",
    "            qsms.append(qsm.get_fdata())\n",
    "            print('Appending arrays with segmentation','labels2_iMag'+str(id)+'.nii.gz','and QSM',qsm_filename)\n",
    "            case_list.append('qsm_'+str(id)+'.nii.gz')\n",
    "            n_cases = len(segs)\n",
    "            d_count = d_count+1\n",
    "            try:\n",
    "                next\n",
    "                # qsms_wl = np.asarray(qsms)\n",
    "                # segs_wl = np.asarray(segs)\n",
    "            except:\n",
    "                print('Failed to append QSM at case',str(id))\n",
    "            with open('./pickles/segs_all', 'wb') as fp:  \n",
    "                pickle.dump(segs, fp)\n",
    "\n",
    "            with open('./pickles/qsms_all', 'wb') as fp:  \n",
    "                pickle.dump(qsms, fp)\n",
    "        else:\n",
    "            print('Skipping missing case',str(id))\n",
    "\n",
    "else:\n",
    "    with open('/data/Ali/RadDBS-QSM/src/jupyter/pickles/segs_all', \"rb\") as fp:  \n",
    "        segs = pickle.load(fp)\n",
    "\n",
    "    with open('/data/Ali/RadDBS-QSM/src/jupyter/pickles/qsms_all', \"rb\") as fp:  \n",
    "        qsms = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791766003583574"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.power import FTestPower\n",
    "r2 = 0.9\n",
    "f2 = r2 / (1 - r2)\n",
    "f = np.sqrt(f2)\n",
    "r2, f2, f\n",
    "df1 = 50\n",
    "df2 = FTestPower().solve_power(effect_size=f, alpha=0.05, power=0.9,\n",
    "                                   df_denom=df1)\n",
    "ncc = 1  # default\n",
    "nobs = df2 + df1 + ncc\n",
    "df2, nobs\n",
    "\n",
    "FTestPower().power(effect_size=f, alpha=0.1, df_denom=df1, df_num=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize == 0:\n",
    "    qsms_wl = np.asarray(qsms)\n",
    "    segs_wl = np.asarray(segs)\n",
    "    qsms_wl[qsms_wl < m1] = m1\n",
    "    qsms_wl[qsms_wl > m2] = m2\n",
    "    n_cases = len(segs)\n",
    "    multi_slice_viewer(np.hstack(((np.vstack(qsms_wl[:n_cases//2,:,:,:]/1000+0*segs_wl[:n_cases//2,:,:,:]).T),\n",
    "                                  (np.vstack(qsms_wl[(n_cases-n_cases//2):,:,:,:]/1000+0*segs_wl[(n_cases-n_cases//2):,:,:,:]).T))))\n",
    "   \n",
    "                                    \n",
    "    label_min = np.partition(np.unique(seg.get_fdata().ravel()), 1)[1]\n",
    "    label_max = np.amax(seg.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '/data/Ali/RadDBS-QSM/src/csv'\n",
    "# Load patient data\n",
    "os.chdir(file_dir)\n",
    "df = pd.read_csv('QSM anonymus- 6.22.2023-1528.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "dfd = df.copy()\n",
    "# Drop blank columns\n",
    "for (columnName, columnData) in dfd.iteritems():\n",
    "    if columnData.isnull().all():\n",
    "        print('Dropping NaN column at',columnName)\n",
    "        dfd.drop(columnName,axis=1,inplace=True)\n",
    "# Add relevant column names from headers\n",
    "for (columnName, columnData) in dfd.iteritems():\n",
    "        dfd.rename(columns={columnName:columnName+': '+columnData.values[0]},inplace=True)\n",
    "\n",
    "def drop_prefix(self, prefix):\n",
    "    self.columns = self.columns.str.lstrip(prefix)\n",
    "    return self\n",
    "\n",
    "pd.core.frame.DataFrame.drop_prefix = drop_prefix\n",
    "\n",
    "dfd.drop_prefix('Unnamed:')        \n",
    "for (columnName, columnData) in dfd.iteritems():\n",
    "    if columnName[1].isdigit():\n",
    "        dfd.rename(columns={columnName:columnName[4:]},inplace=True)\n",
    "\n",
    "# Make a copy for motor symptoms\n",
    "motor_df = dfd.copy()\n",
    "# Drop non-motor (III) columns\n",
    "for (columnName, columnData) in motor_df.iteritems():\n",
    "    if 'pre-dbs updrs' in columnName:\n",
    "        next\n",
    "    elif 'stim' in columnName:\n",
    "        next\n",
    "    elif 'CORNELL ID' in columnName:\n",
    "        next\n",
    "    else:\n",
    "        motor_df.drop(columnName,axis=1,inplace=True)\n",
    "\n",
    "# Drop subheader\n",
    "motor_df = motor_df.tail(-1)\n",
    "motor_df = motor_df.replace('na',np.nan)\n",
    "motor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "for seg_filename in s_directory:\n",
    "    id.append(seg_filename[12:14])\n",
    "df_post_dbs_off_meds_on_stim = motor_df['OFF meds ON stim 6mo'].to_numpy().astype('float')\n",
    "df_post_dbs_off_meds_off_stim = motor_df[' off stim off med 6mo'].to_numpy().astype('float')\n",
    "df_pre_dbs_off_meds = motor_df['OFF (pre-dbs updrs)'].to_numpy().astype('float')\n",
    "df_pre_dbs_on_meds = motor_df['ON (pre-dbs updrs)'].to_numpy().astype('float')\n",
    "\n",
    "cases = ~np.isnan(df_pre_dbs_off_meds+df_pre_dbs_on_meds+df_post_dbs_off_meds_on_stim)\n",
    "pre_dbs_meds_improvement = (df_pre_dbs_off_meds[cases]-df_pre_dbs_on_meds[cases])/df_pre_dbs_off_meds[cases]\n",
    "dbs_off_meds_improvement = (df_pre_dbs_off_meds[cases]-df_post_dbs_off_meds_on_stim[cases])/df_pre_dbs_off_meds[cases]\n",
    "motor_df['CORNELL ID'].replace('only Ct data ', np.nan, inplace=True)\n",
    "pids = motor_df['CORNELL ID'].to_numpy().astype('float')\n",
    "subs = pids[cases]\n",
    "subs_in = (np.intersect1d(subs,np.asarray(id).astype(float)))\n",
    "df_pre_dbs_off_meds_in = df_pre_dbs_off_meds[cases]\n",
    "pre_dbs_off_meds_in = df_pre_dbs_off_meds_in[np.in1d(subs,np.asarray(id).astype(float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reextract == 1:\n",
    "    logger = logging.getLogger(\"radiomics\")\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Generate feature structure Phi from all ROIs and all cases\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "    extractor.enableAllFeatures()\n",
    "    extractor.enableAllImageTypes()\n",
    "    extractor.enableFeatureClassByName('shape2D',enabled = False)\n",
    "\n",
    "    roi_txt = pd.read_csv(\"/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv\")\n",
    "    roi_df = roi_txt.astype(str)\n",
    "    packet = [*zip(qsms,segs,subs_in,pre_dbs_off_meds_in)]\n",
    "    def extract(qsm,seg,sub_in,pre_dbs_off_meds_in):\n",
    "        fv_count = 0\n",
    "        seg_labels_all = [0,1,2,3,4,5,6,7]\n",
    "        Phi_gt = []\n",
    "        x_row_gt = []\n",
    "        keylib = []\n",
    "        roilib = []\n",
    "        roi_names = []\n",
    "        voxel_size = ((0.5,0.5,0.5))\n",
    "        seg_sitk = sitk.GetImageFromArray(seg)\n",
    "        seg_sitk.SetSpacing(voxel_size)\n",
    "        qsm_sitk_gt = sitk.GetImageFromArray(qsm)\n",
    "        qsm_sitk_gt.SetSpacing(voxel_size)\n",
    "        for j in seg_labels_all:\n",
    "            if 0 < j < 7:\n",
    "                fv_count = 0\n",
    "                featureVector_gt = extractor.execute(qsm_sitk_gt,seg_sitk,label=int(j));\n",
    "                Phi_gt.append(featureVector_gt)\n",
    "                for key, value in six.iteritems(featureVector_gt):\n",
    "                    if 'diagnostic' in key:\n",
    "                        next\n",
    "                    else:\n",
    "                        x_row_gt.append(featureVector_gt[key])\n",
    "                        fv_count = fv_count+1\n",
    "                        keylib.append(key)\n",
    "                        roilib.append(j)\n",
    "                        mask = np.row_stack([roi_df[row].str.contains(str(int(roilib[-1])), na = False) for row in roi_df])\n",
    "                        roi_names.append(np.asarray(roi_df.iloc[mask.any(axis=0),1])[0])\n",
    "                x_row_gt.append(pre_dbs_off_meds_in)\n",
    "                fv_count = fv_count+1\n",
    "                print('Extracting features for subject',sub_in,\n",
    "                    'ROI',j,'and appending feature matrix with vector of length',\n",
    "                    fv_count,'with UPDRS score',pre_dbs_off_meds_in)\n",
    "\n",
    "        X0_gt = np.array(x_row_gt)\n",
    "        npy_file = '/data/Ali/RadDBS-QSM/src/jupyter/npy/X0_gt_msw_rois'+str(sub_in)+'.npy'\n",
    "        np.save(npy_file,X0_gt)\n",
    "        K = np.asarray(keylib)\n",
    "        R = np.asarray(roi_names)\n",
    "        K_file = '/data/Ali/RadDBS-QSM/src/jupyter/npy/K_msw'+str(sub_in)+'.npy'\n",
    "        R_file = '/data/Ali/RadDBS-QSM/src/jupyter/npy/R_msw'+str(sub_in)+'.npy'\n",
    "        np.save(K_file,K)\n",
    "        np.save(R_file,R)\n",
    "        Phi_file = '/data/Ali/RadDBS-QSM/src/jupyter/phi/Phi_mcl_gt_roi_msw'+str(sub_in)\n",
    "        print('Saving ground truth feature vector')\n",
    "        with open(Phi_file, 'wb') as fp:  \n",
    "            pickle.dump(Phi_gt, fp)\n",
    "\n",
    "    pool = Pool(os.cpu_count()-5)\n",
    "    results = pool.starmap(extract,packet)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_ls = np.zeros((n_cases))\n",
    "ut_qr = np.zeros((n_cases))\n",
    "\n",
    "ut_lsds = np.zeros((n_cases))\n",
    "ut_qrds = np.zeros((n_cases))\n",
    "# Normalize testing and training cases together\n",
    "#   Set with_mean=False to preserve data sparsity\n",
    "#   And with_std=False \n",
    "#   However, need a significant number of samples to do this\n",
    "X_all_r = X_all.reshape(n_cases,((n_features)*n_rois))\n",
    "X_all_rds = X_all_ds.reshape(n_cases,((n_features)*n_rois))\n",
    "scaler = StandardScaler()\n",
    "# Transform feature matrix and UPDRS\n",
    "X_all_t = scaler.fit_transform(X_all_r)\n",
    "X_all_t_ds = scaler.fit_transform(X_all_rds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_off_meds_improvement_in = dbs_off_meds_improvement[np.in1d(subs,np.asarray(id).astype(float))]\n",
    "pre_dbs_meds_improvement_in = pre_dbs_meds_improvement[np.in1d(subs,np.asarray(id).astype(float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for SMOGN generation\n",
    "D = pd.DataFrame(np.hstack((X_all_t,(dbs_off_meds_improvement_in.reshape(n_cases,1)))))\n",
    "for col in D.columns:\n",
    "    D.rename(columns={col:str(col)},inplace=True)\n",
    "\n",
    "# Specify phi relevance values\n",
    "Rm = [[np.min(dbs_off_meds_improvement_in),  1, 0],  ## over-sample (\"minority\")\n",
    "    [np.median(dbs_off_meds_improvement_in), 0, 0],  ## under-sample (\"majority\")\n",
    "    ]\n",
    "\n",
    "# Conduct SMOGN\n",
    "print('Prior to SMOGN sampling, mean is',X_all_t.mean(),'standard deviation is',X_all_t.std())\n",
    "X_smogn = smogn.smoter(data = D, y = str(D.columns[-1]),rel_method = 'manual',rel_ctrl_pts_rg = Rm)\n",
    "\n",
    "# Drop label\n",
    "X_in_s = np.array(X_smogn)[:,:-1] \n",
    "print('After SMOGN sampling, mean is',X_in_s.mean(),'standard deviation is',X_in_s.std())\n",
    "X_in_s = scaler.fit_transform(X_in_s)\n",
    "print('Standardizing the SMOGN dataset gives, mean',X_in_s.mean(),'standard deviation',X_in_s.std())\n",
    "\n",
    "for j in np.arange(X_in_s.shape[1]):\n",
    "    if np.array_equal(X_in_s[:,j],np.array(X_smogn)[:,-1]) == 0:\n",
    "        next\n",
    "    else:\n",
    "        print('Labels detected at column',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.zeros_like(X_in_s)\n",
    "C = np.zeros_like(X_all_t)\n",
    "for j in np.arange(n_cases):\n",
    "        # Add UPDRS after scaling\n",
    "        # Initialize training feature matrix\n",
    "        X_in = X_all_t\n",
    "        X_in = np.delete(X_in,j,axis=0)\n",
    "        if j < X_in_s.shape[0]: \n",
    "                # Drop the label in SMOGN array\n",
    "                X_in_s = np.array(X_smogn)[:,:-1] \n",
    "                # Drop the test case features\n",
    "                X_in_s = np.delete(X_in_s,j,axis=0)\n",
    "                # Create training label array from the SMOGN array\n",
    "                smogn_per_change_in = np.asarray(X_smogn)[:,-1]\n",
    "                # Drop the test case labels\n",
    "                smogn_per_change_in = np.delete(smogn_per_change_in,j,axis=0)\n",
    "                # Train LASSO on SMOGN\n",
    "                clf_s = Lasso(alpha=1e-4,max_iter=10000).fit(X_in_s,smogn_per_change_in)\n",
    "                # Get the features LASSO-SMOGN uses\n",
    "                Cs[j] = clf_s.coef_\n",
    "\n",
    "        # Initialize training labels\n",
    "        per_change_in = dbs_off_meds_improvement_in\n",
    "        per_change_in = np.delete(per_change_in,j,axis=0)\n",
    "  \n",
    "        # Cross-validation for model selection\n",
    "        # Identify most important features\n",
    "        clf_ls = Lasso(alpha=1e-4,max_iter=10000).fit(X_in,per_change_in)\n",
    "        print('Fit complete')\n",
    "        ut_ls[j] = clf_ls.predict(X_all_t[j,:].reshape(1, -1))\n",
    "        ut_qr[j] = clf_s.predict(X_all_t[j,:].reshape(1, -1))\n",
    "\n",
    "        print('Testing patient',subs_in[j],'with pre-surgical UPDRS score',str(dbs_off_meds_improvement_in[int(j)]),'at feature matrix row',str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (25,5)\n",
    "# Cross validation results\n",
    "[fig,ax] = plt.subplots(1,3,sharex=True, sharey=True)\n",
    "lr_prepost = linregress(pre_dbs_meds_improvement_in,dbs_off_meds_improvement_in)\n",
    "ax[0].scatter(pre_dbs_meds_improvement_in,dbs_off_meds_improvement_in,)\n",
    "ax[0].plot(pre_dbs_meds_improvement_in,pre_dbs_meds_improvement_in*lr_prepost.slope+lr_prepost.intercept,'-r')\n",
    "ax[0].set_title('LCT')\n",
    "ax[0].set_ylabel(\"DBS improvement\")\n",
    "ax[0].set_xlabel(\"Prediction\")\n",
    "ax[0].set_ylim([0, 1])\n",
    "text = f\"$y={lr_prepost.slope:0.3f}\\;x{lr_prepost.intercept:+0.3f}$\\n$r = {lr_prepost.rvalue:0.3f}$\\n$p = {lr_prepost.pvalue:0.3f}$\"\n",
    "ax[0].text(0.5, 0.375, text,transform=ax[0].transAxes,\n",
    "     fontsize=14, verticalalignment='top')\n",
    "ax[0].hlines(0.4,0,1,linestyle='dashed',color='black')\n",
    "ax[0].vlines(0.4,0,2,linestyle='dashed',color='black')\n",
    "\n",
    "lr_pred_ls = linregress(ut_ls,dbs_off_meds_improvement_in)\n",
    "ax[1].scatter(ut_ls,dbs_off_meds_improvement_in)\n",
    "ax[1].plot(ut_ls,ut_ls*lr_pred_ls.slope+lr_pred_ls.intercept,'-r')\n",
    "ax[1].set_title('LASSO')\n",
    "ax[1].set_ylabel(\"DBS improvement\")\n",
    "ax[1].set_xlabel(\"Prediction\")\n",
    "text = f\"$y={lr_pred_ls.slope:0.3f}\\;x{lr_pred_ls.intercept:+0.3f}$\\n$r = {lr_pred_ls.rvalue:0.3f}$\\n$p = {lr_pred_ls.pvalue:0.3f}$\"\n",
    "ax[1].text(0.5, 0.375, text,transform=ax[1].transAxes,\n",
    "     fontsize=14, verticalalignment='top')\n",
    "ax[1].hlines(0.4,0,1,linestyle='dashed',color='black')\n",
    "ax[1].vlines(0.4,0,2,linestyle='dashed',color='black')\n",
    "\n",
    "\n",
    "lr_pred_qr = linregress(ut_qr,dbs_off_meds_improvement_in)\n",
    "ax[2].scatter(ut_qr,dbs_off_meds_improvement_in)\n",
    "ax[2].plot(ut_qr,ut_qr*lr_pred_qr.slope+lr_pred_qr.intercept,'-r')\n",
    "ax[2].set_title('LASSO with SMOGN')\n",
    "ax[2].set_ylabel(\"DBS improvement\")\n",
    "ax[2].set_xlabel(\"Prediction\")\n",
    "text = f\"$y={lr_pred_qr.slope:0.3f}\\;x{lr_pred_qr.intercept:+0.3f}$\\n$r = {lr_pred_qr.rvalue:0.3f}$\\n$p = {lr_pred_qr.pvalue:0.10f}$\"\n",
    "ax[2].text(0.5, 0.375, text,transform=ax[2].transAxes,\n",
    "     fontsize=14, verticalalignment='top')\n",
    "ax[2].hlines(0.4,0,1,linestyle='dashed',color='black')\n",
    "ax[2].vlines(0.4,0,2,linestyle='dashed',color='black')\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
