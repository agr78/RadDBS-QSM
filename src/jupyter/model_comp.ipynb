{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "import sklearn.pipeline as spl\n",
    "import sklearn.kernel_ridge as skr\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.neural_network as snn\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.decomposition as sdc\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.utils import resample\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "#     Performed poorly using Standard and MinMax scalers. Trying with LOOCV to see if predictions stabilize.\n",
    "#     Does not appear to stabilize predictions with LOOCV (using StandardScaler())\n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function?\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,False)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "K_all_c = K_all[c_cases_idx,:,:]\n",
    "R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,train_index,test_index = util.set_split(X_all_c,per_change,1,5/len(X_all_c))\n",
    "\n",
    "# Cross validation\n",
    "X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                             X_train,train_index,X_test,test_index,pre_updrs_off)\n",
    "# X0_ss0, y_train = resample(X0_ss0,y_train,replace=True,n_samples=100,random_state=1)\n",
    "cvn = len(X0_ss0)-1\n",
    "# Feature selection\n",
    "sel = skf.SelectKBest(skf.f_regression,k=X0_ss0.shape[1])\n",
    "X0_ss = X0_ss0 #sel.fit_transform(X0_ss0,y_train)\n",
    "X_test_ss = X_test_ss0#(sel.transform(X_test_ss0.reshape(X_test_ss0.shape[0],X_test_ss0.shape[1]*X_test_ss0.shape[2]))).reshape((X_test_ss0.shape[0],1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = np.vstack((X0_ss.T,y_train)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bootstrap\n",
    "res = bootstrap((z_train,),np.std,n_resamples=100,confidence_level=0.9,method='basic',random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_mean_squared_error'\n",
    "print(y_test)\n",
    "print(y_test.mean())\n",
    "print(y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-9,-2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = slm.LinearRegression()\n",
    "est_lr = lr.fit(X0_ss,y_train)\n",
    "results_lr = est_lr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(slm.BayesianRidge(),cvn,\n",
    "                                         br_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "br = slm.BayesianRidge(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'])\n",
    "br.fit(X0_ss, y_train)\n",
    "results_br = np.asarray(br.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_grid = {'hidden_layer_sizes': [(X_train.shape[1],X_train.shape[2])],\n",
    "          'activation': ['relu'],\n",
    "          'alpha': alphas,\n",
    "          'epsilon': [1e0],\n",
    "          'solver': ['sgd'],\n",
    "          'max_iter':[5000]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(snn.MLPRegressor(),\n",
    "                                         cvn,\n",
    "                                         mlp_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "\n",
    "mlp = snn.MLPRegressor(hidden_layer_sizes=best_params[\"hidden_layer_sizes\"], \n",
    "                        activation=best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"],\n",
    "                        alpha=best_params['alpha'],\n",
    "                        epsilon=best_params[\"epsilon\"],\n",
    "                        max_iter=5000, \n",
    "                        n_iter_no_change=500, \n",
    "                        verbose=True,\n",
    "                        early_stopping=True,\n",
    "                        random_state=1,\n",
    "                        batch_size=len(X0_ss)//cvn)\n",
    "\n",
    "mlp.fit(X0_ss,y_train)\n",
    "results_mlp = mlp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "\n",
    "print(results_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = slm.LassoCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    verbose=True,\n",
    "    random_state=1,\n",
    "    max_iter=100000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_ls = lasso.fit(X0_ss,y_train)\n",
    "results_ls = est_ls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = slm.RidgeCV(\n",
    "    alphas=[1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4],\n",
    "    scoring=scoring,\n",
    "    cv=cvn)\n",
    "\n",
    "est_rr = ridge.fit(X0_ss,y_train)\n",
    "results_rr = est_rr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lars = slm.LarsCV(\n",
    "    cv=cvn, \n",
    "    max_iter=1000,\n",
    "    max_n_alphas=10000,\n",
    "    verbose=True,\n",
    "    normalize=False,\n",
    "    eps=np.finfo(float).eps,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_lars = lars.fit(X0_ss,y_train)\n",
    "results_lars = est_lars.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr_grid = {'kernel': ['linear','rbf'],\n",
    "          'alpha': [alphas]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(skr.KernelRidge(),\n",
    "                                         cvn,\n",
    "                                         krr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "krr = skr.KernelRidge(kernel=best_params['kernel'],alpha=best_params['alpha'])\n",
    "krr.fit(X0_ss, y_train)\n",
    "results_krr = krr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_krr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = slm.ElasticNetCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    max_iter=10000,\n",
    "    verbose=True,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_en = gsc.fit(X0_ss,y_train)\n",
    "results_en = est_en.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls_grid = {'n_components': np.flip(np.arange(5,int(len(X_train)))),\n",
    "#             'scale': [True,False]}\n",
    "# best_params = util.gridsearch_pickparams(skd.PLSRegression(),cvn,\n",
    "#                                          pls_grid,scaler_ss,X_train,\n",
    "#                                          train_index,X_test,test_index,pre_updrs_off,y_train,scoring,-1)\n",
    "# pls = skd.PLSRegression(n_components=best_params['n_components'],scale=best_params['scale'],max_iter=10000)\n",
    "# pls.fit(X0_ss, y_train)\n",
    "# results_pls = (pls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "# print(results_pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr = spl.make_pipeline(sdc.PCA(),slm.LinearRegression())\n",
    "pcr.fit(X0_ss, y_train)\n",
    "results_pcr = np.asarray(pcr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_pcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omp = slm.OrthogonalMatchingPursuitCV(normalize=True,cv=cvn,max_iter=len(X_train)//2,verbose=True)\n",
    "# omp.fit(X0_ss, y_train)\n",
    "# results_omp = np.asarray(omp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "# print(results_omp)\n",
    "results_omp = results_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsr = slm.RANSACRegressor(random_state=1,min_samples=len(X0_ss)).fit(X0_ss, y_train)\n",
    "results_rsr = rsr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]])).ravel()\n",
    "print(results_rsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very slow on leave one out\n",
    "# ard_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4], 'lambda_1': alphas[-5:-4], 'lambda_2': alphas[-5:-4]}\n",
    "# best_params = util.gridsearch_pickparams(slm.ARDRegression(),cvn,\n",
    "#                                          ard_grid,scaler_ss,X_train,\n",
    "#                                          train_index,X_test,test_index,pre_updrs_off,y_train,scoring,8)\n",
    "# ard = slm.ARDRegression(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'],\n",
    "#                        lambda_1=best_params['lambda_1'],lambda_2=best_params['lambda_2'])\n",
    "# ard.fit(X0_ss,y_train)\n",
    "# results_ard = np.asarray(ard.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svr_grid = {'kernel': ['linear','rbf'],\n",
    "          'epsilon': [3e-1]}\n",
    "best_params = util.gridsearch_pickparams(svm.SVR(),\n",
    "                                         cvn,\n",
    "                                         svr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "svr = svm.SVR(kernel=best_params['kernel'],epsilon=best_params['epsilon'])\n",
    "svr.fit(X0_ss, y_train)\n",
    "results_svr = np.asarray(svr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid = {'max_depth':[3,6,9,12,15,20,100]}\n",
    "best_params = util.gridsearch_pickparams(ske.GradientBoostingRegressor(random_state=1),cvn,\n",
    "                                         gbr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "gbr = ske.GradientBoostingRegressor(random_state=1,learning_rate=0.001,max_depth=best_params['max_depth'],n_estimators=100)\n",
    "gbr.fit(X0_ss, y_train)\n",
    "results_gbr = np.asarray(gbr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp[test_index],\n",
    "                               results_lr.ravel(),\n",
    "                               results_mlp,\n",
    "                               results_ls,\n",
    "                               results_lars,\n",
    "                               results_en,\n",
    "                               results_rr.ravel(),\n",
    "                               #results_krr.ravel(),\n",
    "                               results_pcr,\n",
    "                               #results_pls,\n",
    "                               #results_omp,\n",
    "                               results_br,\n",
    "                               results_rsr,\n",
    "                               results_svr,\n",
    "                               results_gbr)),\n",
    "                               y_test,\n",
    "                               ['LCT',\n",
    "                                'Regression',\n",
    "                                'MLP',\n",
    "                                'Lasso',\n",
    "                                'LARS',\n",
    "                                'ElasticNet',\n",
    "                                'Ridge',\n",
    "                                #'KernelRidge',\n",
    "                                'PCR',\n",
    "                                #'PLS',\n",
    "                                #'OMP',\n",
    "                                'Bayesian',\n",
    "                                'RANSAC',\n",
    "                                'SVR',\n",
    "                                'GBR'],(70,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_train = stats.gaussian_kde(y_train)\n",
    "density_test = stats.gaussian_kde(y_test)\n",
    "n, x, _ = plt.hist(y_train, bins=np.linspace(-1, 2, 50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(x, density_train(x),color='tab:blue',label=r'$y_{train}$')\n",
    "n, y, _ = plt.hist(y_test, bins=np.linspace(-1, 2, 50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(y, density_test(y),color='tab:green',label=r'$y_{test}$')\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlim([-1,2])\n",
    "plt.ylim([0,3])\n",
    "plt.xlabel('DBS improvement',fontsize=24)\n",
    "plt.ylabel('Frequency',fontsize=24)\n",
    "plt.title('Dataset distributions',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "Q = X0_ss0\n",
    "P = X_test_ss\n",
    "\n",
    "x = np.arange(np.min((np.min(Q),np.min(P))), np.max((np.max(Q),np.max(P))),1/1000)\n",
    "p = scipy.stats.norm.pdf(x, np.mean(P), np.std(P))\n",
    "q = scipy.stats.norm.pdf(x, np.mean(Q), np.std(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.kl_divergence(p[p>1e-16],q[p>1e-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_test.npy',X_test)\n",
    "# np.save('X_train.npy',X_train)\n",
    "# np.save('y_test.npy',y_test)\n",
    "# np.save('y_train.npy',y_train)\n",
    "# np.save('test_index.npy',test_index)\n",
    "# np.save('train_index.npy',train_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
