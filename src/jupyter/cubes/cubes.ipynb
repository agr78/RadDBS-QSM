{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import util\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from qsm_feats import MLP, train_model\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import RawScoresOutputTarget, BinaryClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from util import pyvis\n",
    "import scipy\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model.eval()\n",
    "# Pass masked volumes through to reduce dataset memory burden on GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = 0\n",
    "qsms = util.full_path('/home/ali/RadDBS-QSM/data/nii/qsm')\n",
    "qsms_subs = qsms[-9]\n",
    "segs = util.full_path('/home/ali/RadDBS-QSM/data/nii/seg')\n",
    "chi = []\n",
    "im_subs = []\n",
    "if reload == 1:\n",
    "    for j in np.arange(len(qsms)):\n",
    "        data = nib.load(qsms[j])\n",
    "        qsm_subs = qsms[j][-9:-7]\n",
    "        try:\n",
    "            mask = nib.load('/home/ali/RadDBS-QSM/data/nii/seg/labels_2iMag'+qsm_subs+'.nii.gz').get_fdata()\n",
    "            cube_mask = util.mask_crop(mask.get_fdata(),mask)\n",
    "            img = util.mask_crop(data.get_fdata(),mask)\n",
    "            img = util.pad_to(img,152,152,105)\n",
    "            chi.append(img)\n",
    "            masks.append(mask)\n",
    "            im_subs.append(qsms[j][-9:-7])\n",
    "        except:\n",
    "            print('Skipping',qsms[j])\n",
    "    np.save('../txt/cube_masks',np.asarray(masks))\n",
    "    np.save('../txt/chi.npy',np.asarray(chi))\n",
    "    np.save('../txt/im_subs.npy',np.asarray(im_subs))\n",
    "else:\n",
    "    print('Using whole susceptibility')\n",
    "    chi = np.load('../txt/chi.npy')\n",
    "    im_subs = np.load('../txt/im_subs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.pyvis(np.hstack(chi[0].T,cube_mask[0].T),5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "ID_all = im_subs\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subsc = subs[s_cases_idx]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subsc = subs[s_cases_idx]\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp\n",
    "X_all_c = np.asarray(chi)[c_cases_idx,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_neighbors = 3\n",
    "batch_size = X_all_c.shape[0]-num_neighbors-1\n",
    "print(batch_size)\n",
    "results = np.zeros_like(per_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_layers = [encoder.layers[-1]]\n",
    "# input_tensor = X_test_ss # Create an input tensor image for your model..\n",
    "# # Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# # Construct the CAM object once, and then re-use it on many images:\n",
    "# cam = GradCAM(model=encoder, target_layers=target_layers)\n",
    "\n",
    "# # You can also use it within a with statement, to make sure it is freed,\n",
    "# # In case you need to re-create it inside an outer loop:\n",
    "# # with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "# #   ...\n",
    "\n",
    "# # We have to specify the target we want to generate\n",
    "# # the Class Activation Maps for.\n",
    "# # If targets is None, the highest scoring category\n",
    "# # will be used for every image in the batch.\n",
    "# # Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "# # That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "\n",
    "# targets = [RawScoresOutputTarget()]\n",
    "\n",
    "# # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "# grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "# # In this example grayscale_cam has only one image in the batch:\n",
    "# grayscale_cam = grayscale_cam[0, :]\n",
    "# visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "# # You can also get the model outputs without having to re-inference\n",
    "# model_outputs = cam.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:,:]\n",
    "    X_test = X_all_c[test_index,:,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "   # MLP (add early stopping?)\n",
    "    encoder = MLP(in_size=(batch_size,152,152,105),\n",
    "                  kernel_size=(30,30,20),\n",
    "                  cnn_layers=5,\n",
    "                  n_channels=2,\n",
    "                  fc_layers=1)\n",
    "    \n",
    "    yt, encoder, X_trained, y_trained, X_val, y_val, train_curve, val_curve = train_model(X_all=X_train,\n",
    "                     y_all=y_train,\n",
    "                     model=encoder,\n",
    "                     X_test=X_test,\n",
    "                     solver='adam',\n",
    "                     lr=1e-1,\n",
    "                     lr_decay=None,\n",
    "                     alpha=1e0,\n",
    "                     reg_type='latent_dist',\n",
    "                     num_epochs=num_epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     case_id=str(int(subsc[j])),\n",
    "                     num_neighbors=num_neighbors,\n",
    "                     random_val=True,\n",
    "                     early_stopping=False,\n",
    "                     verbose=True,\n",
    "                     save_state=False)\n",
    "    # target_layers = [encoder.layers[:]]\n",
    "    # input_tensor = torch.unsqueeze(torch.Tensor(X_test),axis=0).cuda()# Create an input tensor image for your model..\n",
    "    # # Construct the CAM object once, and then re-use it on many images:\n",
    "    # cam = GradCAM(model=encoder, target_layers=target_layers)\n",
    "    # targets = [BinaryClassifierOutputTarget(0)]\n",
    "\n",
    "    # # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "    # grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    # print(grayscale_cam.shape)\n",
    "    # # In this example grayscale_cam has only one image in the batch:\n",
    "    # grayscale_cam_in = grayscale_cam[0,:,0,:]\n",
    "    # visualization = show_cam_on_image(X_test[:,:,:,0], grayscale_cam_in, use_rgb=False)\n",
    "\n",
    "    # # You can also get the model outputs without having to re-inference\n",
    "    # model_outputs = cam.outputs\n",
    "    \n",
    "    results[j] = yt\n",
    "    print('Predicted',str(np.round(yt.cpu().detach(),2)),'for',str(np.round(per_change[j],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyvis(np.squeeze(X_test.T),10,10)\n",
    "# pyvis(np.squeeze(grayscale_cam.T),10,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'CNN regressor',\n",
    "                                ],(30,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
