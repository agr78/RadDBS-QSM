{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "import sklearn.pipeline as spl\n",
    "import sklearn.kernel_ridge as skr\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.neural_network as snn\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.decomposition as sdc\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "#     Performed poorly using Standard and MinMax scalers. Trying with LOOCV to see if predictions stabilize.\n",
    "#     Does not appear to stabilize predictions with LOOCV (using StandardScaler())\n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function?\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs_init,pre_imp_init,post_imp_init,pre_updrs_off_init = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 1000 slices\n",
      "Appended 2000 slices\n",
      "Appended 3000 slices\n",
      "Appended 4000 slices\n",
      "Appended 5000 slices\n",
      "Appended 6000 slices\n",
      "Allocated arrays\n"
     ]
    }
   ],
   "source": [
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/slices/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/slices/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,939,True)\n",
    "ids = np.asarray(ID_all).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs_init).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "# K_all_c = K_all[c_cases_idx,:,:]\n",
    "# R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs_init,ids[c_cases_idx])\n",
    "subs_init = subs_init[s_cases_idx]\n",
    "pre_imp_init = pre_imp_init[s_cases_idx]\n",
    "post_imp_init = post_imp_init[s_cases_idx]\n",
    "pre_updrs_off_init = pre_updrs_off_init[s_cases_idx]\n",
    "per_change_init = post_imp_init\n",
    "subs = np.asarray(ID_all,dtype=float)[np.in1d(np.asarray(ID_all,dtype=float),subs_init)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_imp = np.zeros((1,len(subs))).T\n",
    "post_imp = np.zeros((1,len(subs))).T\n",
    "pre_updrs_off = np.zeros((1,len(subs))).T\n",
    "per_change = np.zeros((1,len(subs))).T\n",
    "for j in np.arange(len(subs)):\n",
    "    pre_imp[j] = pre_imp_init[subs_init == subs[j]]\n",
    "    post_imp[j] = post_imp_init[subs_init == subs[j]]\n",
    "    pre_updrs_off[j] = pre_updrs_off_init[subs_init == subs[j]]\n",
    "    per_change[j] = per_change_init[subs_init == subs[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.random.choice(np.unique(subs))\n",
    "test_index = subs == test_id\n",
    "train_index = subs != test_id\n",
    "X_train = X_all_c[train_index,:,:]\n",
    "X_test = X_all_c[test_index,:,:]\n",
    "y_train = per_change[train_index]\n",
    "y_test = per_change[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sku.shuffle(X_train, y_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test,train_index,test_index = util.set_split(X_all_c,per_change,1,10/len(X_all_c))\n",
    "\n",
    "# Cross validation\n",
    "cvn = 40\n",
    "# Choose scaling\n",
    "X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                             X_train,train_index,X_test,test_index,pre_updrs_off.ravel())\n",
    "# Feature selection\n",
    "# sel = skf.SelectKBest(skf.f_regression,k=X0_ss0.shape[1])\n",
    "X0_ss = X0_ss0# sel.fit_transform(X0_ss0,y_train)\n",
    "X_test_ss = X_test_ss0 # (sel.transform(X_test_ss0.reshape(X_test_ss0.shape[0],X_test_ss0.shape[1]*X_test_ss0.shape[2]))).reshape((X_test_ss0.shape[0],1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7435897435897436\n",
      "0.6484936161919129\n"
     ]
    }
   ],
   "source": [
    "scoring = 'r2'\n",
    "print(y_test.mean())\n",
    "print(y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-9,-2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64688286]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64688286]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]\n",
      " [0.64690861]]\n"
     ]
    }
   ],
   "source": [
    "lr = slm.LinearRegression()\n",
    "est_lr = lr.fit(X0_ss,y_train)\n",
    "results_lr = est_lr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 40 folds for each of 1 candidates, totalling 40 fits\n",
      "[0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181\n",
      " 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181 0.64838181]\n"
     ]
    }
   ],
   "source": [
    "br_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(slm.BayesianRidge(),cvn,\n",
    "                                         br_grid,X0_ss0,\n",
    "                                         y_train.ravel(),scoring,8)\n",
    "br = slm.BayesianRidge(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'])\n",
    "br.fit(X0_ss, y_train.ravel())\n",
    "results_br = np.asarray(br.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 40 folds for each of 10 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30046592\n",
      "Validation score: -9.743576\n",
      "Iteration 2, loss = 0.28633622\n",
      "Validation score: -9.201631\n",
      "Iteration 3, loss = 0.26805752\n",
      "Validation score: -8.567452\n",
      "Iteration 4, loss = 0.24941071\n",
      "Validation score: -7.886818\n",
      "Iteration 5, loss = 0.23041189\n",
      "Validation score: -7.188875\n",
      "Iteration 6, loss = 0.21195614\n",
      "Validation score: -6.501813\n",
      "Iteration 7, loss = 0.19412675\n",
      "Validation score: -5.844865\n",
      "Iteration 8, loss = 0.17703685\n",
      "Validation score: -5.213708\n",
      "Iteration 9, loss = 0.16093987\n",
      "Validation score: -4.626910\n",
      "Iteration 10, loss = 0.14599240\n",
      "Validation score: -4.087209\n",
      "Iteration 11, loss = 0.13221076\n",
      "Validation score: -3.587271\n",
      "Iteration 12, loss = 0.11947398\n",
      "Validation score: -3.131477\n",
      "Iteration 13, loss = 0.10788476\n",
      "Validation score: -2.716740\n",
      "Iteration 14, loss = 0.09740695\n",
      "Validation score: -2.349338\n",
      "Iteration 15, loss = 0.08813822\n",
      "Validation score: -2.024573\n",
      "Iteration 16, loss = 0.07985875\n",
      "Validation score: -1.734244\n",
      "Iteration 17, loss = 0.07241299\n",
      "Validation score: -1.477976\n",
      "Iteration 18, loss = 0.06589657\n",
      "Validation score: -1.253668\n",
      "Iteration 19, loss = 0.06019538\n",
      "Validation score: -1.059937\n",
      "Iteration 20, loss = 0.05514115\n",
      "Validation score: -0.890335\n",
      "Iteration 21, loss = 0.05078168\n",
      "Validation score: -0.747023\n",
      "Iteration 22, loss = 0.04695539\n",
      "Validation score: -0.620666\n",
      "Iteration 23, loss = 0.04360839\n",
      "Validation score: -0.511640\n",
      "Iteration 24, loss = 0.04073663\n",
      "Validation score: -0.420777\n",
      "Iteration 25, loss = 0.03826679\n",
      "Validation score: -0.343382\n",
      "Iteration 26, loss = 0.03618668\n",
      "Validation score: -0.278542\n",
      "Iteration 27, loss = 0.03439767\n",
      "Validation score: -0.224995\n",
      "Iteration 28, loss = 0.03288160\n",
      "Validation score: -0.179428\n",
      "Iteration 29, loss = 0.03159360\n",
      "Validation score: -0.142471\n",
      "Iteration 30, loss = 0.03052351\n",
      "Validation score: -0.112393\n",
      "Iteration 31, loss = 0.02962345\n",
      "Validation score: -0.087378\n",
      "Iteration 32, loss = 0.02888678\n",
      "Validation score: -0.067869\n",
      "Iteration 33, loss = 0.02826126\n",
      "Validation score: -0.051937\n",
      "Iteration 34, loss = 0.02773240\n",
      "Validation score: -0.038814\n",
      "Iteration 35, loss = 0.02731072\n",
      "Validation score: -0.028812\n",
      "Iteration 36, loss = 0.02694467\n",
      "Validation score: -0.020626\n",
      "Iteration 37, loss = 0.02663430\n",
      "Validation score: -0.014388\n",
      "Iteration 38, loss = 0.02639368\n",
      "Validation score: -0.009836\n",
      "Iteration 39, loss = 0.02617973\n",
      "Validation score: -0.006062\n",
      "Iteration 40, loss = 0.02600370\n",
      "Validation score: -0.003623\n",
      "Iteration 41, loss = 0.02586314\n",
      "Validation score: -0.001624\n",
      "Iteration 42, loss = 0.02574329\n",
      "Validation score: -0.000414\n",
      "Iteration 43, loss = 0.02564534\n",
      "Validation score: 0.000269\n",
      "Iteration 44, loss = 0.02556916\n",
      "Validation score: 0.000558\n",
      "Iteration 45, loss = 0.02550649\n",
      "Validation score: 0.000564\n",
      "Iteration 46, loss = 0.02545901\n",
      "Validation score: 0.000368\n",
      "Iteration 47, loss = 0.02541931\n",
      "Validation score: 0.000040\n",
      "Iteration 48, loss = 0.02538911\n",
      "Validation score: -0.000366\n",
      "Iteration 49, loss = 0.02536260\n",
      "Validation score: -0.000852\n",
      "Iteration 50, loss = 0.02534399\n",
      "Validation score: -0.001334\n",
      "Iteration 51, loss = 0.02532431\n",
      "Validation score: -0.002012\n",
      "Iteration 52, loss = 0.02531191\n",
      "Validation score: -0.002437\n",
      "Iteration 53, loss = 0.02529963\n",
      "Validation score: -0.003011\n",
      "Iteration 54, loss = 0.02528978\n",
      "Validation score: -0.003631\n",
      "Iteration 55, loss = 0.02528098\n",
      "Validation score: -0.004255\n",
      "Iteration 56, loss = 0.02527772\n",
      "Validation score: -0.004450\n",
      "Iteration 57, loss = 0.02527401\n",
      "Validation score: -0.004981\n",
      "Iteration 58, loss = 0.02527169\n",
      "Validation score: -0.005007\n",
      "Iteration 59, loss = 0.02527174\n",
      "Validation score: -0.004935\n",
      "Iteration 60, loss = 0.02527085\n",
      "Validation score: -0.005270\n",
      "Iteration 61, loss = 0.02526798\n",
      "Validation score: -0.005648\n",
      "Iteration 62, loss = 0.02526262\n",
      "Validation score: -0.006384\n",
      "Iteration 63, loss = 0.02526031\n",
      "Validation score: -0.006865\n",
      "Iteration 64, loss = 0.02525932\n",
      "Validation score: -0.007103\n",
      "Iteration 65, loss = 0.02525991\n",
      "Validation score: -0.007410\n",
      "Iteration 66, loss = 0.02525750\n",
      "Validation score: -0.007653\n",
      "Iteration 67, loss = 0.02525801\n",
      "Validation score: -0.007521\n",
      "Iteration 68, loss = 0.02525841\n",
      "Validation score: -0.007282\n",
      "Iteration 69, loss = 0.02525775\n",
      "Validation score: -0.007617\n",
      "Iteration 70, loss = 0.02525679\n",
      "Validation score: -0.007852\n",
      "Iteration 71, loss = 0.02525677\n",
      "Validation score: -0.007526\n",
      "Iteration 72, loss = 0.02525676\n",
      "Validation score: -0.008019\n",
      "Iteration 73, loss = 0.02525578\n",
      "Validation score: -0.008404\n",
      "Iteration 74, loss = 0.02525565\n",
      "Validation score: -0.008533\n",
      "Iteration 75, loss = 0.02525650\n",
      "Validation score: -0.008812\n",
      "Iteration 76, loss = 0.02525503\n",
      "Validation score: -0.009078\n",
      "Iteration 77, loss = 0.02525524\n",
      "Validation score: -0.009098\n",
      "Iteration 78, loss = 0.02525531\n",
      "Validation score: -0.009245\n",
      "Iteration 79, loss = 0.02525532\n",
      "Validation score: -0.009415\n",
      "Iteration 80, loss = 0.02525553\n",
      "Validation score: -0.009127\n",
      "Iteration 81, loss = 0.02525518\n",
      "Validation score: -0.009067\n",
      "Iteration 82, loss = 0.02525582\n",
      "Validation score: -0.009305\n",
      "Iteration 83, loss = 0.02525509\n",
      "Validation score: -0.008825\n",
      "Iteration 84, loss = 0.02525567\n",
      "Validation score: -0.008659\n",
      "Iteration 85, loss = 0.02525469\n",
      "Validation score: -0.009085\n",
      "Iteration 86, loss = 0.02525442\n",
      "Validation score: -0.009649\n",
      "Iteration 87, loss = 0.02525545\n",
      "Validation score: -0.009599\n",
      "Iteration 88, loss = 0.02525554\n",
      "Validation score: -0.009153\n",
      "Iteration 89, loss = 0.02525463\n",
      "Validation score: -0.008874\n",
      "Iteration 90, loss = 0.02525486\n",
      "Validation score: -0.008786\n",
      "Iteration 91, loss = 0.02525513\n",
      "Validation score: -0.008671\n",
      "Iteration 92, loss = 0.02525624\n",
      "Validation score: -0.008952\n",
      "Iteration 93, loss = 0.02525500\n",
      "Validation score: -0.008913\n",
      "Iteration 94, loss = 0.02525549\n",
      "Validation score: -0.008528\n",
      "Iteration 95, loss = 0.02525498\n",
      "Validation score: -0.008249\n",
      "Iteration 96, loss = 0.02525602\n",
      "Validation score: -0.008129\n",
      "Iteration 97, loss = 0.02525521\n",
      "Validation score: -0.008370\n",
      "Iteration 98, loss = 0.02525509\n",
      "Validation score: -0.008601\n",
      "Iteration 99, loss = 0.02525534\n",
      "Validation score: -0.008440\n",
      "Iteration 100, loss = 0.02525517\n",
      "Validation score: -0.008031\n",
      "Iteration 101, loss = 0.02525629\n",
      "Validation score: -0.007856\n",
      "Iteration 102, loss = 0.02525674\n",
      "Validation score: -0.007296\n",
      "Iteration 103, loss = 0.02525754\n",
      "Validation score: -0.007404\n",
      "Iteration 104, loss = 0.02525714\n",
      "Validation score: -0.007602\n",
      "Iteration 105, loss = 0.02525798\n",
      "Validation score: -0.007273\n",
      "Iteration 106, loss = 0.02525830\n",
      "Validation score: -0.007293\n",
      "Iteration 107, loss = 0.02525761\n",
      "Validation score: -0.007458\n",
      "Iteration 108, loss = 0.02525760\n",
      "Validation score: -0.007480\n",
      "Iteration 109, loss = 0.02525597\n",
      "Validation score: -0.007977\n",
      "Iteration 110, loss = 0.02525710\n",
      "Validation score: -0.007730\n",
      "Iteration 111, loss = 0.02525656\n",
      "Validation score: -0.007744\n",
      "Iteration 112, loss = 0.02525672\n",
      "Validation score: -0.007542\n",
      "Iteration 113, loss = 0.02525712\n",
      "Validation score: -0.007660\n",
      "Iteration 114, loss = 0.02525660\n",
      "Validation score: -0.007914\n",
      "Iteration 115, loss = 0.02525663\n",
      "Validation score: -0.007801\n",
      "Iteration 116, loss = 0.02525700\n",
      "Validation score: -0.007946\n",
      "Iteration 117, loss = 0.02525523\n",
      "Validation score: -0.008353\n",
      "Iteration 118, loss = 0.02525403\n",
      "Validation score: -0.009257\n",
      "Iteration 119, loss = 0.02525741\n",
      "Validation score: -0.009871\n",
      "Iteration 120, loss = 0.02525486\n",
      "Validation score: -0.009848\n",
      "Iteration 121, loss = 0.02525538\n",
      "Validation score: -0.009997\n",
      "Iteration 122, loss = 0.02525513\n",
      "Validation score: -0.010076\n",
      "Iteration 123, loss = 0.02525456\n",
      "Validation score: -0.009783\n",
      "Iteration 124, loss = 0.02525482\n",
      "Validation score: -0.009853\n",
      "Iteration 125, loss = 0.02525498\n",
      "Validation score: -0.009790\n",
      "Iteration 126, loss = 0.02525481\n",
      "Validation score: -0.009646\n",
      "Iteration 127, loss = 0.02525529\n",
      "Validation score: -0.009283\n",
      "Iteration 128, loss = 0.02525491\n",
      "Validation score: -0.009374\n",
      "Iteration 129, loss = 0.02525472\n",
      "Validation score: -0.009750\n",
      "Iteration 130, loss = 0.02525475\n",
      "Validation score: -0.009916\n",
      "Iteration 131, loss = 0.02525446\n",
      "Validation score: -0.009495\n",
      "Iteration 132, loss = 0.02525432\n",
      "Validation score: -0.009891\n",
      "Iteration 133, loss = 0.02525535\n",
      "Validation score: -0.010216\n",
      "Iteration 134, loss = 0.02525654\n",
      "Validation score: -0.009139\n",
      "Iteration 135, loss = 0.02525456\n",
      "Validation score: -0.009189\n",
      "Iteration 136, loss = 0.02525449\n",
      "Validation score: -0.009490\n",
      "Iteration 137, loss = 0.02525495\n",
      "Validation score: -0.009752\n",
      "Iteration 138, loss = 0.02525473\n",
      "Validation score: -0.009870\n",
      "Iteration 139, loss = 0.02525540\n",
      "Validation score: -0.009778\n",
      "Iteration 140, loss = 0.02525437\n",
      "Validation score: -0.010172\n",
      "Iteration 141, loss = 0.02525533\n",
      "Validation score: -0.009911\n",
      "Iteration 142, loss = 0.02525495\n",
      "Validation score: -0.009597\n",
      "Iteration 143, loss = 0.02525485\n",
      "Validation score: -0.009549\n",
      "Iteration 144, loss = 0.02525514\n",
      "Validation score: -0.009180\n",
      "Iteration 145, loss = 0.02525452\n",
      "Validation score: -0.009272\n",
      "Iteration 146, loss = 0.02525474\n",
      "Validation score: -0.009274\n",
      "Iteration 147, loss = 0.02525759\n",
      "Validation score: -0.008614\n",
      "Iteration 148, loss = 0.02525525\n",
      "Validation score: -0.009012\n",
      "Iteration 149, loss = 0.02525489\n",
      "Validation score: -0.009009\n",
      "Iteration 150, loss = 0.02525475\n",
      "Validation score: -0.009446\n",
      "Iteration 151, loss = 0.02525508\n",
      "Validation score: -0.009198\n",
      "Iteration 152, loss = 0.02525406\n",
      "Validation score: -0.008883\n",
      "Iteration 153, loss = 0.02525481\n",
      "Validation score: -0.009020\n",
      "Iteration 154, loss = 0.02525461\n",
      "Validation score: -0.009013\n",
      "Iteration 155, loss = 0.02525444\n",
      "Validation score: -0.009137\n",
      "Iteration 156, loss = 0.02525480\n",
      "Validation score: -0.009093\n",
      "Iteration 157, loss = 0.02525447\n",
      "Validation score: -0.008846\n",
      "Iteration 158, loss = 0.02525531\n",
      "Validation score: -0.008849\n",
      "Iteration 159, loss = 0.02525452\n",
      "Validation score: -0.008677\n",
      "Iteration 160, loss = 0.02525464\n",
      "Validation score: -0.008677\n",
      "Iteration 161, loss = 0.02525396\n",
      "Validation score: -0.009235\n",
      "Iteration 162, loss = 0.02525415\n",
      "Validation score: -0.009325\n",
      "Iteration 163, loss = 0.02525445\n",
      "Validation score: -0.009392\n",
      "Iteration 164, loss = 0.02525495\n",
      "Validation score: -0.009628\n",
      "Iteration 165, loss = 0.02525450\n",
      "Validation score: -0.009546\n",
      "Iteration 166, loss = 0.02525430\n",
      "Validation score: -0.009451\n",
      "Iteration 167, loss = 0.02525340\n",
      "Validation score: -0.008913\n",
      "Iteration 168, loss = 0.02525439\n",
      "Validation score: -0.008385\n",
      "Iteration 169, loss = 0.02525573\n",
      "Validation score: -0.008551\n",
      "Iteration 170, loss = 0.02525483\n",
      "Validation score: -0.008277\n",
      "Iteration 171, loss = 0.02525511\n",
      "Validation score: -0.008422\n",
      "Iteration 172, loss = 0.02525537\n",
      "Validation score: -0.008349\n",
      "Iteration 173, loss = 0.02525559\n",
      "Validation score: -0.008956\n",
      "Iteration 174, loss = 0.02525499\n",
      "Validation score: -0.009128\n",
      "Iteration 175, loss = 0.02525456\n",
      "Validation score: -0.009298\n",
      "Iteration 176, loss = 0.02525465\n",
      "Validation score: -0.009170\n",
      "Iteration 177, loss = 0.02525452\n",
      "Validation score: -0.009356\n",
      "Iteration 178, loss = 0.02525474\n",
      "Validation score: -0.009090\n",
      "Iteration 179, loss = 0.02525521\n",
      "Validation score: -0.008743\n",
      "Iteration 180, loss = 0.02525499\n",
      "Validation score: -0.008870\n",
      "Iteration 181, loss = 0.02525484\n",
      "Validation score: -0.008823\n",
      "Iteration 182, loss = 0.02525447\n",
      "Validation score: -0.008983\n",
      "Iteration 183, loss = 0.02525469\n",
      "Validation score: -0.008879\n",
      "Iteration 184, loss = 0.02525432\n",
      "Validation score: -0.009060\n",
      "Iteration 185, loss = 0.02525436\n",
      "Validation score: -0.009264\n",
      "Iteration 186, loss = 0.02525437\n",
      "Validation score: -0.009219\n",
      "Iteration 187, loss = 0.02525428\n",
      "Validation score: -0.009073\n",
      "Iteration 188, loss = 0.02525510\n",
      "Validation score: -0.008596\n",
      "Iteration 189, loss = 0.02525493\n",
      "Validation score: -0.008427\n",
      "Iteration 190, loss = 0.02525536\n",
      "Validation score: -0.008988\n",
      "Iteration 191, loss = 0.02525464\n",
      "Validation score: -0.009004\n",
      "Iteration 192, loss = 0.02525419\n",
      "Validation score: -0.009153\n",
      "Iteration 193, loss = 0.02525503\n",
      "Validation score: -0.009438\n",
      "Iteration 194, loss = 0.02525433\n",
      "Validation score: -0.009693\n",
      "Iteration 195, loss = 0.02525450\n",
      "Validation score: -0.009987\n",
      "Iteration 196, loss = 0.02525548\n",
      "Validation score: -0.009853\n",
      "Iteration 197, loss = 0.02525417\n",
      "Validation score: -0.010124\n",
      "Iteration 198, loss = 0.02525507\n",
      "Validation score: -0.009954\n",
      "Iteration 199, loss = 0.02525425\n",
      "Validation score: -0.009988\n",
      "Iteration 200, loss = 0.02525464\n",
      "Validation score: -0.010258\n",
      "Iteration 201, loss = 0.02525479\n",
      "Validation score: -0.010360\n",
      "Iteration 202, loss = 0.02525459\n",
      "Validation score: -0.010189\n",
      "Iteration 203, loss = 0.02525459\n",
      "Validation score: -0.010046\n",
      "Iteration 204, loss = 0.02525509\n",
      "Validation score: -0.009898\n",
      "Iteration 205, loss = 0.02525471\n",
      "Validation score: -0.009959\n",
      "Iteration 206, loss = 0.02525490\n",
      "Validation score: -0.009534\n",
      "Iteration 207, loss = 0.02525443\n",
      "Validation score: -0.009636\n",
      "Iteration 208, loss = 0.02525496\n",
      "Validation score: -0.009902\n",
      "Iteration 209, loss = 0.02525489\n",
      "Validation score: -0.009926\n",
      "Iteration 210, loss = 0.02525449\n",
      "Validation score: -0.009826\n",
      "Iteration 211, loss = 0.02525436\n",
      "Validation score: -0.009528\n",
      "Iteration 212, loss = 0.02525434\n",
      "Validation score: -0.009927\n",
      "Iteration 213, loss = 0.02525477\n",
      "Validation score: -0.010135\n",
      "Iteration 214, loss = 0.02525418\n",
      "Validation score: -0.009952\n",
      "Iteration 215, loss = 0.02525414\n",
      "Validation score: -0.010181\n",
      "Iteration 216, loss = 0.02525371\n",
      "Validation score: -0.009552\n",
      "Iteration 217, loss = 0.02525378\n",
      "Validation score: -0.009237\n",
      "Iteration 218, loss = 0.02525451\n",
      "Validation score: -0.009347\n",
      "Iteration 219, loss = 0.02525392\n",
      "Validation score: -0.009144\n",
      "Iteration 220, loss = 0.02525399\n",
      "Validation score: -0.009477\n",
      "Iteration 221, loss = 0.02525457\n",
      "Validation score: -0.009963\n",
      "Iteration 222, loss = 0.02525424\n",
      "Validation score: -0.009950\n",
      "Iteration 223, loss = 0.02525423\n",
      "Validation score: -0.009711\n",
      "Iteration 224, loss = 0.02525459\n",
      "Validation score: -0.009239\n",
      "Iteration 225, loss = 0.02525424\n",
      "Validation score: -0.009297\n",
      "Iteration 226, loss = 0.02525532\n",
      "Validation score: -0.008872\n",
      "Iteration 227, loss = 0.02525411\n",
      "Validation score: -0.008981\n",
      "Iteration 228, loss = 0.02525496\n",
      "Validation score: -0.008936\n",
      "Iteration 229, loss = 0.02525423\n",
      "Validation score: -0.009040\n",
      "Iteration 230, loss = 0.02525417\n",
      "Validation score: -0.009076\n",
      "Iteration 231, loss = 0.02525432\n",
      "Validation score: -0.009477\n",
      "Iteration 232, loss = 0.02525417\n",
      "Validation score: -0.009330\n",
      "Iteration 233, loss = 0.02525408\n",
      "Validation score: -0.009147\n",
      "Iteration 234, loss = 0.02525400\n",
      "Validation score: -0.009597\n",
      "Iteration 235, loss = 0.02525559\n",
      "Validation score: -0.009237\n",
      "Iteration 236, loss = 0.02525408\n",
      "Validation score: -0.009339\n",
      "Iteration 237, loss = 0.02525409\n",
      "Validation score: -0.009435\n",
      "Iteration 238, loss = 0.02525455\n",
      "Validation score: -0.009467\n",
      "Iteration 239, loss = 0.02525427\n",
      "Validation score: -0.009731\n",
      "Iteration 240, loss = 0.02525450\n",
      "Validation score: -0.009976\n",
      "Iteration 241, loss = 0.02525415\n",
      "Validation score: -0.009475\n",
      "Iteration 242, loss = 0.02525402\n",
      "Validation score: -0.009469\n",
      "Iteration 243, loss = 0.02525437\n",
      "Validation score: -0.009528\n",
      "Iteration 244, loss = 0.02525410\n",
      "Validation score: -0.009351\n",
      "Iteration 245, loss = 0.02525406\n",
      "Validation score: -0.009695\n",
      "Iteration 246, loss = 0.02525384\n",
      "Validation score: -0.009998\n",
      "Iteration 247, loss = 0.02525458\n",
      "Validation score: -0.010105\n",
      "Iteration 248, loss = 0.02525294\n",
      "Validation score: -0.009271\n",
      "Iteration 249, loss = 0.02525440\n",
      "Validation score: -0.009178\n",
      "Iteration 250, loss = 0.02525395\n",
      "Validation score: -0.009181\n",
      "Iteration 251, loss = 0.02525445\n",
      "Validation score: -0.009161\n",
      "Iteration 252, loss = 0.02525388\n",
      "Validation score: -0.009395\n",
      "Iteration 253, loss = 0.02525499\n",
      "Validation score: -0.008926\n",
      "Iteration 254, loss = 0.02525425\n",
      "Validation score: -0.008875\n",
      "Iteration 255, loss = 0.02525446\n",
      "Validation score: -0.008788\n",
      "Iteration 256, loss = 0.02525703\n",
      "Validation score: -0.008487\n",
      "Iteration 257, loss = 0.02525443\n",
      "Validation score: -0.008691\n",
      "Iteration 258, loss = 0.02525394\n",
      "Validation score: -0.008901\n",
      "Iteration 259, loss = 0.02525398\n",
      "Validation score: -0.009148\n",
      "Iteration 260, loss = 0.02525372\n",
      "Validation score: -0.009578\n",
      "Iteration 261, loss = 0.02525473\n",
      "Validation score: -0.009496\n",
      "Iteration 262, loss = 0.02525423\n",
      "Validation score: -0.009425\n",
      "Iteration 263, loss = 0.02525433\n",
      "Validation score: -0.009625\n",
      "Iteration 264, loss = 0.02525381\n",
      "Validation score: -0.009728\n",
      "Iteration 265, loss = 0.02525403\n",
      "Validation score: -0.009977\n",
      "Iteration 266, loss = 0.02525485\n",
      "Validation score: -0.010213\n",
      "Iteration 267, loss = 0.02525414\n",
      "Validation score: -0.010479\n",
      "Iteration 268, loss = 0.02525627\n",
      "Validation score: -0.010731\n",
      "Iteration 269, loss = 0.02525470\n",
      "Validation score: -0.010342\n",
      "Iteration 270, loss = 0.02525472\n",
      "Validation score: -0.009770\n",
      "Iteration 271, loss = 0.02525401\n",
      "Validation score: -0.009391\n",
      "Iteration 272, loss = 0.02525605\n",
      "Validation score: -0.009894\n",
      "Iteration 273, loss = 0.02525417\n",
      "Validation score: -0.009497\n",
      "Iteration 274, loss = 0.02525386\n",
      "Validation score: -0.009511\n",
      "Iteration 275, loss = 0.02525413\n",
      "Validation score: -0.009295\n",
      "Iteration 276, loss = 0.02525427\n",
      "Validation score: -0.009292\n",
      "Iteration 277, loss = 0.02525394\n",
      "Validation score: -0.009054\n",
      "Iteration 278, loss = 0.02525408\n",
      "Validation score: -0.008981\n",
      "Iteration 279, loss = 0.02525521\n",
      "Validation score: -0.008359\n",
      "Iteration 280, loss = 0.02525606\n",
      "Validation score: -0.007961\n",
      "Iteration 281, loss = 0.02525547\n",
      "Validation score: -0.008218\n",
      "Iteration 282, loss = 0.02525488\n",
      "Validation score: -0.008441\n",
      "Iteration 283, loss = 0.02525438\n",
      "Validation score: -0.008622\n",
      "Iteration 284, loss = 0.02525372\n",
      "Validation score: -0.008985\n",
      "Iteration 285, loss = 0.02525401\n",
      "Validation score: -0.009512\n",
      "Iteration 286, loss = 0.02525391\n",
      "Validation score: -0.009451\n",
      "Iteration 287, loss = 0.02525507\n",
      "Validation score: -0.009968\n",
      "Iteration 288, loss = 0.02525387\n",
      "Validation score: -0.009927\n",
      "Iteration 289, loss = 0.02525414\n",
      "Validation score: -0.009908\n",
      "Iteration 290, loss = 0.02525394\n",
      "Validation score: -0.009809\n",
      "Iteration 291, loss = 0.02525402\n",
      "Validation score: -0.009895\n",
      "Iteration 292, loss = 0.02525370\n",
      "Validation score: -0.010125\n",
      "Iteration 293, loss = 0.02525430\n",
      "Validation score: -0.010148\n",
      "Iteration 294, loss = 0.02525404\n",
      "Validation score: -0.010076\n",
      "Iteration 295, loss = 0.02525408\n",
      "Validation score: -0.009702\n",
      "Iteration 296, loss = 0.02525401\n",
      "Validation score: -0.009504\n",
      "Iteration 297, loss = 0.02525391\n",
      "Validation score: -0.010008\n",
      "Iteration 298, loss = 0.02525490\n",
      "Validation score: -0.010197\n",
      "Iteration 299, loss = 0.02525525\n",
      "Validation score: -0.010008\n",
      "Iteration 300, loss = 0.02525683\n",
      "Validation score: -0.010793\n",
      "Iteration 301, loss = 0.02525444\n",
      "Validation score: -0.010588\n",
      "Iteration 302, loss = 0.02525460\n",
      "Validation score: -0.010726\n",
      "Iteration 303, loss = 0.02525451\n",
      "Validation score: -0.009482\n",
      "Iteration 304, loss = 0.02525377\n",
      "Validation score: -0.009704\n",
      "Iteration 305, loss = 0.02525401\n",
      "Validation score: -0.009301\n",
      "Iteration 306, loss = 0.02525435\n",
      "Validation score: -0.009318\n",
      "Iteration 307, loss = 0.02525400\n",
      "Validation score: -0.009221\n",
      "Iteration 308, loss = 0.02525521\n",
      "Validation score: -0.008878\n",
      "Iteration 309, loss = 0.02525415\n",
      "Validation score: -0.008964\n",
      "Iteration 310, loss = 0.02525442\n",
      "Validation score: -0.009395\n",
      "Iteration 311, loss = 0.02525404\n",
      "Validation score: -0.009099\n",
      "Iteration 312, loss = 0.02525430\n",
      "Validation score: -0.009105\n",
      "Iteration 313, loss = 0.02525390\n",
      "Validation score: -0.008960\n",
      "Iteration 314, loss = 0.02525485\n",
      "Validation score: -0.008667\n",
      "Iteration 315, loss = 0.02525442\n",
      "Validation score: -0.008659\n",
      "Iteration 316, loss = 0.02525417\n",
      "Validation score: -0.008751\n",
      "Iteration 317, loss = 0.02525422\n",
      "Validation score: -0.008806\n",
      "Iteration 318, loss = 0.02525389\n",
      "Validation score: -0.008893\n",
      "Iteration 319, loss = 0.02525397\n",
      "Validation score: -0.008823\n",
      "Iteration 320, loss = 0.02525498\n",
      "Validation score: -0.009231\n",
      "Iteration 321, loss = 0.02525438\n",
      "Validation score: -0.009678\n",
      "Iteration 322, loss = 0.02525410\n",
      "Validation score: -0.009586\n",
      "Iteration 323, loss = 0.02525376\n",
      "Validation score: -0.009578\n",
      "Iteration 324, loss = 0.02525377\n",
      "Validation score: -0.009483\n",
      "Iteration 325, loss = 0.02525383\n",
      "Validation score: -0.009273\n",
      "Iteration 326, loss = 0.02525414\n",
      "Validation score: -0.009219\n",
      "Iteration 327, loss = 0.02525365\n",
      "Validation score: -0.009929\n",
      "Iteration 328, loss = 0.02525376\n",
      "Validation score: -0.009788\n",
      "Iteration 329, loss = 0.02525308\n",
      "Validation score: -0.009287\n",
      "Iteration 330, loss = 0.02525384\n",
      "Validation score: -0.009293\n",
      "Iteration 331, loss = 0.02525379\n",
      "Validation score: -0.009224\n",
      "Iteration 332, loss = 0.02525361\n",
      "Validation score: -0.009516\n",
      "Iteration 333, loss = 0.02525434\n",
      "Validation score: -0.009539\n",
      "Iteration 334, loss = 0.02525330\n",
      "Validation score: -0.009821\n",
      "Iteration 335, loss = 0.02525372\n",
      "Validation score: -0.009959\n",
      "Iteration 336, loss = 0.02525405\n",
      "Validation score: -0.009734\n",
      "Iteration 337, loss = 0.02525392\n",
      "Validation score: -0.010052\n",
      "Iteration 338, loss = 0.02525466\n",
      "Validation score: -0.009942\n",
      "Iteration 339, loss = 0.02525361\n",
      "Validation score: -0.010200\n",
      "Iteration 340, loss = 0.02525454\n",
      "Validation score: -0.010126\n",
      "Iteration 341, loss = 0.02525408\n",
      "Validation score: -0.010049\n",
      "Iteration 342, loss = 0.02525364\n",
      "Validation score: -0.010029\n",
      "Iteration 343, loss = 0.02525412\n",
      "Validation score: -0.010232\n",
      "Iteration 344, loss = 0.02525351\n",
      "Validation score: -0.009943\n",
      "Iteration 345, loss = 0.02525373\n",
      "Validation score: -0.009882\n",
      "Iteration 346, loss = 0.02525384\n",
      "Validation score: -0.009965\n",
      "Iteration 347, loss = 0.02525407\n",
      "Validation score: -0.010170\n",
      "Iteration 348, loss = 0.02525413\n",
      "Validation score: -0.009726\n",
      "Iteration 349, loss = 0.02525404\n",
      "Validation score: -0.009820\n",
      "Iteration 350, loss = 0.02525380\n",
      "Validation score: -0.009444\n",
      "Iteration 351, loss = 0.02525411\n",
      "Validation score: -0.009475\n",
      "Iteration 352, loss = 0.02525341\n",
      "Validation score: -0.009335\n",
      "Iteration 353, loss = 0.02525372\n",
      "Validation score: -0.009350\n",
      "Iteration 354, loss = 0.02525434\n",
      "Validation score: -0.009186\n",
      "Iteration 355, loss = 0.02525336\n",
      "Validation score: -0.009586\n",
      "Iteration 356, loss = 0.02525381\n",
      "Validation score: -0.009725\n",
      "Iteration 357, loss = 0.02525350\n",
      "Validation score: -0.009729\n",
      "Iteration 358, loss = 0.02525455\n",
      "Validation score: -0.009336\n",
      "Iteration 359, loss = 0.02525452\n",
      "Validation score: -0.009829\n",
      "Iteration 360, loss = 0.02525431\n",
      "Validation score: -0.009421\n",
      "Iteration 361, loss = 0.02525401\n",
      "Validation score: -0.009117\n",
      "Iteration 362, loss = 0.02525360\n",
      "Validation score: -0.009401\n",
      "Iteration 363, loss = 0.02525381\n",
      "Validation score: -0.009554\n",
      "Iteration 364, loss = 0.02525355\n",
      "Validation score: -0.009436\n",
      "Iteration 365, loss = 0.02525387\n",
      "Validation score: -0.009530\n",
      "Iteration 366, loss = 0.02525525\n",
      "Validation score: -0.010030\n",
      "Iteration 367, loss = 0.02525320\n",
      "Validation score: -0.009636\n",
      "Iteration 368, loss = 0.02525421\n",
      "Validation score: -0.010034\n",
      "Iteration 369, loss = 0.02525385\n",
      "Validation score: -0.009905\n",
      "Iteration 370, loss = 0.02525401\n",
      "Validation score: -0.009835\n",
      "Iteration 371, loss = 0.02525374\n",
      "Validation score: -0.009590\n",
      "Iteration 372, loss = 0.02525399\n",
      "Validation score: -0.009895\n",
      "Iteration 373, loss = 0.02525417\n",
      "Validation score: -0.009856\n",
      "Iteration 374, loss = 0.02525297\n",
      "Validation score: -0.009366\n",
      "Iteration 375, loss = 0.02525435\n",
      "Validation score: -0.008811\n",
      "Iteration 376, loss = 0.02525401\n",
      "Validation score: -0.008634\n",
      "Iteration 377, loss = 0.02525468\n",
      "Validation score: -0.008934\n",
      "Iteration 378, loss = 0.02525362\n",
      "Validation score: -0.009026\n",
      "Iteration 379, loss = 0.02525347\n",
      "Validation score: -0.009290\n",
      "Iteration 380, loss = 0.02525374\n",
      "Validation score: -0.009278\n",
      "Iteration 381, loss = 0.02525397\n",
      "Validation score: -0.009680\n",
      "Iteration 382, loss = 0.02525386\n",
      "Validation score: -0.009592\n",
      "Iteration 383, loss = 0.02525424\n",
      "Validation score: -0.009979\n",
      "Iteration 384, loss = 0.02525459\n",
      "Validation score: -0.009691\n",
      "Iteration 385, loss = 0.02525350\n",
      "Validation score: -0.009677\n",
      "Iteration 386, loss = 0.02525387\n",
      "Validation score: -0.009484\n",
      "Iteration 387, loss = 0.02525364\n",
      "Validation score: -0.009720\n",
      "Iteration 388, loss = 0.02525396\n",
      "Validation score: -0.010032\n",
      "Iteration 389, loss = 0.02525334\n",
      "Validation score: -0.009760\n",
      "Iteration 390, loss = 0.02525282\n",
      "Validation score: -0.009154\n",
      "Iteration 391, loss = 0.02525341\n",
      "Validation score: -0.009385\n",
      "Iteration 392, loss = 0.02525455\n",
      "Validation score: -0.009844\n",
      "Iteration 393, loss = 0.02525373\n",
      "Validation score: -0.009869\n",
      "Iteration 394, loss = 0.02525338\n",
      "Validation score: -0.010088\n",
      "Iteration 395, loss = 0.02525450\n",
      "Validation score: -0.010380\n",
      "Iteration 396, loss = 0.02525381\n",
      "Validation score: -0.010384\n",
      "Iteration 397, loss = 0.02525366\n",
      "Validation score: -0.009823\n",
      "Iteration 398, loss = 0.02525352\n",
      "Validation score: -0.009678\n",
      "Iteration 399, loss = 0.02525336\n",
      "Validation score: -0.009398\n",
      "Iteration 400, loss = 0.02525366\n",
      "Validation score: -0.009546\n",
      "Iteration 401, loss = 0.02525465\n",
      "Validation score: -0.009853\n",
      "Iteration 402, loss = 0.02525348\n",
      "Validation score: -0.009890\n",
      "Iteration 403, loss = 0.02525342\n",
      "Validation score: -0.009700\n",
      "Iteration 404, loss = 0.02525389\n",
      "Validation score: -0.009939\n",
      "Iteration 405, loss = 0.02525465\n",
      "Validation score: -0.009836\n",
      "Iteration 406, loss = 0.02525365\n",
      "Validation score: -0.009864\n",
      "Iteration 407, loss = 0.02525430\n",
      "Validation score: -0.009494\n",
      "Iteration 408, loss = 0.02525417\n",
      "Validation score: -0.009845\n",
      "Iteration 409, loss = 0.02525312\n",
      "Validation score: -0.009312\n",
      "Iteration 410, loss = 0.02525399\n",
      "Validation score: -0.009694\n",
      "Iteration 411, loss = 0.02525381\n",
      "Validation score: -0.009995\n",
      "Iteration 412, loss = 0.02525349\n",
      "Validation score: -0.010037\n",
      "Iteration 413, loss = 0.02525359\n",
      "Validation score: -0.010019\n",
      "Iteration 414, loss = 0.02525417\n",
      "Validation score: -0.010342\n",
      "Iteration 415, loss = 0.02525349\n",
      "Validation score: -0.010109\n",
      "Iteration 416, loss = 0.02525327\n",
      "Validation score: -0.009969\n",
      "Iteration 417, loss = 0.02525343\n",
      "Validation score: -0.009970\n",
      "Iteration 418, loss = 0.02525453\n",
      "Validation score: -0.010252\n",
      "Iteration 419, loss = 0.02525408\n",
      "Validation score: -0.009931\n",
      "Iteration 420, loss = 0.02525349\n",
      "Validation score: -0.010021\n",
      "Iteration 421, loss = 0.02525392\n",
      "Validation score: -0.009517\n",
      "Iteration 422, loss = 0.02525342\n",
      "Validation score: -0.009714\n",
      "Iteration 423, loss = 0.02525432\n",
      "Validation score: -0.009677\n",
      "Iteration 424, loss = 0.02525537\n",
      "Validation score: -0.010404\n",
      "Iteration 425, loss = 0.02525498\n",
      "Validation score: -0.010917\n",
      "Iteration 426, loss = 0.02525393\n",
      "Validation score: -0.010472\n",
      "Iteration 427, loss = 0.02525421\n",
      "Validation score: -0.009992\n",
      "Iteration 428, loss = 0.02525340\n",
      "Validation score: -0.009851\n",
      "Iteration 429, loss = 0.02525334\n",
      "Validation score: -0.010313\n",
      "Iteration 430, loss = 0.02525391\n",
      "Validation score: -0.010446\n",
      "Iteration 431, loss = 0.02525409\n",
      "Validation score: -0.010313\n",
      "Iteration 432, loss = 0.02525254\n",
      "Validation score: -0.009763\n",
      "Iteration 433, loss = 0.02525355\n",
      "Validation score: -0.009873\n",
      "Iteration 434, loss = 0.02525328\n",
      "Validation score: -0.009723\n",
      "Iteration 435, loss = 0.02525368\n",
      "Validation score: -0.009421\n",
      "Iteration 436, loss = 0.02525303\n",
      "Validation score: -0.009762\n",
      "Iteration 437, loss = 0.02525286\n",
      "Validation score: -0.010175\n",
      "Iteration 438, loss = 0.02525367\n",
      "Validation score: -0.009752\n",
      "Iteration 439, loss = 0.02525345\n",
      "Validation score: -0.009743\n",
      "Iteration 440, loss = 0.02525335\n",
      "Validation score: -0.010208\n",
      "Iteration 441, loss = 0.02525356\n",
      "Validation score: -0.010056\n",
      "Iteration 442, loss = 0.02525375\n",
      "Validation score: -0.010077\n",
      "Iteration 443, loss = 0.02525368\n",
      "Validation score: -0.009966\n",
      "Iteration 444, loss = 0.02525429\n",
      "Validation score: -0.009550\n",
      "Iteration 445, loss = 0.02525381\n",
      "Validation score: -0.009343\n",
      "Iteration 446, loss = 0.02525374\n",
      "Validation score: -0.009380\n",
      "Iteration 447, loss = 0.02525348\n",
      "Validation score: -0.009502\n",
      "Iteration 448, loss = 0.02525394\n",
      "Validation score: -0.009669\n",
      "Iteration 449, loss = 0.02525364\n",
      "Validation score: -0.009534\n",
      "Iteration 450, loss = 0.02525328\n",
      "Validation score: -0.010006\n",
      "Iteration 451, loss = 0.02525411\n",
      "Validation score: -0.010132\n",
      "Iteration 452, loss = 0.02525372\n",
      "Validation score: -0.009504\n",
      "Iteration 453, loss = 0.02525327\n",
      "Validation score: -0.009349\n",
      "Iteration 454, loss = 0.02525332\n",
      "Validation score: -0.009175\n",
      "Iteration 455, loss = 0.02525394\n",
      "Validation score: -0.008959\n",
      "Iteration 456, loss = 0.02525403\n",
      "Validation score: -0.008776\n",
      "Iteration 457, loss = 0.02525429\n",
      "Validation score: -0.008557\n",
      "Iteration 458, loss = 0.02525411\n",
      "Validation score: -0.008632\n",
      "Iteration 459, loss = 0.02525454\n",
      "Validation score: -0.008446\n",
      "Iteration 460, loss = 0.02525521\n",
      "Validation score: -0.008052\n",
      "Iteration 461, loss = 0.02525567\n",
      "Validation score: -0.007901\n",
      "Iteration 462, loss = 0.02525538\n",
      "Validation score: -0.008074\n",
      "Iteration 463, loss = 0.02525489\n",
      "Validation score: -0.008362\n",
      "Iteration 464, loss = 0.02525446\n",
      "Validation score: -0.008366\n",
      "Iteration 465, loss = 0.02525432\n",
      "Validation score: -0.008589\n",
      "Iteration 466, loss = 0.02525435\n",
      "Validation score: -0.008555\n",
      "Iteration 467, loss = 0.02525316\n",
      "Validation score: -0.009273\n",
      "Iteration 468, loss = 0.02525342\n",
      "Validation score: -0.009185\n",
      "Iteration 469, loss = 0.02525383\n",
      "Validation score: -0.009372\n",
      "Iteration 470, loss = 0.02525402\n",
      "Validation score: -0.009880\n",
      "Iteration 471, loss = 0.02525310\n",
      "Validation score: -0.009997\n",
      "Iteration 472, loss = 0.02525395\n",
      "Validation score: -0.009775\n",
      "Iteration 473, loss = 0.02525321\n",
      "Validation score: -0.009789\n",
      "Iteration 474, loss = 0.02525326\n",
      "Validation score: -0.009821\n",
      "Iteration 475, loss = 0.02525347\n",
      "Validation score: -0.010249\n",
      "Iteration 476, loss = 0.02525339\n",
      "Validation score: -0.010506\n",
      "Iteration 477, loss = 0.02525473\n",
      "Validation score: -0.010196\n",
      "Iteration 478, loss = 0.02525332\n",
      "Validation score: -0.010608\n",
      "Iteration 479, loss = 0.02525337\n",
      "Validation score: -0.010325\n",
      "Iteration 480, loss = 0.02525319\n",
      "Validation score: -0.010087\n",
      "Iteration 481, loss = 0.02525355\n",
      "Validation score: -0.009796\n",
      "Iteration 482, loss = 0.02525353\n",
      "Validation score: -0.009948\n",
      "Iteration 483, loss = 0.02525380\n",
      "Validation score: -0.010075\n",
      "Iteration 484, loss = 0.02525355\n",
      "Validation score: -0.010430\n",
      "Iteration 485, loss = 0.02525311\n",
      "Validation score: -0.009813\n",
      "Iteration 486, loss = 0.02525293\n",
      "Validation score: -0.010176\n",
      "Iteration 487, loss = 0.02525353\n",
      "Validation score: -0.010344\n",
      "Iteration 488, loss = 0.02525357\n",
      "Validation score: -0.010205\n",
      "Iteration 489, loss = 0.02525331\n",
      "Validation score: -0.010333\n",
      "Iteration 490, loss = 0.02525331\n",
      "Validation score: -0.010148\n",
      "Iteration 491, loss = 0.02525474\n",
      "Validation score: -0.009461\n",
      "Iteration 492, loss = 0.02525332\n",
      "Validation score: -0.009200\n",
      "Iteration 493, loss = 0.02525327\n",
      "Validation score: -0.008936\n",
      "Iteration 494, loss = 0.02525361\n",
      "Validation score: -0.009011\n",
      "Iteration 495, loss = 0.02525459\n",
      "Validation score: -0.008925\n",
      "Iteration 496, loss = 0.02525355\n",
      "Validation score: -0.008763\n",
      "Iteration 497, loss = 0.02525348\n",
      "Validation score: -0.009075\n",
      "Iteration 498, loss = 0.02525362\n",
      "Validation score: -0.009230\n",
      "Iteration 499, loss = 0.02525314\n",
      "Validation score: -0.009469\n",
      "Iteration 500, loss = 0.02525403\n",
      "Validation score: -0.009542\n",
      "Iteration 501, loss = 0.02525326\n",
      "Validation score: -0.009542\n",
      "Iteration 502, loss = 0.02525328\n",
      "Validation score: -0.009599\n",
      "Iteration 503, loss = 0.02525331\n",
      "Validation score: -0.009708\n",
      "Iteration 504, loss = 0.02525359\n",
      "Validation score: -0.010090\n",
      "Iteration 505, loss = 0.02525358\n",
      "Validation score: -0.009972\n",
      "Iteration 506, loss = 0.02525396\n",
      "Validation score: -0.010281\n",
      "Iteration 507, loss = 0.02525434\n",
      "Validation score: -0.010123\n",
      "Iteration 508, loss = 0.02525339\n",
      "Validation score: -0.009930\n",
      "Iteration 509, loss = 0.02525308\n",
      "Validation score: -0.009640\n",
      "Iteration 510, loss = 0.02525294\n",
      "Validation score: -0.009821\n",
      "Iteration 511, loss = 0.02525320\n",
      "Validation score: -0.009813\n",
      "Iteration 512, loss = 0.02525490\n",
      "Validation score: -0.009659\n",
      "Iteration 513, loss = 0.02525325\n",
      "Validation score: -0.009634\n",
      "Iteration 514, loss = 0.02525359\n",
      "Validation score: -0.009253\n",
      "Iteration 515, loss = 0.02525452\n",
      "Validation score: -0.009633\n",
      "Iteration 516, loss = 0.02525319\n",
      "Validation score: -0.009577\n",
      "Iteration 517, loss = 0.02525317\n",
      "Validation score: -0.009624\n",
      "Iteration 518, loss = 0.02525325\n",
      "Validation score: -0.009667\n",
      "Iteration 519, loss = 0.02525354\n",
      "Validation score: -0.009486\n",
      "Iteration 520, loss = 0.02525299\n",
      "Validation score: -0.009744\n",
      "Iteration 521, loss = 0.02525312\n",
      "Validation score: -0.009479\n",
      "Iteration 522, loss = 0.02525339\n",
      "Validation score: -0.009144\n",
      "Iteration 523, loss = 0.02525395\n",
      "Validation score: -0.009012\n",
      "Iteration 524, loss = 0.02525354\n",
      "Validation score: -0.009105\n",
      "Iteration 525, loss = 0.02525420\n",
      "Validation score: -0.009655\n",
      "Iteration 526, loss = 0.02525317\n",
      "Validation score: -0.009474\n",
      "Iteration 527, loss = 0.02525319\n",
      "Validation score: -0.009271\n",
      "Iteration 528, loss = 0.02525391\n",
      "Validation score: -0.009261\n",
      "Iteration 529, loss = 0.02525326\n",
      "Validation score: -0.009103\n",
      "Iteration 530, loss = 0.02525341\n",
      "Validation score: -0.009244\n",
      "Iteration 531, loss = 0.02525377\n",
      "Validation score: -0.009486\n",
      "Iteration 532, loss = 0.02525396\n",
      "Validation score: -0.008762\n",
      "Iteration 533, loss = 0.02525363\n",
      "Validation score: -0.008849\n",
      "Iteration 534, loss = 0.02525347\n",
      "Validation score: -0.009131\n",
      "Iteration 535, loss = 0.02525330\n",
      "Validation score: -0.009463\n",
      "Iteration 536, loss = 0.02525507\n",
      "Validation score: -0.009410\n",
      "Iteration 537, loss = 0.02525321\n",
      "Validation score: -0.009356\n",
      "Iteration 538, loss = 0.02525318\n",
      "Validation score: -0.009430\n",
      "Iteration 539, loss = 0.02525396\n",
      "Validation score: -0.009843\n",
      "Iteration 540, loss = 0.02525333\n",
      "Validation score: -0.009920\n",
      "Iteration 541, loss = 0.02525319\n",
      "Validation score: -0.009793\n",
      "Iteration 542, loss = 0.02525313\n",
      "Validation score: -0.009877\n",
      "Iteration 543, loss = 0.02525331\n",
      "Validation score: -0.009820\n",
      "Iteration 544, loss = 0.02525325\n",
      "Validation score: -0.009409\n",
      "Iteration 545, loss = 0.02525301\n",
      "Validation score: -0.009516\n",
      "Validation score did not improve more than tol=0.000100 for 500 consecutive epochs. Stopping.\n",
      "[0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176\n",
      " 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176 0.62949176]\n"
     ]
    }
   ],
   "source": [
    "mlp_grid = {'hidden_layer_sizes': [(X_train.shape[1],X_train.shape[2])],\n",
    "          'activation': ['relu'],\n",
    "          'alpha': alphas,\n",
    "          'epsilon': [1e0],\n",
    "          'solver': ['adam'],\n",
    "          'max_iter':[5000]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(snn.MLPRegressor(),\n",
    "                                         cvn,\n",
    "                                         mlp_grid,X0_ss0,\n",
    "                                         y_train.ravel(),scoring,8)\n",
    "\n",
    "mlp = snn.MLPRegressor(hidden_layer_sizes=best_params[\"hidden_layer_sizes\"], \n",
    "                        activation=best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"],\n",
    "                        alpha=best_params['alpha'],\n",
    "                        epsilon=best_params[\"epsilon\"],\n",
    "                        max_iter=5000, \n",
    "                        n_iter_no_change=500, \n",
    "                        verbose=True,\n",
    "                        early_stopping=True,\n",
    "                        random_state=1,\n",
    "                        batch_size=len(X0_ss)//cvn)\n",
    "\n",
    "mlp.fit(X0_ss,y_train)\n",
    "results_mlp = mlp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "\n",
    "print(results_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:1571: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      ".............................................................................................................................................................................................................................................[Parallel(n_jobs=-1)]: Done  18 out of  40 | elapsed:  2.5min remaining:  3.0min\n",
      "...................................................................................................................................................................[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362]\n"
     ]
    }
   ],
   "source": [
    "lasso = slm.LassoCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    verbose=True,\n",
    "    random_state=1,\n",
    "    max_iter=100000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_ls = lasso.fit(X0_ss,y_train)\n",
    "results_ls = est_ls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]\n",
      " [0.64798973]]\n"
     ]
    }
   ],
   "source": [
    "ridge = slm.RidgeCV(\n",
    "    alphas=[1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4],\n",
    "    scoring=scoring,\n",
    "    cv=cvn)\n",
    "\n",
    "est_rr = ridge.fit(X0_ss,y_train)\n",
    "results_rr = est_rr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py:429: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "regr = ske.BaggingRegressor(base_estimator=svm.SVR(),n_estimators=10,random_state=1,max_samples=40)\n",
    "regr.fit(X0_ss,y_train)\n",
    "results_lars = regr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  40 | elapsed: 46.6min remaining: 56.9min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 48.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362]\n"
     ]
    }
   ],
   "source": [
    "lars = slm.LarsCV(\n",
    "    cv=cvn, \n",
    "    max_iter=1000,\n",
    "    max_n_alphas=10000,\n",
    "    verbose=True,\n",
    "    normalize=False,\n",
    "    eps=np.finfo(float).eps,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_lars = lars.fit(X0_ss,y_train)\n",
    "results_lars = est_lars.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 40 folds for each of 2 candidates, totalling 80 fits\n",
      "[[0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64722443]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64722443]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]\n",
      " [0.64723206]]\n"
     ]
    }
   ],
   "source": [
    "krr_grid = {'kernel': ['linear','rbf'],\n",
    "          'alpha': [alphas]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(skr.KernelRidge(),\n",
    "                                         cvn,\n",
    "                                         krr_grid,X0_ss0,\n",
    "                                         y_train.ravel(),scoring,8)\n",
    "krr = skr.KernelRidge(kernel=best_params['kernel'],alpha=best_params['alpha'])\n",
    "krr.fit(X0_ss, y_train)\n",
    "results_krr = krr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_krr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:1571: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      ".........................................................................................................................................................................................................................[Parallel(n_jobs=-1)]: Done  18 out of  40 | elapsed: 44.4min remaining: 54.2min\n",
      ".......................................................................................................................................................................................[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 56.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362\n",
      " 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362 0.64849362]\n"
     ]
    }
   ],
   "source": [
    "gsc = slm.ElasticNetCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    max_iter=10000,\n",
    "    verbose=True,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_en = gsc.fit(X0_ss,y_train)\n",
    "results_en = est_en.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls_grid = {'n_components': np.flip(np.arange(5,int(len(X_train)))),\n",
    "#             'scale': [True,False]}\n",
    "\n",
    "# best_params = util.gridsearch_pickparams(skd.PLSRegression(),cvn,\n",
    "#                                          pls_grid,X0_ss0,\n",
    "#                                          y_train.ravel(),scoring,8)\n",
    "# pls = skd.PLSRegression(n_components=best_params['n_components'],scale=best_params['scale'],max_iter=10000)\n",
    "# pls.fit(X0_ss, y_train)\n",
    "# results_pls = (pls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "\n",
    "# print(results_pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719\n",
      " 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719 0.64748719]\n"
     ]
    }
   ],
   "source": [
    "pcr = spl.make_pipeline(sdc.PCA(),slm.LinearRegression())\n",
    "pcr.fit(X0_ss, y_train)\n",
    "results_pcr = np.asarray(pcr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_pcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_omp.py:420: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  X, y[:, k], n_nonzero_coefs, tol, copy_X=copy_X, return_path=return_path\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   28.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934\n",
      " 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934 0.64856934]\n"
     ]
    }
   ],
   "source": [
    "omp = slm.OrthogonalMatchingPursuitCV(normalize=True,cv=cvn,max_iter=len(X_train)//2,verbose=True)\n",
    "omp.fit(X0_ss, y_train)\n",
    "results_omp = np.asarray(omp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_omp)\n",
    "results_omp = results_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64939958 0.64939958 0.64939958 0.64939958 0.64940482 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64940482 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958\n",
      " 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958 0.64939958]\n"
     ]
    }
   ],
   "source": [
    "rsr = slm.RANSACRegressor(random_state=1,min_samples=len(X0_ss)).fit(X0_ss, y_train)\n",
    "results_rsr = rsr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]])).ravel()\n",
    "print(results_rsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very slow on leave one out\n",
    "# ard_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4], 'lambda_1': alphas[-5:-4], 'lambda_2': alphas[-5:-4]}\n",
    "# best_params = util.gridsearch_pickparams(slm.ARDRegression(),cvn,\n",
    "#                                          ard_grid,scaler_ss,X_train,\n",
    "#                                          train_index,X_test,test_index,pre_updrs_off,y_train,scoring,8)\n",
    "# ard = slm.ARDRegression(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'],\n",
    "#                        lambda_1=best_params['lambda_1'],lambda_2=best_params['lambda_2'])\n",
    "# ard.fit(X0_ss,y_train)\n",
    "# results_ard = np.asarray(ard.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 40 folds for each of 18 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:concurrent.futures:exception calling callback for <Future at 0x7f93c67b4dd0 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\", line 360, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\", line 797, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1115, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "The exit codes of the workers are {SIGKILL(-9)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b6d999f96211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                          \u001b[0mcvn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0msvr_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX0_ss0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          y_train.ravel(),scoring,8)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_ss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RadDBS-QSM/src/jupyter/util.py\u001b[0m in \u001b[0;36mgridsearch_pickparams\u001b[0;34m(model, cvn, param_grid, X0_tt, y_train, scoring, n_js)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_tt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \"\"\"\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "svr_grid = {'kernel': ['linear','rbf'],\n",
    "          'epsilon': [1e-1,1.5e-1,2.5e-1],\n",
    "          'C': [1e0,1e1,1e2]}\n",
    "best_params = util.gridsearch_pickparams(svm.SVR(),\n",
    "                                         cvn,\n",
    "                                         svr_grid,X0_ss0,\n",
    "                                         y_train.ravel(),scoring,8)\n",
    "svr = svm.SVR(kernel=best_params['kernel'],epsilon=best_params['epsilon'])\n",
    "svr.fit(X0_ss, y_train)\n",
    "results_svr = np.asarray(svr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid = {'max_depth':[3,6,9,12,15,20,100]}\n",
    "best_params = util.gridsearch_pickparams(ske.GradientBoostingRegressor(random_state=1),cvn,\n",
    "                                         gbr_grid,X0_ss0,\n",
    "                                         y_train.ravel(),scoring,8)\n",
    "gbr = ske.GradientBoostingRegressor(random_state=1,learning_rate=0.001,max_depth=best_params['max_depth'],n_estimators=100)\n",
    "gbr.fit(X0_ss, y_train)\n",
    "results_gbr = np.asarray(gbr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max =util.eval_prediction(np.vstack((pre_imp[test_index].T,\n",
    "                               results_lr.T,\n",
    "                               results_mlp,\n",
    "                               results_ls,\n",
    "                               results_lars,\n",
    "                               results_en,\n",
    "                               results_rr.ravel(),\n",
    "                               results_krr.ravel(),\n",
    "                               results_pcr,\n",
    "                               #results_pls,\n",
    "                               results_omp,\n",
    "                               results_br,\n",
    "                               results_rsr,\n",
    "                               results_svr,\n",
    "                               results_gbr)),\n",
    "                               y_test.T,\n",
    "                               ['LCT','Regression','MLP','Lasso','BaggingRegressor',\n",
    "                                'ElasticNet','Ridge','KernelRidge','PCR',\n",
    "                                #'PLS',\n",
    "                                'OMP','Bayesian','RANSAC','SVR','GBR'],(70,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_train = stats.gaussian_kde(y_train)\n",
    "density_test = stats.gaussian_kde(y_test)\n",
    "n, x, _ = plt.hist(y_train, bins=np.linspace(-1,2,50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(x, density_train(x),color='tab:blue',label=r'$y_{train}$')\n",
    "n, y, _ = plt.hist(y_test, bins=np.linspace(-1,2,50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(y, density_test(y),color='tab:green',label=r'$y_{test}$')\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlim([-1,2])\n",
    "plt.ylim([0,5])\n",
    "plt.xlabel('DBS improvement',fontsize=24)\n",
    "plt.ylabel('Frequency',fontsize=24)\n",
    "plt.title('Dataset distributions',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,q = util.make_pdfs(X0_ss.ravel(),X_test_ss0.ravel(),1e3)\n",
    "util.kl_divergence(p[abs(p)>1e-16],q[abs(p)>1e-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
