{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "import sklearn.pipeline as spl\n",
    "import sklearn.kernel_ridge as skr\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.neural_network as snn\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.decomposition as sdc\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.utils import resample\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "#     Performed poorly using Standard and MinMax scalers. Trying with LOOCV to see if predictions stabilize.\n",
    "#     Does not appear to stabilize predictions with LOOCV (using StandardScaler())\n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function?\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,False)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "K_all_c = K_all[c_cases_idx,:,:]\n",
    "R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,train_index,test_index = util.set_split(X_all_c,per_change,1,5/len(X_all_c))\n",
    "\n",
    "# Cross validation\n",
    "X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                             X_train,train_index,X_test,test_index,pre_updrs_off)\n",
    "X0_ss0, y_train = resample(X0_ss0,y_train,replace=True,n_samples=80,random_state=1)\n",
    "cvn = len(X0_ss0)-1\n",
    "# Feature selection\n",
    "sel = skf.SelectKBest(skf.f_regression,k=X0_ss0.shape[1])\n",
    "X0_ss = X0_ss0 #sel.fit_transform(X0_ss0,y_train)\n",
    "X_test_ss = X_test_ss0#(sel.transform(X_test_ss0.reshape(X_test_ss0.shape[0],X_test_ss0.shape[1]*X_test_ss0.shape[2]))).reshape((X_test_ss0.shape[0],1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.68656716 0.65517241 0.42857143 0.5       ]\n",
      "0.5540622013087273\n",
      "0.6502412337535141\n"
     ]
    }
   ],
   "source": [
    "scoring = 'neg_mean_squared_error'\n",
    "print(y_test)\n",
    "print(y_test.mean())\n",
    "print(y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-9,-2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63532058 0.95948728 0.88294836 0.43118717 0.68752231]\n"
     ]
    }
   ],
   "source": [
    "lr = slm.LinearRegression()\n",
    "est_lr = lr.fit(X0_ss,y_train)\n",
    "results_lr = est_lr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 79 folds for each of 1 candidates, totalling 79 fits\n",
      "[0.63544087 0.95910871 0.88311066 0.43124536 0.68738652]\n"
     ]
    }
   ],
   "source": [
    "br_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(slm.BayesianRidge(),cvn,\n",
    "                                         br_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "br = slm.BayesianRidge(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'])\n",
    "br.fit(X0_ss, y_train)\n",
    "results_br = np.asarray(br.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 79 folds for each of 10 candidates, totalling 790 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c5aae99a291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m best_params = util.gridsearch_pickparams(snn.MLPRegressor(),\n\u001b[1;32m      9\u001b[0m                                          \u001b[0mcvn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                          mlp_grid,X0_ss,y_train.ravel(),scoring,8)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m mlp = snn.MLPRegressor(hidden_layer_sizes=best_params[\"hidden_layer_sizes\"], \n",
      "\u001b[0;32m~/RadDBS-QSM/src/jupyter/util.py\u001b[0m in \u001b[0;36mgridsearch_pickparams\u001b[0;34m(model, cvn, param_grid, X0_tt, y_train, scoring, n_js)\u001b[0m\n\u001b[1;32m    559\u001b[0m         refit=False)\n\u001b[1;32m    560\u001b[0m     \u001b[0;31m# X0_tt,scaler,X_test_in = model_scale(scaler_type,X_train,train_index,X_test,test_index,pre_metric)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_tt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_grid = {'hidden_layer_sizes': [(X_train.shape[1],X_train.shape[2])],\n",
    "          'activation': ['relu'],\n",
    "          'alpha': alphas,\n",
    "          'epsilon': [1e0],\n",
    "          'solver': ['sgd'],\n",
    "          'max_iter':[5000]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(snn.MLPRegressor(),\n",
    "                                         cvn,\n",
    "                                         mlp_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "\n",
    "mlp = snn.MLPRegressor(hidden_layer_sizes=best_params[\"hidden_layer_sizes\"], \n",
    "                        activation=best_params[\"activation\"],\n",
    "                        solver=best_params[\"solver\"],\n",
    "                        alpha=best_params['alpha'],\n",
    "                        epsilon=best_params[\"epsilon\"],\n",
    "                        max_iter=5000, \n",
    "                        n_iter_no_change=500, \n",
    "                        verbose=True,\n",
    "                        early_stopping=True,\n",
    "                        random_state=1,\n",
    "                        batch_size=len(X0_ss)//cvn)\n",
    "\n",
    "mlp.fit(X0_ss,y_train)\n",
    "results_mlp = mlp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "\n",
    "print(results_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = slm.LassoCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    verbose=True,\n",
    "    random_state=1,\n",
    "    max_iter=100000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_ls = lasso.fit(X0_ss,y_train)\n",
    "results_ls = est_ls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = slm.RidgeCV(\n",
    "    alphas=[1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4],\n",
    "    scoring=scoring,\n",
    "    cv=cvn)\n",
    "\n",
    "est_rr = ridge.fit(X0_ss,y_train)\n",
    "results_rr = est_rr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lars = slm.LarsCV(\n",
    "    cv=cvn, \n",
    "    max_iter=1000,\n",
    "    max_n_alphas=10000,\n",
    "    verbose=True,\n",
    "    normalize=False,\n",
    "    eps=np.finfo(float).eps,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_lars = lars.fit(X0_ss,y_train)\n",
    "results_lars = est_lars.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr_grid = {'kernel': ['linear','rbf'],\n",
    "          'alpha': [alphas]}\n",
    "\n",
    "best_params = util.gridsearch_pickparams(skr.KernelRidge(),\n",
    "                                         cvn,\n",
    "                                         krr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "krr = skr.KernelRidge(kernel=best_params['kernel'],alpha=best_params['alpha'])\n",
    "krr.fit(X0_ss, y_train)\n",
    "results_krr = krr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_krr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = slm.ElasticNetCV(\n",
    "    alphas=alphas,\n",
    "    cv=cvn, \n",
    "    max_iter=10000,\n",
    "    verbose=True,\n",
    "    n_jobs=-1)\n",
    "\n",
    "est_en = gsc.fit(X0_ss,y_train)\n",
    "results_en = est_en.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))\n",
    "print(results_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls_grid = {'n_components': np.flip(np.arange(5,int(len(X_train)))),\n",
    "#             'scale': [True,False]}\n",
    "# best_params = util.gridsearch_pickparams(skd.PLSRegression(),cvn,\n",
    "#                                          pls_grid,scaler_ss,X_train,\n",
    "#                                          train_index,X_test,test_index,pre_updrs_off,y_train,scoring,-1)\n",
    "# pls = skd.PLSRegression(n_components=best_params['n_components'],scale=best_params['scale'],max_iter=10000)\n",
    "# pls.fit(X0_ss, y_train)\n",
    "# results_pls = (pls.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "# print(results_pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr = spl.make_pipeline(sdc.PCA(),slm.LinearRegression())\n",
    "pcr.fit(X0_ss, y_train)\n",
    "results_pcr = np.asarray(pcr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_pcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omp = slm.OrthogonalMatchingPursuitCV(normalize=True,cv=cvn,max_iter=len(X_train)//2,verbose=True)\n",
    "# omp.fit(X0_ss, y_train)\n",
    "# results_omp = np.asarray(omp.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "# print(results_omp)\n",
    "results_omp = results_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsr = slm.RANSACRegressor(random_state=1,min_samples=len(X0_ss)).fit(X0_ss, y_train)\n",
    "results_rsr = rsr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]])).ravel()\n",
    "print(results_rsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very slow on leave one out\n",
    "# ard_grid = {'alpha_1': alphas[-5:-4], 'alpha_2': alphas[-5:-4], 'lambda_1': alphas[-5:-4], 'lambda_2': alphas[-5:-4]}\n",
    "# best_params = util.gridsearch_pickparams(slm.ARDRegression(),cvn,\n",
    "#                                          ard_grid,scaler_ss,X_train,\n",
    "#                                          train_index,X_test,test_index,pre_updrs_off,y_train,scoring,8)\n",
    "# ard = slm.ARDRegression(alpha_1=best_params['alpha_1'],alpha_2=best_params['alpha_2'],\n",
    "#                        lambda_1=best_params['lambda_1'],lambda_2=best_params['lambda_2'])\n",
    "# ard.fit(X0_ss,y_train)\n",
    "# results_ard = np.asarray(ard.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "#                                            X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svr_grid = {'kernel': ['linear','rbf'],\n",
    "          'epsilon': [3e-1]}\n",
    "best_params = util.gridsearch_pickparams(svm.SVR(),\n",
    "                                         cvn,\n",
    "                                         svr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "svr = svm.SVR(kernel=best_params['kernel'],epsilon=best_params['epsilon'])\n",
    "svr.fit(X0_ss, y_train)\n",
    "results_svr = np.asarray(svr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()\n",
    "print(results_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_grid = {'max_depth':[3,6,9,12,15,20,100]}\n",
    "best_params = util.gridsearch_pickparams(ske.GradientBoostingRegressor(random_state=1),cvn,\n",
    "                                         gbr_grid,X0_ss,y_train.ravel(),scoring,8)\n",
    "gbr = ske.GradientBoostingRegressor(random_state=1,learning_rate=0.001,max_depth=best_params['max_depth'],n_estimators=100)\n",
    "gbr.fit(X0_ss, y_train)\n",
    "results_gbr = np.asarray(gbr.predict(X_test_ss.reshape([X_test_ss.shape[0],\n",
    "                                           X_test_ss.shape[1]*X_test_ss.shape[2]]))).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp[test_index],\n",
    "                               results_lr.ravel(),\n",
    "                               results_mlp,\n",
    "                               results_ls,\n",
    "                               results_lars,\n",
    "                               results_en,\n",
    "                               results_rr.ravel(),\n",
    "                               #results_krr.ravel(),\n",
    "                               results_pcr,\n",
    "                               #results_pls,\n",
    "                               #results_omp,\n",
    "                               results_br,\n",
    "                               results_rsr,\n",
    "                               results_svr,\n",
    "                               results_gbr)),\n",
    "                               y_test,\n",
    "                               ['LCT',\n",
    "                                'Regression',\n",
    "                                'MLP',\n",
    "                                'Lasso',\n",
    "                                'LARS',\n",
    "                                'ElasticNet',\n",
    "                                'Ridge',\n",
    "                                #'KernelRidge',\n",
    "                                'PCR',\n",
    "                                #'PLS',\n",
    "                                #'OMP',\n",
    "                                'Bayesian',\n",
    "                                'RANSAC',\n",
    "                                'SVR',\n",
    "                                'GBR'],(70,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_train = stats.gaussian_kde(y_train)\n",
    "density_test = stats.gaussian_kde(y_test)\n",
    "n, x, _ = plt.hist(y_train, bins=np.linspace(-1, 2, 50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(x, density_train(x),color='tab:blue',label=r'$y_{train}$')\n",
    "n, y, _ = plt.hist(y_test, bins=np.linspace(-1, 2, 50), \n",
    "                   histtype=u'step', density=True,color='tab:blue',linewidth=0)  \n",
    "plt.plot(y, density_test(y),color='tab:green',label=r'$y_{test}$')\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlim([-1,2])\n",
    "plt.ylim([0,3])\n",
    "plt.xlabel('DBS improvement',fontsize=24)\n",
    "plt.ylabel('Frequency',fontsize=24)\n",
    "plt.title('Dataset distributions',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,q = util.make_pdfs(X0_ss0,X_test_ss0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.kl_divergence(p[p>1e-16],q[p>1e-16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X_test.npy',X_test)\n",
    "# np.save('X_train.npy',X_train)\n",
    "# np.save('y_test.npy',y_test)\n",
    "# np.save('y_train.npy',y_train)\n",
    "# np.save('test_index.npy',test_index)\n",
    "# np.save('train_index.npy',train_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
