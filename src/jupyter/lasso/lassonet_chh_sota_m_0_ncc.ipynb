{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping torch import\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "from lassonet import LassoNetRegressor, LassoNetRegressorCV\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.optim import SGD, Adam\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import traceback\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7961/3066526659.py:24: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000001 for case 1.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000002 for case 2.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000003 for case 3.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000004 for case 4.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000005 for case 5.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000006 for case 6.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000007 for case 7.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000008 for case 8.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000009 for case 9.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000010 for case 10.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000011 for case 11.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000013 for case 13.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000014 for case 14.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000016 for case 16.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000018 for case 18.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000019 for case 19.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000020 for case 20.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000021 for case 21.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000022 for case 22.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000023 for case 23.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000024 for case 24.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000025 for case 25.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000026 for case 26.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000027 for case 27.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000028 for case 28.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000029 for case 29.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000030 for case 30.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000031 for case 31.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000032 for case 32.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000033 for case 33.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000034 for case 34.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000035 for case 35.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000036 for case 36.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000037 for case 37.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000038 for case 38.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000039 for case 39.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000040 for case 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7961/3066526659.py:30: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  pre_updrs_iii_off =  np.asarray(df[df.columns[3]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)\n",
      "/tmp/ipykernel_7961/3066526659.py:31: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  pre_updrs_iii_on =  np.asarray(df[df.columns[4]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)\n",
      "/tmp/ipykernel_7961/3066526659.py:32: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  post_updrs_iii_off =  np.asarray(df[df.columns[6]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Augment with CHH data\n",
    "X0_gt = np.load('/data/Ali/RadDBS-QSM/data/npy/old/X0_gt_chh_rois.npy')\n",
    "df = pd.read_csv('/data/Ali/RadDBS-QSM/data/xlxs/updrs_iii_chh.csv')\n",
    "# Patient IDs\n",
    "subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "n_rois = 6\n",
    "# Data\n",
    "s_directory = open('/data/Ali/RadDBS-QSM/data/roi/roi_list','r').read().splitlines()\n",
    "# Load\n",
    "with open('/data/Ali/RadDBS-QSM/data/pickles/segs_chh', \"rb\") as fp:  \n",
    "    segs = pickle.load(fp)\n",
    "    n_cases = len(segs)\n",
    "with open('/data/Ali/RadDBS-QSM/data/pickles/qsms_chh', \"rb\") as fp:  \n",
    "    qsms = pickle.load(fp)\n",
    "with open('/data/Ali/RadDBS-QSM/data/phi/chh/_ts/Phi_mcl_gt_roi_chh', \"rb\") as fp:  \n",
    "    Phi_gt = pickle.load(fp)\n",
    "L = int(len(X0_gt)/n_cases)\n",
    "n_features = int(L/n_rois)\n",
    "# Only extract ROI if it is present in all cases\n",
    "seg_labels_all = segs[0]\n",
    "case_number = np.zeros_like(np.asarray(s_directory))\n",
    "for i in range(n_cases):\n",
    "    case_number[i] = float(s_directory[i][-2:])\n",
    "subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "for i in range(n_cases):\n",
    "    try:\n",
    "        print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "    except:\n",
    "        print('Case',subject_id[i],'quarantined')\n",
    "pre_updrs_iii_off =  np.asarray(df[df.columns[3]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)                             \n",
    "pre_updrs_iii_on =  np.asarray(df[df.columns[4]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "post_updrs_iii_off =  np.asarray(df[df.columns[6]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "\n",
    "per_change = (pre_updrs_iii_off-post_updrs_iii_off)/pre_updrs_iii_off\n",
    "pre_updrs_off = pre_updrs_iii_off\n",
    "X_all_c = X0_gt.reshape(n_cases,n_rois,n_features)\n",
    "X_all_c = X_all_c[:,0:4,:]\n",
    "\n",
    "lct_change = (pre_updrs_iii_off-pre_updrs_iii_on)/pre_updrs_iii_off\n",
    "pre_imp = lct_change\n",
    "# X_all_c = X_all_c.reshape(X_all_c.shape[0],z-1)\n",
    "# X_all_c = np.append(X_all_c,pre_imp.reshape(-1,1),axis=1)\n",
    "subsc = subject_id_corr\n",
    "subs_init = subsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training parameters\n",
    "# scoring = 'r2'\n",
    "# results_bls = np.zeros_like(per_change)\n",
    "# results_ls = np.zeros_like(per_change)\n",
    "# scaler = skp.StandardScaler()\n",
    "# #X = X_all_c.astype(float)#scaler.fit_transform(np.asarray(X_all_c,dtype=float).reshape(X_all_c.shape[0],-1))\n",
    "# epsilon = 1e-1\n",
    "# ledd = np.zeros_like(per_change)\n",
    "# cvn = 6\n",
    "# # Train\n",
    "# for j in np.arange(len(subsc)):\n",
    "#     test_id = subsc[j]\n",
    "#     test_index = subsc == test_id\n",
    "#     train_index = subsc != test_id\n",
    "#     X_train = X_all_c[train_index,:,:]\n",
    "#     X_test = X_all_c[test_index,:,:]\n",
    "#     y_train = per_change[train_index]\n",
    "#     y_test = per_change[test_index]\n",
    "#     # Try this with common scaling\n",
    "#     X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "#                                                 X_train,train_index,X_test,\n",
    "#                                                 test_index,pre_updrs_off,ledd,None,None,None,None,None,None,None,None,False,False,False)\n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#       # Feature selection\n",
    "#       sel = skf.SelectKBest(skf.r_regression,k='all')\n",
    "#       X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "#       X_test_ss = sel.transform(X_test_ss0)\n",
    "#       y_n = cKDTree(X0_ss).query(X_test_ss, k=1)[1]\n",
    "    \n",
    "#       Xy = np.dot(X0_ss.T,y_train)\n",
    "#     if Xy.ndim == 1:\n",
    "#         Xy = Xy[:, np.newaxis]\n",
    "#     alpha_max = np.sqrt(np.sum(Xy**2, axis=1)).max()/len(y_train) \n",
    "#     alphas = np.linspace(alpha_max*1e-3,alpha_max,10)\n",
    "#     # LASSO\n",
    "#     lasso = slm.LassoCV(max_iter=int(1e5),n_jobs=-1,cv=cvn,alphas=alphas,random_state=0)\n",
    "#     est_ls = lasso.fit(X0_ss,y_train)\n",
    "#     print('LassoCV score:',est_ls.score(X0_ss,y_train))\n",
    "#     results_ls[j] = est_ls.predict(X_test_ss).item()\n",
    "#     print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "#           'with regularization',str(np.round(est_ls.alpha_,5)))\n",
    "#     # LASSONet\n",
    "#     lr=1e-3 # NOT ACTUALLY PASSING\n",
    "#     lassonet = LassoNetRegressorCV(\n",
    "#     cv=cvn,\n",
    "#     M=1e-16, # Approximate standard LASSO\n",
    "#     batch_size=len(y_train), # Leads to gradient descent optimization\n",
    "#     hidden_dims=(5,), #CHANGE\n",
    "#     #n_iters=(int(1e4),int(1e2)), # Iterations for objective function and path\n",
    "#     tol=0.99,#1-est_ls.tol,  \n",
    "#     lambda_seq=alphas, # Path multipler and initial lambda disregarded\n",
    "#     optim=partial(SGD,lr=lr,momentum=0.9), # Approximate coordinate descent\n",
    "#     #backtrack=True, # Approximate monotonic coordinate descent path\n",
    "#     verbose=1,\n",
    "#     torch_seed=0,\n",
    "#     random_state=0,\n",
    "#     gamma=0.0, # No L2 regularization\n",
    "#     gamma_skip=0.0, # No L2 regularization on skip connection\n",
    "#     patience=None, # Disable early stopping\n",
    "#     val_size=0.1,\n",
    "#     )\n",
    "#     # What should these norms be...besides nonzero?\n",
    "#     est_lsn = lassonet.fit(X0_ss,y_train)\n",
    "  \n",
    "#     print('LassoNetCV score:',est_lsn.score(X0_ss,y_train))\n",
    "#     results_bls[j] = est_lsn.predict(X_test_ss).item()\n",
    "\n",
    "#     # Training status\n",
    "#     print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "#           'with regularization',str(np.round(est_ls.alpha_,5)),\n",
    "#           'and',str(np.sum(est_ls.coef_!=0)),'nonzero coefficients',\n",
    "#           'and LassoNet predicts',str(np.round(results_bls[j],2)),\n",
    "#           'for case',str(int(subsc[j])),'with',str(np.round(per_change[j],2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution of: 0.5669595264848581 0.20858808082526412 -0.24474920851943865\n",
      "Resampled to size (37,)\n",
      "Resampled to size (38,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing lambda with cross-validation:   0%|          | 0/2 [00:00<?, ?it/s]/data/Ali/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:486: UserWarning: lambda_start=0.001 (selected automatically) might be too large.\n",
      "Features start to disappear at current_lambda=0.001.\n",
      "  warnings.warn(\n",
      "Choosing lambda with cross-validation:   0%|          | 0/2 [01:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m\n\u001b[1;32m     65\u001b[0m   lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m \u001b[38;5;66;03m# NOT ACTUALLY PASSING\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   lassonet \u001b[38;5;241m=\u001b[39m LassoNetRegressorCV(\n\u001b[1;32m     67\u001b[0m   cv\u001b[38;5;241m=\u001b[39mjj,\n\u001b[1;32m     68\u001b[0m   M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-16\u001b[39m, \u001b[38;5;66;03m# Approximate standard LASSO\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m   val_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     83\u001b[0m   )\n\u001b[0;32m---> 84\u001b[0m   est_lsn \u001b[38;5;241m=\u001b[39m lassonet\u001b[38;5;241m.\u001b[39mfit(X0_ss,y_train)\n\u001b[1;32m     85\u001b[0m   cv_scores[jj] \u001b[38;5;241m=\u001b[39m est_lsn\u001b[38;5;241m.\u001b[39mscore(X0_ss,y_train)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings() \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m): \n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:936\u001b[0m, in \u001b[0;36mBaseLassoNetCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     X,\n\u001b[1;32m    930\u001b[0m     y,\n\u001b[1;32m    931\u001b[0m ):\n\u001b[1;32m    932\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m    Note that if `lambda_` is not given, the trained model\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    will most likely not use any feature.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(X, y, return_state_dicts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:872\u001b[0m, in \u001b[0;36mBaseLassoNetCV.path\u001b[0;34m(self, X, y, return_state_dicts)\u001b[0m\n\u001b[1;32m    869\u001b[0m         split_lambdas\u001b[38;5;241m.\u001b[39mappend(hist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlambda_)\n\u001b[1;32m    870\u001b[0m         split_scores\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mscore(X[test_index], y[test_index]))\n\u001b[0;32m--> 872\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpath(\n\u001b[1;32m    873\u001b[0m         X[train_index],\n\u001b[1;32m    874\u001b[0m         y[train_index],\n\u001b[1;32m    875\u001b[0m         return_state_dicts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# avoid memory cost\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    877\u001b[0m     )\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_paths_\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# build final path\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:471\u001b[0m, in \u001b[0;36mBaseLassoNet.path\u001b[0;34m(self, X, y, X_val, y_val, lambda_seq, lambda_max, return_state_dicts, callback, disable_lambda_warning)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mselected_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[1;32m    472\u001b[0m     X_train,\n\u001b[1;32m    473\u001b[0m     y_train,\n\u001b[1;32m    474\u001b[0m     X_val,\n\u001b[1;32m    475\u001b[0m     y_val,\n\u001b[1;32m    476\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    477\u001b[0m     lambda_\u001b[38;5;241m=\u001b[39mcurrent_lambda,\n\u001b[1;32m    478\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iters_path,\n\u001b[1;32m    479\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    480\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience_path,\n\u001b[1;32m    481\u001b[0m     return_state_dict\u001b[38;5;241m=\u001b[39mreturn_state_dicts,\n\u001b[1;32m    482\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dense \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mselected_count() \u001b[38;5;241m<\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    484\u001b[0m     is_dense \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:317\u001b[0m, in \u001b[0;36mBaseLassoNet._train\u001b[0;34m(self, X_train, y_train, X_val, y_val, batch_size, epochs, lambda_, optimizer, return_state_dict, patience)\u001b[0m\n\u001b[1;32m    314\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ans\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m/\u001b[39m n_train\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ans\n\u001b[0;32m--> 317\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[1;32m    318\u001b[0m     model\u001b[38;5;241m.\u001b[39mprox(\n\u001b[1;32m    319\u001b[0m         lambda_\u001b[38;5;241m=\u001b[39mlambda_ \u001b[38;5;241m*\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    320\u001b[0m         M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM,\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# fallback to running loss of first epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/sgd.py:112\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 112\u001b[0m         loss \u001b[38;5;241m=\u001b[39m closure()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    115\u001b[0m     params: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:293\u001b[0m, in \u001b[0;36mBaseLassoNet._train.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m loss\n\u001b[0;32m--> 293\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    294\u001b[0m     crit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(model(X_train[batch]), y_train[batch])\n\u001b[1;32m    295\u001b[0m     ans \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    296\u001b[0m         crit\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39ml2_regularization()\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_skip \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39ml2_regularization_skip()\n\u001b[1;32m    299\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/optimizer.py:952\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 952\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Noise compensated LASSO\n",
    "retrain = 1\n",
    "results_bls = np.zeros_like(per_change)\n",
    "K_nz_nc = []\n",
    "K_nz_nc_lr = []\n",
    "E_nz_nc = []\n",
    "E_nz_nc_lr = []\n",
    "R_nz_cd = []\n",
    "results_ls_aug = np.zeros_like(per_change)\n",
    "reg = True\n",
    "if retrain == 1:\n",
    "\n",
    "  aug = True\n",
    "  K_nz = []\n",
    "  c = 0\n",
    "\n",
    "  for j in np.arange(c,len(subsc)):\n",
    "      test_id = subsc[j]\n",
    "      test_index = subsc == test_id\n",
    "      train_index = subsc != test_id\n",
    "      X_train = X_all_c[train_index,:,:]\n",
    "      X_test = X_all_c[test_index,:,:]\n",
    "      y_train0 = per_change[train_index]\n",
    "      y_test = per_change[test_index]\n",
    "\n",
    "      y_cat = y_train0 <= 0.3\n",
    "      idy = np.where(y_cat==1)\n",
    "      # Cross validation\n",
    "                                            \n",
    "      X0_ss00,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                  X_train,train_index,X_test,\n",
    "                                                  test_index,pre_updrs_iii_on,None,None,None,None,\n",
    "                                                  None,None,None,None,None,False,False,False)\n",
    "      cvn = 5\n",
    "      cv_scores = np.zeros((cvn+1,1))\n",
    "      cv_lgr_scores = np.zeros((cvn+1,1))\n",
    "      rs = 1\n",
    "      rcfs = 1000\n",
    "      (mu, sigma) = stats.norm.fit(y_train0)\n",
    "      kappa = stats.skew(y_train0)\n",
    "      print('Label distribution of:',mu,sigma,kappa)\n",
    "      Q = 10\n",
    "      for jj in np.arange(Q):\n",
    "        # Resample to avoid stratification errors\n",
    "        while np.sum(y_cat) < cvn:\n",
    "          np.random.seed(rs)\n",
    "          idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "          X0_ss00 = np.append(X0_ss00,X0_ss00[idyr,:].reshape(1,-1),axis=0)\n",
    "          y_train0 = np.append(y_train0,y_train0[idyr])\n",
    "          y_cat = y_train0 <= 0.3\n",
    "          rs = rs+1\n",
    "          print('Resampled to size',y_train0.shape)\n",
    "          y_train_n = y_train0\n",
    "          X0_ss0_n = X0_ss00\n",
    "        if aug == True:\n",
    "          y_train_n = np.append(y_train_n,y_train0+(1.96*sigma)*np.random.normal(0,1,1))\n",
    "          y_cat = y_train_n <= 0.3\n",
    "          X0_ss0_n = np.append(X0_ss0_n,X0_ss00,axis=0)\n",
    "\n",
    "      y_train = y_train_n\n",
    "      X0_ss = X0_ss0_n\n",
    "      \n",
    "      for jj in np.arange(2,cvn+1):\n",
    "        #LASSONet\n",
    "        lr=1e-3 # NOT ACTUALLY PASSING\n",
    "        lassonet = LassoNetRegressorCV(\n",
    "        cv=jj,\n",
    "        M=1e-16, # Approximate standard LASSO\n",
    "        batch_size=len(y_train), # Leads to gradient descent optimization\n",
    "        hidden_dims=(5,), #CHANGE\n",
    "        #n_iters=(int(1e4),int(1e2)), # Iterations for objective function and path\n",
    "        tol=0.99,#1-est_ls.tol,  \n",
    "        #lambda_seq=alphas, # Path multipler and initial lambda disregarded\n",
    "        optim=partial(SGD,lr=lr,momentum=0.9), # Approximate coordinate descent\n",
    "        #backtrack=True, # Approximate monotonic coordinate descent path\n",
    "        verbose=1,\n",
    "        torch_seed=0,\n",
    "        random_state=0,\n",
    "        gamma=0.0, # No L2 regularization\n",
    "        gamma_skip=0.0, # No L2 regularization on skip connection\n",
    "        patience=None, # Disable early stopping\n",
    "        val_size=0.1,\n",
    "        )\n",
    "        with warnings.filterwarnings('ignore', category=UserWarning):      \n",
    "          est_lsn = lassonet.fit(X0_ss,y_train)\n",
    "        cv_scores[jj] = est_lsn.score(X0_ss,y_train)\n",
    "      with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):     \n",
    "        if reg == True: \n",
    "          best_cv = np.argmax(cv_scores)\n",
    "          #LASSONet\n",
    "          lr=1e-3 # NOT ACTUALLY PASSING\n",
    "          lassonet = LassoNetRegressorCV(\n",
    "          cv=best_cv,\n",
    "          M=1e-16, # Approximate standard LASSO\n",
    "          batch_size=len(y_train), # Leads to gradient descent optimization\n",
    "          hidden_dims=(100,), #CHANGE\n",
    "          #n_iters=(int(1e4),int(1e2)), # Iterations for objective function and path\n",
    "          tol=0.99,#1-est_ls.tol,  \n",
    "          #lambda_seq=alphas, # Path multipler and initial lambda disregarded\n",
    "          optim=partial(SGD,lr=lr,momentum=0.9), # Approximate coordinate descent\n",
    "          #backtrack=True, # Approximate monotonic coordinate descent path\n",
    "          verbose=1,\n",
    "          torch_seed=0,\n",
    "          random_state=0,\n",
    "          gamma=0.0, # No L2 regularization\n",
    "          gamma_skip=0.0, # No L2 regularization on skip connection\n",
    "          patience=None, # Disable early stopping\n",
    "          val_size=0.1,\n",
    "          )\n",
    "        with warnings.filterwarnings('ignore', category=UserWarning):      \n",
    "          est_lsn = lassonet.fit(X0_ss,y_train)\n",
    "  print('LassoNetCV score:',est_lsn.score(X0_ss,y_train))\n",
    "  results_bls[j] = est_lsn.predict(X_test_ss0).item()\n",
    "  print('LassoNet predicts',str(np.round(results_bls[j],2)),'for case',str(int(subsc[j])),'with',str(np.round(per_change[j],2)))\n",
    "  c = c+1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               results_bls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                'LassoNet'\n",
    "                                ],(30,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_bls,per_change)\n",
    "lr = stats.linregress(results_bls,per_change)\n",
    "plt.plot(results_bls,results_bls*lr.slope+lr.intercept,color='r')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.title('LassoNet')\n",
    "plt.ylabel(\"DBS improvement\",fontsize=14)\n",
    "plt.xlabel(\"Prediction\",fontsize=14)\n",
    "text = f\"$y={lr.slope:0.2f}\\; x{lr.intercept:+0.2f}$\\n$r = {lr.rvalue:0.2f}$\\n$p = {lr.pvalue:0.2e}$\"\n",
    "plt.text(0.1, 0.8, text,\n",
    "    fontsize=14, verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lct_change,per_change)\n",
    "lr = stats.linregress(lct_change,per_change)\n",
    "plt.plot(lct_change,lct_change*lr.slope+lr.intercept,color='r')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.title('LCT')\n",
    "plt.ylabel(\"DBS improvement\",fontsize=14)\n",
    "plt.xlabel(\"Prediction\",fontsize=14)\n",
    "text = f\"$y={lr.slope:0.2f}\\; x{lr.intercept:+0.2f}$\\n$r = {lr.rvalue:0.2f}$\\n$p = {lr.pvalue:0.2e}$\"\n",
    "plt.text(0.1, 0.8, text,\n",
    "    fontsize=14, verticalalignment='top')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdlnetenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
