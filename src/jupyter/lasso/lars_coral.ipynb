{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=6\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.neural_network as skn\n",
    "from celer import GroupLassoCV\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch import nn\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from adapt.feature_based import CORAL\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function ✓\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)\n",
    "# Combine CHH dataset ✓\n",
    "# Implement CV and test ✓\n",
    "# Print selected features ✓\n",
    "# Make magnitude templates\n",
    "# Sample weights ✓\n",
    "# Look at segmentations by error ✓ (Appears to have most difference in red nucleus, which includes surrounding (white?) matter for underperforming cases)\n",
    "# Extract features from current (1:6) eroded ROIs\n",
    "# Extract features from all ROIs\n",
    "# Plot segmentation variance against error for each case across all ROIs ✓\n",
    "# Why does excluding the subthalamic nucleus increase the correlation (r=0.5 -> r=0.6)?\n",
    "# Best performance with all ROIs: cvn=6, k=1800\n",
    "# Best performance with ROIs 0:4, excluding STN: cvn=6, k=1800\n",
    "# Should the pre-operative UPDRS be appended once or to each ROI? ✓\n",
    "# Plot histogram of features for successful and unsuccessful predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528_wldd.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','pre op levadopa equivalent dose (mg)','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off,ledd = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo',\n",
    "                                                          'pre op levadopa equivalent dose (mg)')\n",
    "print(ledd)\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,False)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,0:4,:]\n",
    "K_all_c = K_all[c_cases_idx,0:4,:]\n",
    "R_all_c = R_all[c_cases_idx,0:4,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subs_init = subs[s_cases_idx]\n",
    "pre_imp_init = pre_imp[s_cases_idx]\n",
    "post_imp_init = post_imp[s_cases_idx]\n",
    "pre_updrs_off_init = pre_updrs_off[s_cases_idx]\n",
    "ledd_init = ledd[s_cases_idx]\n",
    "per_change_init = post_imp_init\n",
    "subs = np.asarray(ID_all,dtype=float)[np.in1d(np.asarray(ID_all,dtype=float),subs_init)]\n",
    "\n",
    "pre_imp = np.zeros((1,len(subs))).T\n",
    "post_imp = np.zeros((1,len(subs))).T\n",
    "pre_updrs_off = np.zeros((1,len(subs))).T\n",
    "ledd = np.zeros((1,len(subs))).T\n",
    "per_change = np.zeros((1,len(subs))).T\n",
    "for j in np.arange(len(subs)):\n",
    "    pre_imp[j] = pre_imp_init[subs_init == subs[j]]\n",
    "    post_imp[j] = post_imp_init[subs_init == subs[j]]\n",
    "    pre_updrs_off[j] = pre_updrs_off_init[subs_init == subs[j]]\n",
    "    ledd[j] = ledd_init[subs_init == subs[j]]\n",
    "    per_change[j] = per_change_init[subs_init == subs[j]]\n",
    "\n",
    "subsc = subs\n",
    "X_all_c = X_all_c.reshape(X_all_c.shape[0],-1)\n",
    "X_all_c = np.append(X_all_c,pre_updrs_off,axis=1)\n",
    "\n",
    "X_all_c = np.append(X_all_c,ledd,axis=1)\n",
    "print(np.unique(R_all_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'r2'\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_gls = np.zeros_like(per_change)\n",
    "gerror = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "err_var = np.zeros_like(per_change)\n",
    "alphas = np.logspace(-4,4,100)\n",
    "Ks = []\n",
    "Kstg = []\n",
    "w = []\n",
    "wg = []\n",
    "pcases = []\n",
    "pscores = []\n",
    "s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = []\n",
    "err_var = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:]\n",
    "    X_test = X_all_c[test_index,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    idy = y_train[y_train<=0.3]\n",
    "    \n",
    "    scaler = skp.StandardScaler()\n",
    "    X0_ss0 = scaler.fit_transform(X_train)\n",
    "    X_test_ss0 = scaler.transform(X_test)\n",
    "    cvn = 6\n",
    "    lasso = slm.LassoLarsCV(max_iter=1000,cv=cvn,normalize=False,eps=0.1,n_jobs=1)\n",
    "\n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "      # Feature selection\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      sel = skf.SelectKBest(skf.r_regression,k=2925)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train.ravel())\n",
    "      X_test_sst = sel.transform(X_test_ss0)\n",
    "      #gel = skf.RFECV(lasso,verbose=0,cv=cvn,step=100,n_jobs=-1)\n",
    "      X0_ss = X0_sst#gel.fit_transform(X0_sst,y_train)\n",
    "      kappa.append(np.linalg.cond(X0_ss0))\n",
    "      X_test_ss = X_test_sst#gel.transform(X_test_sst)\n",
    "     #Ks.append(sel.transform(K.reshape(1, -1)))\n",
    "      dx, y_n0 = cKDTree(X0_ss).query(X_test_ss, k=1)\n",
    "\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=cvn,n_jobs=-1,normalize=False,eps=0.1)\n",
    "\n",
    "      # Raise lambda until prediction is in [0,1]\n",
    "      lassoc = CORAL(lasso, Xt=X_test_ss, random_state=0, lambda_=1e9)\n",
    "      est_ls = lassoc.fit(X0_ss,y_train)\n",
    "      print('Previous neighbor',str(y_train[y_n0]))\n",
    "      # If domain='tgt', apply transform to X0_ss (source data)\n",
    "      dx, y_n = cKDTree(X0_ss).query(lassoc.transform(X_test_ss,domain='src'), k=1)\n",
    "      print('New neighbor',str(y_train[y_n]))\n",
    "\n",
    "    # Reconstruct nearest neighbor\n",
    "    r[j] = est_ls.predict(X0_ss[y_n,:])\n",
    "    err_var[j] = np.mean(abs(est_ls.predict(X0_ss)-y_train))\n",
    "    rerror[j] = np.abs(r[j]-y_train[y_n])\n",
    "    #s.append(est_ls.score(X0_ss,y_train))\n",
    "    results_ls[j] = est_ls.predict(X_test_ss)\n",
    "\n",
    "\n",
    "    print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "              'for case with',str(np.round(per_change[j],2)))\n",
    "    gerror[j] = (abs(results_ls[j]-y_test))\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(kappa,gerror)\n",
    "plt.xlabel('Condition number')\n",
    "plt.ylabel('True error')\n",
    "plt.title('Error estimation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots()\n",
    "# df = pd.DataFrame({'Feature':(Kstg[wg != 0]).tolist()})\n",
    "# hist = df['Feature'].value_counts()#.plot(kind='bar',ax=ax)\n",
    "# ax.plot(hist[hist>1])\n",
    "#ax.get_legend().remove()\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Case ' + str(int(j)) + ', subject ' + str(subsc[j]) + ' with error ' + str(np.round(gerror[j],2)))\n",
    "# plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "# plt.style.use('dark_background')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls[results_ls>1] = 1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(20,10))\n",
    "plt.ylim([0,1.5])\n",
    "plt.xlim([0,1.5])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(3,2,sharex=True,sharey=True)\n",
    "# plt.style.use('dark_background')\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "# ax[0,0].scatter(V[:,0]/1000,gerror)\n",
    "# ax[0,0].set_title('Right red nucleus')\n",
    "# ax[0,1].scatter(V[:,1]/1000,gerror)\n",
    "# ax[0,1].set_title('Left red nucleus')\n",
    "# ax[1,0].scatter(V[:,2]/1000,gerror)\n",
    "# ax[1,0].set_title('Right substantia nigra')\n",
    "# ax[1,1].scatter(V[:,3]/1000,gerror)\n",
    "# ax[1,1].set_title('Left substantia nigra')\n",
    "# ax[2,0].scatter(V[:,4]/1000,gerror)\n",
    "# ax[2,0].set_title('Right subthalamic nuclei')\n",
    "# ax[2,1].scatter(V[:,5]/1000,gerror)\n",
    "# ax[2,1].set_title('Left subthalamic nuclei')\n",
    "# plt.setp(ax[-1, :], xlabel='Variance');\n",
    "# plt.setp(ax[:, 0], ylabel='Error');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
