{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "import sklearn.decomposition as skd\n",
    "import sklearn.neighbors as skn\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.datasets import make_sparse_coded_signal\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from celer import GroupLassoCV\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function ✓\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)\n",
    "# Combine CHH dataset ✓\n",
    "# Implement CV and test ✓\n",
    "# Print selected features ✓\n",
    "# Make magnitude templates\n",
    "# Sample weights ✓\n",
    "# Look at segmentations by error ✓ (Appears to have most difference in red nucleus, which includes surrounding (white?) matter for underperforming cases)\n",
    "# Extract features from current (1:6) eroded ROIs\n",
    "# Extract features from all ROIs\n",
    "# Plot segmentation variance against error for each case across all ROIs ✓\n",
    "# Why does excluding the subthalamic nucleus increase the correlation (r=0.5 -> r=0.6)?\n",
    "# Best performance with all ROIs: cvn=6, k=1800\n",
    "# Best performance with ROIs 0:4, excluding STN: cvn=6, k=1800\n",
    "# Should the pre-operative UPDRS be appended once or to each ROI? ✓\n",
    "# Plot histogram of features for successful and unsuccessful predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000001 for case 1.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000002 for case 2.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000003 for case 3.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000004 for case 4.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000005 for case 5.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000006 for case 6.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000007 for case 7.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000008 for case 8.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000009 for case 9.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000010 for case 10.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000011 for case 11.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000013 for case 13.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000014 for case 14.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000016 for case 16.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000018 for case 18.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000019 for case 19.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000020 for case 20.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000021 for case 21.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000022 for case 22.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000023 for case 23.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000024 for case 24.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000025 for case 25.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000026 for case 26.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000027 for case 27.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000028 for case 28.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000029 for case 29.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000030 for case 30.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000031 for case 31.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000032 for case 32.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000033 for case 33.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000034 for case 34.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000035 for case 35.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000036 for case 36.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000037 for case 37.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000038 for case 38.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000039 for case 39.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000040 for case 40.0\n"
     ]
    }
   ],
   "source": [
    "# Augment with CHH data\n",
    "X0_gt = np.load('/home/ali/RadDBS-QSM/data/npy/old/X0_gt_chh_rois.npy')\n",
    "df = pd.read_csv('/home/ali/RadDBS-QSM/data/xlxs/updrs_iii_chh.csv')\n",
    "# Patient IDs\n",
    "subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "n_rois = 6\n",
    "# Data\n",
    "s_directory = open('/home/ali/RadDBS-QSM/data/roi/roi_list','r').read().splitlines()\n",
    "# Load\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/segs_chh', \"rb\") as fp:  \n",
    "    segs = pickle.load(fp)\n",
    "    n_cases = len(segs)\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/qsms_chh', \"rb\") as fp:  \n",
    "    qsms = pickle.load(fp)\n",
    "with open('/home/ali/RadDBS-QSM/data/phi/chh/Phi_mcl_gt_roi_chh', \"rb\") as fp:  \n",
    "    Phi_gt = pickle.load(fp)\n",
    "L = int(len(X0_gt)/n_cases)\n",
    "n_features = int(L/n_rois)\n",
    "# Only extract ROI if it is present in all cases\n",
    "seg_labels_all = segs[0]\n",
    "case_number = np.zeros_like(np.asarray(s_directory))\n",
    "for i in range(n_cases):\n",
    "    case_number[i] = float(s_directory[i][-2:])\n",
    "subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "for i in range(n_cases):\n",
    "    try:\n",
    "        print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "    except:\n",
    "        print('Case',subject_id[i],'quarantined')\n",
    "pre_updrs_iii_off =  np.asarray(df[df.columns[3]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)                             \n",
    "pre_updrs_iii_on =  np.asarray(df[df.columns[4]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "post_updrs_iii_off =  np.asarray(df[df.columns[6]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "\n",
    "per_change = (pre_updrs_iii_off-post_updrs_iii_off)/pre_updrs_iii_off\n",
    "pre_updrs_off = pre_updrs_iii_off\n",
    "X_all_c = X0_gt.reshape(n_cases,n_rois,n_features)\n",
    "X_all_c = X_all_c[:,0:4,:]\n",
    "lct_change = (pre_updrs_iii_off-pre_updrs_iii_on)/pre_updrs_iii_off\n",
    "pre_imp = lct_change\n",
    "X_all_c = X_all_c.reshape(X_all_c.shape[0],-1)\n",
    "X_all_c = np.append(X_all_c,pre_imp.reshape(-1,1),axis=1)\n",
    "subsc = subject_id_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>LCT</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>UPDRSⅢ</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Preoperative Off-Medicine</td>\n",
       "      <td>Preoperative On-Medicine</td>\n",
       "      <td>Postoperative  Off-Medicine &amp;Off-Stimulation\\n</td>\n",
       "      <td>Postoperative  Off-Medicine &amp;On-Stimulation</td>\n",
       "      <td>Postoperative  On-Medicine &amp;On-Stimulation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.26%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>51.72%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.58%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>55.88%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>75.44%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>84.00%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>41.86%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>72.58%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>70.21%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>63.95%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>89.55%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>88.46%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>62.50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>48.00%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>14.29%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>36.62%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>54.90%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>81.63%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>71.43%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>90.32%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>65.85%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>74.29%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>83.61%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>58.97%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.88%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>76.67%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>81.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.0</td>\n",
       "      <td>62.35%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>32</td>\n",
       "      <td>92</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31.0</td>\n",
       "      <td>27.91%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>31.48%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33.0</td>\n",
       "      <td>80.33%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34.0</td>\n",
       "      <td>40.74%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35.0</td>\n",
       "      <td>16.13%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36.0</td>\n",
       "      <td>59.26%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37.0</td>\n",
       "      <td>61.40%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.0</td>\n",
       "      <td>95.92%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39.0</td>\n",
       "      <td>79.35%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40.0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subjects    LCT   Unnamed: 2                     UPDRSⅢ  \\\n",
       "0        NaN     NaN         NaN  Preoperative Off-Medicine   \n",
       "1        1.0  62.26%         NaN                         53   \n",
       "2        2.0  75.00%         NaN                         32   \n",
       "3        3.0  51.72%         NaN                         58   \n",
       "4        4.0  22.58%         NaN                         62   \n",
       "5        5.0  55.88%         NaN                         34   \n",
       "6        6.0  75.44%         NaN                         57   \n",
       "7        7.0  84.00%         NaN                        100   \n",
       "8        8.0  41.86%         NaN                         43   \n",
       "9        9.0  72.58%         NaN                         62   \n",
       "10      10.0  81.25%         NaN                         64   \n",
       "11      11.0  70.21%         NaN                         94   \n",
       "12      12.0  63.95%         NaN                         86   \n",
       "13      13.0  89.55%         NaN                         67   \n",
       "14      14.0  88.46%         NaN                         26   \n",
       "15      15.0  62.50%         NaN                         72   \n",
       "16      16.0  48.00%         NaN                         25   \n",
       "17      17.0  14.29%         NaN                         98   \n",
       "18      18.0  36.62%         NaN                         71   \n",
       "19      19.0  54.90%         NaN                         51   \n",
       "20      20.0  81.63%         NaN                         49   \n",
       "21      21.0  71.43%         NaN                         49   \n",
       "22      22.0  90.32%         NaN                         31   \n",
       "23      23.0  65.85%         NaN                         41   \n",
       "24      24.0  74.29%         NaN                         35   \n",
       "25      25.0  83.61%         NaN                         61   \n",
       "26      26.0  58.97%         NaN                         78   \n",
       "27      27.0   5.88%         NaN                         51   \n",
       "28      28.0  76.67%         NaN                         60   \n",
       "29      29.0  81.01%         NaN                         79   \n",
       "30      30.0  62.35%         NaN                         85   \n",
       "31      31.0  27.91%         NaN                         43   \n",
       "32      32.0  31.48%         NaN                         54   \n",
       "33      33.0  80.33%         NaN                         61   \n",
       "34      34.0  40.74%         NaN                         54   \n",
       "35      35.0  16.13%         NaN                         93   \n",
       "36      36.0  59.26%         NaN                         54   \n",
       "37      37.0  61.40%         NaN                         57   \n",
       "38      38.0  95.92%         NaN                         49   \n",
       "39      39.0  79.35%         NaN                         92   \n",
       "40      40.0  50.00%         NaN                         54   \n",
       "\n",
       "                  Unnamed: 4                                       Unnamed: 5  \\\n",
       "0   Preoperative On-Medicine  Postoperative  Off-Medicine &Off-Stimulation\\n    \n",
       "1                         20                                               40   \n",
       "2                          8                                               26   \n",
       "3                         28                                               52   \n",
       "4                         48                                               61   \n",
       "5                         15                                               44   \n",
       "6                         14                                               55   \n",
       "7                         16                                               68   \n",
       "8                         25                                               48   \n",
       "9                         17                                               56   \n",
       "10                        12                                               33   \n",
       "11                        28                                               31   \n",
       "12                        31                                               28   \n",
       "13                         7                                               64   \n",
       "14                         3                                               31   \n",
       "15                        27                                               72   \n",
       "16                        13                                               17   \n",
       "17                        84                                               86   \n",
       "18                        45                                               49   \n",
       "19                        23                                               37   \n",
       "20                         9                                               20   \n",
       "21                        14                                               42   \n",
       "22                         3                                               46   \n",
       "23                        14                                               43   \n",
       "24                         9                                               21   \n",
       "25                        10                                               60   \n",
       "26                        32                                               64   \n",
       "27                        48                                               45   \n",
       "28                        14                                               68   \n",
       "29                        15                                               79   \n",
       "30                        32                                               92   \n",
       "31                        31                                               31   \n",
       "32                        37                                               64   \n",
       "33                        12                                               53   \n",
       "34                        32                                               64   \n",
       "35                        78                                               69   \n",
       "36                        22                                               57   \n",
       "37                        22                                               56   \n",
       "38                         2                                               58   \n",
       "39                        19                                              NaN   \n",
       "40                        27                                               34   \n",
       "\n",
       "                                     Unnamed: 6  \\\n",
       "0   Postoperative  Off-Medicine &On-Stimulation   \n",
       "1                                            15   \n",
       "2                                            17   \n",
       "3                                            18   \n",
       "4                                            36   \n",
       "5                                            29   \n",
       "6                                            32   \n",
       "7                                            12   \n",
       "8                                            26   \n",
       "9                                            25   \n",
       "10                                           12   \n",
       "11                                           34   \n",
       "12                                           27   \n",
       "13                                           19   \n",
       "14                                           18   \n",
       "15                                           44   \n",
       "16                                            8   \n",
       "17                                           43   \n",
       "18                                           47   \n",
       "19                                           21   \n",
       "20                                            3   \n",
       "21                                            8   \n",
       "22                                           28   \n",
       "23                                           24   \n",
       "24                                           15   \n",
       "25                                           21   \n",
       "26                                           29   \n",
       "27                                           27   \n",
       "28                                           43   \n",
       "29                                           32   \n",
       "30                                           40   \n",
       "31                                            6   \n",
       "32                                           28   \n",
       "33                                           21   \n",
       "34                                           36   \n",
       "35                                           47   \n",
       "36                                           12   \n",
       "37                                           11   \n",
       "38                                           14   \n",
       "39                                           63   \n",
       "40                                            9   \n",
       "\n",
       "                                    Unnamed: 7  Unnamed: 8  \n",
       "0   Postoperative  On-Medicine &On-Stimulation         NaN  \n",
       "1                                            7         NaN  \n",
       "2                                           10         NaN  \n",
       "3                                           20         NaN  \n",
       "4                                           28         NaN  \n",
       "5                                           22         NaN  \n",
       "6                                           16         NaN  \n",
       "7                                          NaN         NaN  \n",
       "8                                           26         NaN  \n",
       "9                                           11         NaN  \n",
       "10                                         NaN         NaN  \n",
       "11                                          43         NaN  \n",
       "12                                          18         NaN  \n",
       "13                                         NaN         NaN  \n",
       "14                                          17         NaN  \n",
       "15                                          38         NaN  \n",
       "16                                           8         NaN  \n",
       "17                                          34         NaN  \n",
       "18                                          46         NaN  \n",
       "19                                          18         NaN  \n",
       "20                                         NaN         NaN  \n",
       "21                                         NaN         NaN  \n",
       "22                                         NaN         NaN  \n",
       "23                                          24         NaN  \n",
       "24                                         NaN         NaN  \n",
       "25                                          17         NaN  \n",
       "26                                          21         NaN  \n",
       "27                                          20         NaN  \n",
       "28                                         NaN         NaN  \n",
       "29                                          28         NaN  \n",
       "30                                         NaN         NaN  \n",
       "31                                         NaN         NaN  \n",
       "32                                          25         NaN  \n",
       "33                                          15         NaN  \n",
       "34                                          29         NaN  \n",
       "35                                          44         NaN  \n",
       "36                                         NaN         NaN  \n",
       "37                                         NaN         NaN  \n",
       "38                                          12         NaN  \n",
       "39                                         NaN         NaN  \n",
       "40                                           8         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'r2'\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_gls = np.zeros_like(per_change)\n",
    "gerror = np.zeros_like(per_change)\n",
    "alphas = np.logspace(-5,-3,100)\n",
    "Ks = []\n",
    "Kstg = []\n",
    "w = []\n",
    "wg = []\n",
    "pcases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img, subsc0, per_change0, pre_metric0, pre_imp0 = util.slice_pick(subsc=subsc,\n",
    "                        per_change=per_change,\n",
    "                        pre_metric=pre_updrs_off,\n",
    "                        pre_comp=pre_imp,\n",
    "                        pshape=(48,48,48),\n",
    "                        roi_l=0,roi_u=4,\n",
    "                        mask_crop_output=False,mask_output=False,o_index=False,\n",
    "                        file_path='/home/ali/RadDBS-QSM/src/jupyter/mlp/torch/X_chh.pt',\n",
    "                        qsm_path='/home/ali/RadDBS-QSM/data/nii/chh/qsm/',\n",
    "                        seg_prefix='/home/ali/RadDBS-QSM/data/nii/chh/seg/',\n",
    "                        save_image=False,\n",
    "                        L=10,\n",
    "                        new_prefix=False,\n",
    "                        img_directory='/home/ali/RadDBS-QSM/src/jupyter/mlp/chh_tensor_slices_0/',\n",
    "                        visualize=False,\n",
    "                        reload=False)\n",
    "Xr = torch.zeros((len(X_img),X_img[0].shape[0],X_img[0].shape[1]))\n",
    "for j in np.arange(len(X_img)):\n",
    "    img = X_img[j]\n",
    "    img[img>250] = 250\n",
    "    img[img<-250] = -250\n",
    "    Xr[j,:,:] = img\n",
    "    # plt.imshow(np.rot90(img.cpu()),cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # np.save('./chh_tensor_slices_0/case_'+str(subsc[j])+'_0.npy',img.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37, 48, 48])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n",
      "(48, 15)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0cd1758c1974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdict_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionaryLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lasso_lars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0mpositive_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m             \u001b[0mpositive_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m         )\n\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod_max_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         )\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             )\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mnew_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0mfit_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_normalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m             \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         )\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, normalize, Xy)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                     \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m                     \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m                     \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m                 )\n\u001b[1;32m   1082\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36m_lars_path_solver\u001b[0;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    633\u001b[0m                     \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                     \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mSOLVE_TRIANGULAR_ARGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m                 )\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, debug, check_finite)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected square matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         raise ValueError('shapes of a {} and b {} are incompatible'\n\u001b[1;32m    344\u001b[0m                          .format(a1.shape, b1.shape))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Js = []\n",
    "err_var = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "scaler = skp.StandardScaler()\n",
    "X = scaler.fit_transform(X_all_c)\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:]\n",
    "    X_test = X_all_c[test_index,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    idy = y_train[y_train<=0.3]\n",
    "\n",
    "    dict_learner = DictionaryLearning(n_components=15, transform_algorithm='lasso_lars', transform_alpha=0.1,random_state=42)\n",
    "    X_transformed = dict_learner.fit(Xr[j,:,:].reshape(1,-1)).transform(Xr[j,:,:].reshape(1,-1))\n",
    "    print(X_transformed.shape)\n",
    "          \n",
    "\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
