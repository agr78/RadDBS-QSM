{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "import sklearn.pipeline as spl\n",
    "import sklearn.kernel_ridge as skr\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.neighbors as snn\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.decomposition as sdc\n",
    "import sklearn.cross_decomposition as skd\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "from sklearn.utils import resample\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from sklearn import metrics\n",
    "import nibabel as nib\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jupyter-matplotlib {\n",
       "    background-color: #000;\n",
       "}\n",
       "\n",
       ".widget-label, .jupyter-matplotlib-header{\n",
       "    color: #fff;\n",
       "}\n",
       "\n",
       ".jupyter-button {\n",
       "    background-color: #333;\n",
       "    color: #fff;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "#     Performed poorly using Standard and MinMax scalers. Trying with LOOCV to see if predictions stabilize.\n",
    "#     Does not appear to stabilize predictions with LOOCV (using StandardScaler())\n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function?\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)\n",
    "# CHECK PHI AND X DIRECTORIES, WHICH ONE IS RIGHT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "(512, 512, 352)\n",
      "[0. 1. 2. 3. 4.]\n",
      "Appending slice 0 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 1 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 2 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 3 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 4 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 5 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 6 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 7 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 8 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 9 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 10 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 11 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 12 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 13 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 14 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 15 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 16 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 17 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 18 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 19 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 20 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 21 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 22 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 23 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 24 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 25 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 26 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 27 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 28 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 29 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 30 with ROIs [0. 1. 2. 3. 4.]\n",
      "Appending slice 31 with ROIs [0. 1. 2. 3. 4.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-328e9231047a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mk_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Appending slice'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'with ROIs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mmask_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mk_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mFind\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignoring\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload = 1\n",
    "qsms = util.full_path('/home/ali/RadDBS-QSM/data/nii/qsm')\n",
    "qsms_subs = qsms[-9]\n",
    "segs = util.full_path('/home/ali/RadDBS-QSM/data/nii/seg')\n",
    "chi = []\n",
    "im_subs = []\n",
    "c = []\n",
    "roi_s = np.asarray((1.0,2.0,3.0,4.0))\n",
    "for j in np.arange(len(qsms)):\n",
    "    data = nib.load(qsms[j])\n",
    "    qsm_subs = qsms[j][-9:-7]\n",
    "    #try:\n",
    "    mask = nib.load('/home/ali/RadDBS-QSM/data/nii/seg/labels_2iMag'+qsm_subs+'.nii.gz').get_fdata()\n",
    "    print(np.unique(mask))\n",
    "    mask[mask > 4] = 0\n",
    "    mask[mask < 1] = 0\n",
    "    print(mask.shape)\n",
    "    print(np.unique(mask))\n",
    "    mask_k = []\n",
    "    k_all = []\n",
    "    for k in np.arange(mask.shape[2]):\n",
    "            if np.sum(mask[:,:,k]) > 0:\n",
    "                print('Appending slice',str(k),'with ROIs',str(np.unique(mask)))\n",
    "                mask_k.append(np.sum(mask[:,:,k]))\n",
    "                k_all.append(k)\n",
    "        \n",
    "    c.append(k_all[np.argmax(mask_k)])\n",
    "    print('Maximum volume found at slice',str(k_all[np.argmax(mask_k)]))\n",
    "#except:\n",
    "#    print('Missing mask at',str(qsm_subs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 1000 slices\n",
      "Appended 2000 slices\n",
      "Appended 3000 slices\n",
      "Appended 4000 slices\n",
      "Appended 5000 slices\n",
      "Appended 6000 slices\n",
      "Allocated arrays\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3fc921035950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Complete case indices with respect to feature matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mc_cases_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_cases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mX_all_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_cases_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# K_all_c = K_all[c_cases_idx,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# R_all_c = R_all[c_cases_idx,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs_init,pre_imp_init,post_imp_init,pre_updrs_off_init = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/slices/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/slices/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,939,True)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs_init).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all_c = X_all[c_cases_idx,:,:]\n",
    "# K_all_c = K_all[c_cases_idx,:,:]\n",
    "# R_all_c = R_all[c_cases_idx,:,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs_init,ids[c_cases_idx])\n",
    "subs_init = subs_init[s_cases_idx]\n",
    "pre_imp_init = pre_imp_init[s_cases_idx]\n",
    "post_imp_init = post_imp_init[s_cases_idx]\n",
    "pre_updrs_off_init = pre_updrs_off_init[s_cases_idx]\n",
    "per_change_init = post_imp_init\n",
    "subs = np.asarray(ID_all,dtype=float)[np.in1d(np.asarray(ID_all,dtype=float),subs_init)]\n",
    "\n",
    "pre_imp = np.zeros((1,len(subs))).T\n",
    "post_imp = np.zeros((1,len(subs))).T\n",
    "pre_updrs_off = np.zeros((1,len(subs))).T\n",
    "per_change = np.zeros((1,len(subs))).T\n",
    "for j in np.arange(len(subs)):\n",
    "    pre_imp[j] = pre_imp_init[subs_init == subs[j]]\n",
    "    post_imp[j] = post_imp_init[subs_init == subs[j]]\n",
    "    pre_updrs_off[j] = pre_updrs_off_init[subs_init == subs[j]]\n",
    "    per_change[j] = per_change_init[subs_init == subs[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~np.isnan(X_all))/np.prod(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphas = np.logspace(-9,-2,10)\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results_lr = np.zeros_like(per_change_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(len(subs_init)):\n",
    "    test_id = subs_init[j]\n",
    "    test_index = np.argmax(subs == test_id)\n",
    "    train_index = np.argmax(subs != test_id)\n",
    "    print('With patient ID',str(np.unique(subs[test_index])),'pre-improvement is',str(np.unique(pre_updrs_off[test_index])))\n",
    "    # print(len(test_index)) \n",
    "    # print(np.sum(test_index))\n",
    "    # print(len(train_index))\n",
    "    # print(np.sum(train_index))\n",
    "    # print(np.unique(subs[test_index]))\n",
    "    # print(test_id)\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "    X_train, y_train = sku.shuffle(X_train, y_train, random_state=1)\n",
    "\n",
    "    # Cross validation\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,test_index,pre_updrs_off,True,False,True)\n",
    "    # print(np.unique(pre_updrs_off[test_index]))\n",
    "    cvn = 10\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        sel = skf.SelectKBest(skf.r_regression,k=400)\n",
    "        X0_ss = sel.fit_transform(X0_ss0,y_train.ravel())\n",
    "        X_test_ss = sel.transform(X_test_ss0)\n",
    "    # Linear regression\n",
    "    lr = slm.LassoCV(max_iter=1e7,verbose=True,n_jobs=-1)\n",
    "    est_lr = lr.fit(X0_ss,y_train.ravel())\n",
    "    print(est_lr.score(X0_ss,y_train))\n",
    "    #est_lr.predict(X_test_ss)\n",
    "    print('Linear regression predicts',str(np.mean(est_lr.predict(X_test_ss))),'for case with',str(per_change_init[j]))\n",
    "\n",
    "    # # LASSO\n",
    "    # lasso = slm.Lasso(alpha=1e-2,max_iter=1e5)\n",
    "        \n",
    "    # #verbose=False,\n",
    "    # # random_state=1,\n",
    "    # # max_iter=10000,\n",
    "    # # tol=1e-3,\n",
    "    # # n_jobs=-1)\n",
    "    # est_ls = lasso.fit(X0_ss,y_train)\n",
    "    # results_ls[j] = est_ls.predict(X_test_ss)\n",
    "    # print('Lasso predicts',str(results_ls[j]),'for case with',str(per_change[j]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, coefs = slm.lars_path(X0_ss0, y_train, method=\"lasso\",  verbose=True, max_iter = 104)\n",
    "\n",
    "# xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "# xx /= xx[-1]\n",
    "\n",
    "# plt.plot(xx, coefs.T)\n",
    "# ymin, ymax = plt.ylim()\n",
    "# plt.vlines(xx, ymin, ymax, linestyle=\"dashed\")\n",
    "# plt.xlabel(\"|coef| / max|coef|\")\n",
    "# plt.ylabel(\"Coefficients\")\n",
    "# plt.title(\"LASSO Path\")\n",
    "# plt.axis(\"tight\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(per_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp_init,\n",
    "                               results_lr)),\n",
    "                               per_change_init,\n",
    "                               ['LCT',\n",
    "                                'Regression',\n",
    "                                'Ridge',\n",
    "                                ],(30,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
