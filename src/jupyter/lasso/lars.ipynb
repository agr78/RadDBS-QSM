{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe y should also be scaled? \n",
    "# Perhaps a transform would be more effective, or scaling implemented with consistent cross-validation\n",
    "# Different scaling methods? \n",
    "#     This seems most important for noise-sensitive models like LARS. All other use StandardScaler()\n",
    "# Transformers?\n",
    "# Model-specific scaling methods?\n",
    "#     Yes, see above\n",
    "# Common cross-validation function ✓\n",
    "#     Use built-in functions wherever possible and `utils.gridsearch_pickparams()` elsewhere\n",
    "# Quantile loss\n",
    "# RANSAC\n",
    "# Data augmentation? (Mixup)\n",
    "# Data generation? (SMOGN)\n",
    "# Combine CHH dataset ✓\n",
    "# Implement CV and test ✓\n",
    "# Print selected features ✓\n",
    "# Make magnitude templates\n",
    "# Sample weights ✓\n",
    "# Look at segmentations by error ✓ (Appears to have most difference in red nucleus, which includes surrounding (white?) matter for underperforming cases)\n",
    "# Extract features from current (1:6) eroded ROIs\n",
    "# Extract features from all ROIs\n",
    "# Plot segmentation variance against error for each case across all ROIs ✓\n",
    "# Why does excluding the subthalamic nucleus increase the correlation (r=0.5 -> r=0.6)?\n",
    "# Best performance with all ROIs: cvn=6, k=1800\n",
    "# Best performance with ROIs 0:4, excluding STN: cvn=6, k=1800\n",
    "# Should the pre-operative UPDRS be appended once or to each ROI? ✓\n",
    "# Plot histogram of features for successful and unsuccessful predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528_wldd.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','pre op levadopa equivalent dose (mg)','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off,ledd = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo',\n",
    "                                                          'pre op levadopa equivalent dose (mg)')\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "# Omit full reduction data\n",
    "# c_cases_idx[np.where(subs==61)] = 0\n",
    "# c_cases_idx[np.where(subs==69)] = 0\n",
    "X_all_c = X_all[c_cases_idx,0:4,:]\n",
    "K_all_c = K_all[c_cases_idx,0:4,:]\n",
    "R_all_c = R_all[c_cases_idx,0:4,:]\n",
    "print(R_all_c)\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "subsc = subs[s_cases_idx]\n",
    "pre_imp = pre_imp[s_cases_idx]\n",
    "post_imp = post_imp[s_cases_idx]\n",
    "pre_updrs_off = pre_updrs_off[s_cases_idx]\n",
    "per_change = post_imp\n",
    "# Reshape keys and ROIs\n",
    "if all_rois == True:\n",
    "    K_all_cu = np.empty((K_all_c.shape[0],K_all_c.shape[1],K_all_c.shape[2]+1),dtype=object)\n",
    "    K_all_cu[:,:,:-1] = K_all_c\n",
    "    K_all_cu[:,:,-1] = 'pre_updrs'\n",
    "    K = K_all_cu.reshape((K_all_cu.shape[0],K_all_cu.shape[1]*K_all_cu.shape[2]))[0]\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "else:\n",
    "    K = K_all_c.reshape((K_all_c.shape[0],K_all_c.shape[1]*K_all_c.shape[2]))[0]\n",
    "    K = np.append(K,['pre_updrs'],0)\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'r2'\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_gls = np.zeros_like(per_change)\n",
    "gerror = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "err_var = np.zeros_like(per_change)\n",
    "alphas = np.logspace(-4,4,100)\n",
    "Ks = []\n",
    "Kstg = []\n",
    "w = []\n",
    "wg = []\n",
    "pcases = []\n",
    "pscores = []\n",
    "s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528_wldd.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','pre op levadopa equivalent dose (mg)','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off,ledd = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo',\n",
    "                                                          'pre op levadopa equivalent dose (mg)')\n",
    "\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/phi/'\n",
    "roi_path = '/data/Ali/atlas/mcgill_pd_atlas/PD25-subcortical-labels.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(case_id).astype(int),np.asarray(subs).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "X_all = X_all[:,:,:]\n",
    "K_all = K_all[:,:,:]\n",
    "R_all = R_all[:,:,:]\n",
    "R = np.random.randint(low=0,high=1e6,size=(K_all.shape))\n",
    "K_all = np.char.add(K_all,R.astype(str))\n",
    "X_all_c, K, R, subsc, pre_imp, pre_updrs_off, per_change, ledd = util.re_index(X_all,K_all,R_all,c_cases_idx,subs,ids,all_rois,pre_imp,pre_updrs_off,post_imp,ledd)\n",
    "print(K.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = []\n",
    "err_var = np.zeros_like(per_change)\n",
    "r = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "    idy = y_train[y_train<=0.3]\n",
    "    \n",
    "    # Cross validation\n",
    "    Kt = K\n",
    "    Kt = np.append(Kt,['ledd'])\n",
    "    Kt = np.append(Kt,['y_train'])\n",
    "    Kt = np.insert(Kt,0,['id'])\n",
    "    # T = X_train.reshape(X_train.shape[0],-1)\n",
    "    # T = np.append(T,pre_updrs_off[train_index].reshape(-1,1),axis=1)\n",
    "    # T = np.append(T,ledd[train_index].reshape(-1,1),axis=1)\n",
    "    # T = np.append(T,y_train.reshape(-1,1),axis=1)\n",
    "    # T = np.insert(T,0,subsc[train_index],axis=1)\n",
    "    # T = pd.DataFrame(data=T,columns=Kt)\n",
    "    # T.astype({'id': 'int32'}).dtypes\n",
    "    # metadata = SingleTableMetadata()\n",
    "    # metadata.detect_from_dataframe(T)\n",
    "    # metadata.update_column(\n",
    "    #     column_name='id',\n",
    "    #     sdtype='id')\n",
    "    # metadata.set_primary_key(\n",
    "    #     column_name='id')\n",
    "    # metadata.validate()\n",
    "    # synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n",
    "    # synthesizer.fit(data=T)\n",
    "    # Ts = synthesizer.sample(len(subsc))\n",
    "    # Xs = Ts.to_numpy()\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,test_index,pre_updrs_off,ledd,False,False,False)\n",
    "    cvn = len(X0_ss0-1)\n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "      # Feature selection\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      sel = skf.SelectKBest(skf.r_regression,k=2900)\n",
    "      X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_ss = sel.transform(X_test_ss0)\n",
    "      dx, y_n = cKDTree(X0_ss).query(X_test_ss, k=1)\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=int(1e4),cv=cvn,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "    # Reconstruct nearest neighbor\n",
    "    r[j] = est_ls.predict(X0_ss[y_n,:])\n",
    "    err_var[j] = np.mean(abs(est_ls.predict(X0_ss)-y_train))\n",
    "    rerror[j] = np.abs(r[j]-y_train[y_n])\n",
    "    if r[j] > 0.1 and dx > 36:\n",
    "      results_ls[j] = est_ls.predict(X_test_ss)\n",
    "\n",
    "    print('Lasso predicts',str(np.round(results_ls[j],5)),\n",
    "              'for case',str(subsc[j]),'with',str(np.round(per_change[j],2)),\n",
    "              'with reconstruction error',str(np.round(rerror[j],9)),\n",
    "              'distance',str(np.round(dx,9)),\n",
    "              'and neighbor',str(np.round(y_train[y_n],2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls[results_ls>1] = 1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,1.75])\n",
    "plt.xlim([0,1.75])\n",
    "plt.style.use('default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
