{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from econml.sklearn_extensions.linear_model import WeightedLassoCV\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.metrics as sme\n",
    "import sklearn.feature_selection as skf\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.utils as sku\n",
    "import sklearn.decomposition as skd\n",
    "import sklearn.neighbors as skn\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from celer import GroupLassoCV\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch import nn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''\n",
    "<style>\n",
    ".jupyter-matplotlib {\n",
    "    background-color: #000;\n",
    "}\n",
    "\n",
    ".widget-label, .jupyter-matplotlib-header{\n",
    "    color: #fff;\n",
    "}\n",
    "\n",
    ".jupyter-button {\n",
    "    background-color: #333;\n",
    "    color: #fff;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment with CHH data\n",
    "X0_gt = np.load('/home/ali/RadDBS-QSM/data/npy/old/X0_gt_chh_rois.npy')\n",
    "X0_us = np.load('/home/ali/RadDBS-QSM/data/npy/old/X0_lr_chh_rois.npy')\n",
    "df = pd.read_csv('/home/ali/RadDBS-QSM/data/xlxs/updrs_iii_chh.csv')\n",
    "# Patient IDs\n",
    "subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "n_rois = 6\n",
    "# Data\n",
    "s_directory = open('/home/ali/RadDBS-QSM/data/roi/roi_list','r').read().splitlines()\n",
    "# Load\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/segs_chh', \"rb\") as fp:  \n",
    "    segs = pickle.load(fp)\n",
    "    n_cases = len(segs)\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/qsms_chh', \"rb\") as fp:  \n",
    "    qsms = pickle.load(fp)\n",
    "with open('/home/ali/RadDBS-QSM/data/phi/chh/Phi_mcl_gt_roi_chh', \"rb\") as fp:  \n",
    "    Phi_gt = pickle.load(fp)\n",
    "L = int(len(X0_gt)/n_cases)\n",
    "n_features = int(L/n_rois)\n",
    "# Only extract ROI if it is present in all cases\n",
    "seg_labels_all = segs[0]\n",
    "case_number = np.zeros_like(np.asarray(s_directory))\n",
    "for i in range(n_cases):\n",
    "    case_number[i] = float(s_directory[i][-2:])\n",
    "subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "for i in range(n_cases):\n",
    "    try:\n",
    "        print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "    except:\n",
    "        print('Case',subject_id[i],'quarantined')\n",
    "pre_updrs_iii_off =  np.asarray(df[df.columns[3]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)                             \n",
    "pre_updrs_iii_on =  np.asarray(df[df.columns[4]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "post_updrs_iii_off =  np.asarray(df[df.columns[6]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "\n",
    "per_change = (pre_updrs_iii_off-post_updrs_iii_off)/pre_updrs_iii_off\n",
    "pre_updrs_off = pre_updrs_iii_off\n",
    "X_all_c = X0_gt.reshape(n_cases,n_rois,n_features)\n",
    "X_all_c = X_all_c[:,0:4,:]\n",
    "X_all_c_us = X0_us.reshape(n_cases,n_rois,n_features)\n",
    "X_all_c_us = X_all_c_us[:,0:4,:]\n",
    "lct_change = (pre_updrs_iii_off-pre_updrs_iii_on)/pre_updrs_iii_off\n",
    "pre_imp = lct_change\n",
    "subsc = subject_id_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X0_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'r2'\n",
    "r = 1\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros(r*len(per_change))\n",
    "results_gls = np.zeros_like(per_change)\n",
    "gerror = np.zeros_like(per_change)\n",
    "alphas = np.logspace(-5,-3,100)\n",
    "Ks = []\n",
    "Kstg = []\n",
    "w = []\n",
    "wg = []\n",
    "pcases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = []\n",
    "err_var = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "c = 0\n",
    "rfcv_step = 1000\n",
    "\n",
    "for j in np.arange(c,len(subsc)):\n",
    "  rmax = 0\n",
    "  test_id = subsc[j]\n",
    "  test_index = subsc == test_id\n",
    "  train_index = subsc != test_id\n",
    "  X_train = X_all_c[train_index,:,:]\n",
    "  X_test = X_all_c[test_index,:,:]\n",
    "  X_train_us = X_all_c_us[train_index,:,:]\n",
    "  X_test_us = X_all_c_us[test_index,:,:]\n",
    "  y_train = per_change[train_index]\n",
    "  y_test = per_change[test_index]\n",
    "\n",
    "  y_cat = y_train <= 0.3\n",
    "  idy = np.where(y_cat==1)\n",
    "  # Cross validation\n",
    "  X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                              X_train,train_index,X_test,\n",
    "                                              test_index,pre_updrs_off,None,None,None,None,None,None,None,None,None,False,False,False)\n",
    "  X0_ss0_us,scaler_ss_us,X_test_ss0_us = util.model_scale(skp.StandardScaler(),\n",
    "                                              X_train_us,train_index,X_test_us,\n",
    "                                              test_index,pre_updrs_off,None,None,None,None,None,None,None,None,None,False,False,False)\n",
    "  # 10\n",
    "  cvn = 5\n",
    "  cv_scores = np.zeros((cvn,1))\n",
    "  cv_scoresu = np.zeros((cvn,1))\n",
    "  for jj in np.arange(2,cvn):\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Feature selection\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        sel = skf.RFECV(lasso,step=1000,cv=jj)\n",
    "        # Fully sampled\n",
    "        X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "        est_ls = lasso.fit(X0_sst,y_train)\n",
    "        cv_scores[jj] = est_ls.score(X0_sst,y_train)\n",
    "        print('LassoCV score for',jj,'is',cv_scores[jj])\n",
    "        # Under sampled\n",
    "        X0_sstu = sel.fit_transform(X0_ss0_us,y_train)\n",
    "        est_lsu = lasso.fit(X0_sstu,y_train)\n",
    "        cv_scoresu[jj] = est_lsu.score(X0_sstu,y_train)\n",
    "        print('Undersampled LassoCV score for',jj,'is',cv_scoresu[jj])\n",
    "\n",
    "  best_cv = np.argmax(cv_scores)\n",
    "  best_cvu = np.argmax(cv_scoresu)\n",
    "  # Fit whole dataset with optimal cv\n",
    "  lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "  sel = skf.RFECV(lasso,step=1000,cv=best_cv)\n",
    "  lassou = slm.LassoLarsCV(max_iter=1000,cv=best_cvu,n_jobs=-1,normalize=False,eps=0.1)\n",
    "  selu = skf.RFECV(lasso,step=1000,cv=best_cvu)\n",
    "  X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "  X_test_ss = sel.transform(X_test_ss0)\n",
    "  X0_ssu = selu.fit_transform(X0_ss0_us,y_train)\n",
    "  X_test_ssu = selu.transform(X_test_ss0_us)\n",
    "\n",
    "\n",
    "  # LASSO\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "    est_ls = lasso.fit(X0_ss,y_train)\n",
    "  results_ls[c] = est_ls.predict(X_test_ss)\n",
    "  print('Lasso predicts',str(np.round(results_ls[c],4)),\n",
    "            'for case with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cv)\n",
    "\n",
    "  est_lsu = lassou.fit(X0_ssu,y_train)\n",
    "  results_bls[c] = est_lsu.predict(X_test_ssu)\n",
    "  print('Lasso predicts',str(np.round(results_bls[c],4)),\n",
    "            'for case with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cvu)\n",
    "  c=c+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((np.repeat(pre_imp,r),\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               np.repeat(per_change,r),\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
