{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as sms\n",
    "import sklearn.linear_model as slm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.feature_selection as skf\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import util\n",
    "from scipy.spatial import cKDTree\n",
    "from lassonet import LassoNetRegressorCV\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.optim import SGD, Adam\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000001 for case 1.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000002 for case 2.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000003 for case 3.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000004 for case 4.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000005 for case 5.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000006 for case 6.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000007 for case 7.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000008 for case 8.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000009 for case 9.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000010 for case 10.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000011 for case 11.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000013 for case 13.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000014 for case 14.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000016 for case 16.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000018 for case 18.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000019 for case 19.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000020 for case 20.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000021 for case 21.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000022 for case 22.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000023 for case 23.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000024 for case 24.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000025 for case 25.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000026 for case 26.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000027 for case 27.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000028 for case 28.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000029 for case 29.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000030 for case 30.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000031 for case 31.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000032 for case 32.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000033 for case 33.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000034 for case 34.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000035 for case 35.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000036 for case 36.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000037 for case 37.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000038 for case 38.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000039 for case 39.0\n",
      "Found ROIs [0. 1. 2. 3. 4. 5. 6.] at segmentation directory file 00000040 for case 40.0\n"
     ]
    }
   ],
   "source": [
    "# Augment with CHH data\n",
    "X0_gt = np.load('/home/ali/RadDBS-QSM/data/npy/old/X0_gt_chh_rois.npy')\n",
    "df = pd.read_csv('/home/ali/RadDBS-QSM/data/xlxs/updrs_iii_chh.csv')\n",
    "# Patient IDs\n",
    "subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "n_rois = 6\n",
    "# Data\n",
    "s_directory = open('/home/ali/RadDBS-QSM/data/roi/roi_list','r').read().splitlines()\n",
    "# Load\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/segs_chh', \"rb\") as fp:  \n",
    "    segs = pickle.load(fp)\n",
    "    n_cases = len(segs)\n",
    "with open('/home/ali/RadDBS-QSM/data/pickles/qsms_chh', \"rb\") as fp:  \n",
    "    qsms = pickle.load(fp)\n",
    "with open('/home/ali/RadDBS-QSM/data/phi/chh/Phi_mcl_gt_roi_chh', \"rb\") as fp:  \n",
    "    Phi_gt = pickle.load(fp)\n",
    "L = int(len(X0_gt)/n_cases)\n",
    "n_features = int(L/n_rois)\n",
    "# Only extract ROI if it is present in all cases\n",
    "seg_labels_all = segs[0]\n",
    "case_number = np.zeros_like(np.asarray(s_directory))\n",
    "for i in range(n_cases):\n",
    "    case_number[i] = float(s_directory[i][-2:])\n",
    "subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "for i in range(n_cases):\n",
    "    try:\n",
    "        print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "    except:\n",
    "        print('Case',subject_id[i],'quarantined')\n",
    "pre_updrs_iii_off =  np.asarray(df[df.columns[3]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float)                             \n",
    "pre_updrs_iii_on =  np.asarray(df[df.columns[4]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "post_updrs_iii_off =  np.asarray(df[df.columns[6]][1:][np.in1d(subject_id,subject_id_corr)]).astype(float) \n",
    "\n",
    "per_change = (pre_updrs_iii_off-post_updrs_iii_off)/pre_updrs_iii_off\n",
    "pre_updrs_off = pre_updrs_iii_off\n",
    "X_all_c = X0_gt.reshape(n_cases,n_rois,n_features)\n",
    "X_all_c = X_all_c[:,0:4,:]\n",
    "\n",
    "lct_change = (pre_updrs_iii_off-pre_updrs_iii_on)/pre_updrs_iii_off\n",
    "pre_imp = lct_change\n",
    "# X_all_c = X_all_c.reshape(X_all_c.shape[0],z-1)\n",
    "# X_all_c = np.append(X_all_c,pre_imp.reshape(-1,1),axis=1)\n",
    "subsc = subject_id_corr\n",
    "subs_init = subsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV score: 0.9013353368956226\n",
      "Lasso predicts 0.76 with regularization 0.02345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing lambda with cross-validation: 100%|██████████| 5/5 [00:36<00:00,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda start: 0.00010514676204212955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m\n\u001b[1;32m     43\u001b[0m lassonet \u001b[38;5;241m=\u001b[39m LassoNetRegressorCV(\n\u001b[1;32m     44\u001b[0m M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-16\u001b[39m, \u001b[38;5;66;03m# Approximate standard LASSO\u001b[39;00m\n\u001b[1;32m     45\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_train), \u001b[38;5;66;03m# Leads to gradient descent optimization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Disable early stopping\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# What should these norms be...besides nonzero?\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m est_lsn \u001b[38;5;241m=\u001b[39m lassonet\u001b[38;5;241m.\u001b[39mfit(X0_ss,y_train)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print('Best lambda:',est_lsn.best_lambda_)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print('All LassoNet scores:',est_lsn.best_cv_scores_)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print('Mean LassoNetCV score:',est_lsn.best_cv_score_)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel:\u001b[39m\u001b[38;5;124m'\u001b[39m,lassonet\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:779\u001b[0m, in \u001b[0;36mBaseLassoNetCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    772\u001b[0m     X,\n\u001b[1;32m    773\u001b[0m     y,\n\u001b[1;32m    774\u001b[0m ):\n\u001b[1;32m    775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m    Note that if `lambda_` is not given, the trained model\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    will most likely not use any feature.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(X, y, return_state_dicts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:750\u001b[0m, in \u001b[0;36mBaseLassoNetCV.path\u001b[0;34m(self, X, y, return_state_dicts)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLambda start:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_start_)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# train with the chosen lambda sequence\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpath(\n\u001b[1;32m    751\u001b[0m     X,\n\u001b[1;32m    752\u001b[0m     y,\n\u001b[1;32m    753\u001b[0m     lambda_seq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambdas_[: best_lambda_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    754\u001b[0m     return_state_dicts\u001b[38;5;241m=\u001b[39mreturn_state_dicts,\n\u001b[1;32m    755\u001b[0m )\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, LassoNetCoxRegressor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mselected\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# condition to retrain and avoid having 0 feature which gives score 0\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;66;03m# TODO: handle backtrack in path even when return_state_dicts=False\u001b[39;00m\n\u001b[1;32m    759\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpath(\n\u001b[1;32m    760\u001b[0m         X,\n\u001b[1;32m    761\u001b[0m         y,\n\u001b[1;32m    762\u001b[0m         lambda_seq\u001b[38;5;241m=\u001b[39m[h\u001b[38;5;241m.\u001b[39mlambda_ \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m path[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],\n\u001b[1;32m    763\u001b[0m         return_state_dicts\u001b[38;5;241m=\u001b[39mreturn_state_dicts,\n\u001b[1;32m    764\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:458\u001b[0m, in \u001b[0;36mBaseLassoNet.path\u001b[0;34m(self, X, y, X_val, y_val, lambda_seq, lambda_max, return_state_dicts, callback, disable_lambda_warning)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mselected_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[1;32m    459\u001b[0m     X_train,\n\u001b[1;32m    460\u001b[0m     y_train,\n\u001b[1;32m    461\u001b[0m     X_val,\n\u001b[1;32m    462\u001b[0m     y_val,\n\u001b[1;32m    463\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    464\u001b[0m     lambda_\u001b[38;5;241m=\u001b[39mcurrent_lambda,\n\u001b[1;32m    465\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iters_path,\n\u001b[1;32m    466\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    467\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience_path,\n\u001b[1;32m    468\u001b[0m     return_state_dict\u001b[38;5;241m=\u001b[39mreturn_state_dicts,\n\u001b[1;32m    469\u001b[0m )\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dense \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mselected_count() \u001b[38;5;241m<\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    471\u001b[0m     is_dense \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:305\u001b[0m, in \u001b[0;36mBaseLassoNet._train\u001b[0;34m(self, X_train, y_train, X_val, y_val, batch_size, epochs, lambda_, optimizer, return_state_dict, patience)\u001b[0m\n\u001b[1;32m    302\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ans\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m/\u001b[39m n_train\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ans\n\u001b[0;32m--> 305\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[1;32m    306\u001b[0m     model\u001b[38;5;241m.\u001b[39mprox(\n\u001b[1;32m    307\u001b[0m         lambda_\u001b[38;5;241m=\u001b[39mlambda_ \u001b[38;5;241m*\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    308\u001b[0m         M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM,\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# fallback to running loss of first epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/optim/sgd.py:66\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m---> 66\u001b[0m         loss \u001b[38;5;241m=\u001b[39m closure()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     69\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/interfaces.py:285\u001b[0m, in \u001b[0;36mBaseLassoNet._train.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    281\u001b[0m crit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(model(X_train[batch]), y_train[batch])\n\u001b[1;32m    283\u001b[0m ans \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m     crit\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39ml2_regularization()\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_skip \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39ml2_regularization_skip()\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misfinite(ans):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/lassonet/model.py:118\u001b[0m, in \u001b[0;36mLassoNet.l2_regularization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m islice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    117\u001b[0m     ans \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 118\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnorm(\n\u001b[1;32m    119\u001b[0m             layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m    120\u001b[0m             p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    121\u001b[0m         )\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ans\n",
      "File \u001b[0;32m~/anaconda3/envs/pdlnetenv/lib/python3.11/site-packages/torch/functional.py:1626\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1624\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "scoring = 'r2'\n",
    "results_bls = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "scaler = skp.StandardScaler()\n",
    "#X = X_all_c.astype(float)#scaler.fit_transform(np.asarray(X_all_c,dtype=float).reshape(X_all_c.shape[0],-1))\n",
    "epsilon = 1e-1\n",
    "ledd = np.zeros_like(per_change)\n",
    "# Train\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "    # Try this with common scaling\n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,\n",
    "                                                test_index,pre_updrs_off,ledd,False,False,False)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "      # Feature selection\n",
    "      sel = skf.SelectKBest(skf.r_regression,k='all')\n",
    "      X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_ss = sel.transform(X_test_ss0)\n",
    "      y_n = cKDTree(X0_ss).query(X_test_ss, k=1)[1]\n",
    "    \n",
    "      Xy = np.dot(X0_ss.T,y_train)\n",
    "    if Xy.ndim == 1:\n",
    "        Xy = Xy[:, np.newaxis]\n",
    "    alpha_max = np.sqrt(np.sum(Xy**2, axis=1)).max()/len(y_train) \n",
    "    alphas = np.linspace(alpha_max*1e-3,alpha_max,10)\n",
    "    # LASSO\n",
    "    lasso = slm.LassoCV(max_iter=int(1e5),n_jobs=-1,alphas=alphas,random_state=0)\n",
    "    est_ls = lasso.fit(X0_ss,y_train)\n",
    "    print('LassoCV score:',est_ls.score(X0_ss,y_train))\n",
    "    results_ls[j] = est_ls.predict(X_test_ss).item()\n",
    "    print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "          'with regularization',str(np.round(est_ls.alpha_,5)))\n",
    "    # LASSONet\n",
    "    lr=1e-3\n",
    "    lassonet = LassoNetRegressorCV(\n",
    "    M=1e-16, # Approximate standard LASSO\n",
    "    batch_size=len(y_train), # Leads to gradient descent optimization\n",
    "    hidden_dims=(1,),\n",
    "    #n_iters=(int(1e5),int(1e2)), # Iterations for objective function and path\n",
    "    tol=0.99,#1-est_ls.tol,  \n",
    "    lambda_seq=alphas, # Path multipler and initial lambda disregarded\n",
    "    optim=partial(SGD,lr=lr,momentum=1), # Approximate coordinate descent\n",
    "    #backtrack=True, # Approximate monotonic coordinate descent path\n",
    "    verbose=1,\n",
    "    torch_seed=0,\n",
    "    random_state=0,\n",
    "    gamma=0.0, # No L2 regularization\n",
    "    gamma_skip=0.0, # No L2 regularization on skip connection\n",
    "    patience=None # Disable early stopping\n",
    "    )\n",
    "    # What should these norms be...besides nonzero?\n",
    "    est_lsn = lassonet.fit(X0_ss,y_train)\n",
    "  \n",
    "    # print('Best lambda:',est_lsn.best_lambda_)\n",
    "    # print('All LassoNet scores:',est_lsn.best_cv_scores_)\n",
    "    # print('Mean LassoNetCV score:',est_lsn.best_cv_score_)\n",
    "    print('Model:',lassonet.model)\n",
    "    print('LassoNetCV score:',est_lsn.score(X0_ss,y_train))\n",
    "    results_bls[j] = est_lsn.predict(X_test_ss).item()\n",
    "\n",
    "    # Training status\n",
    "    print('Lasso predicts',str(np.round(results_ls[j],2)),\n",
    "          'with regularization',str(np.round(est_ls.alpha_,5)),\n",
    "          'and',str(np.sum(est_ls.coef_!=0)),'nonzero coefficients',\n",
    "          'and LassoNet predicts',str(np.round(results_bls[j],2)),\n",
    "          'for case',str(int(subsc[j])),'with',str(np.round(per_change[j],2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               results_bls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                'LassoNet'\n",
    "                                ],(30,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
