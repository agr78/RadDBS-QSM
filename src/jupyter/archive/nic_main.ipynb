{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, roc_curve, auc\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import preprocessing as skp\n",
    "from sklearn import model_selection as sms\n",
    "from sklearn import feature_selection as skf\n",
    "from sklearn import linear_model as slm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util as util\n",
    "from util import latex_sci, confidence_interval\n",
    "from train import train_estimator\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "def remove_keymap_conflicts(new_keys_set):\n",
    "    for prop in plt.rcParams:\n",
    "        if prop.startswith('keymap.'):\n",
    "            keys = plt.rcParams[prop]\n",
    "            remove_list = set(keys) & new_keys_set\n",
    "            for key in remove_list:\n",
    "                keys.remove(key)\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0]//2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index-1) % volume.shape[0] \n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index+1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set window level\n",
    "level = 0\n",
    "window = 500\n",
    "m1=level-window/2\n",
    "m2=level+window/2\n",
    "visualize = 1\n",
    "# Load data\n",
    "nrows = 256\n",
    "ncols = 256\n",
    "nslices = 160\n",
    "segs = []\n",
    "qsms = []\n",
    "laros = []\n",
    "voxel_sizes = []\n",
    "trackers = []\n",
    "q_directory = '/data/Ali/RadDBS-QSM/data/nii/chh/orig/qsm/'\n",
    "q_directory = os.listdir(q_directory)\n",
    "q_directory = sorted(q_directory)\n",
    "qu_directory = '/data/Ali/RadDBS-QSM/data/nii/chh/lr_roi_ft'\n",
    "qu_directory = os.listdir(qu_directory)\n",
    "qu_directory = sorted(qu_directory)\n",
    "s_directory = '/data/Ali/RadDBS-QSM/data/nii/chh/orig/seg/'\n",
    "s_directory = os.listdir(s_directory)\n",
    "s_directory = sorted(s_directory)\n",
    "m_directory = '/data/Ali/RadDBS-QSM/data/nii/chh/masks'\n",
    "m_directory = os.listdir(m_directory)\n",
    "m_directory = sorted(m_directory)\n",
    "case_list = []\n",
    "d_count = 0\n",
    "if visualize == 1:\n",
    "    for filename in q_directory:\n",
    "    \n",
    "        seg_filename = s_directory[d_count]\n",
    "        laro_filename = qu_directory[d_count]\n",
    "        mask_filename = m_directory[d_count]\n",
    "        seg = nib.load('/data/Ali/RadDBS-QSM/data/nii/chh/orig/seg/'+seg_filename)\n",
    "        mask = nib.load('/data/Ali/RadDBS-QSM/data/nii/chh/masks/'+mask_filename)\n",
    "        voxel_size = seg.header['pixdim'][0:3]\n",
    "        voxel_sizes.append(voxel_size)\n",
    "        segs.append(seg.get_fdata()[:nrows,:ncols,:nslices])\n",
    "        qsm = nib.load('/data/Ali//RadDBS-QSM/data/nii/chh/orig/qsm/'+filename)\n",
    "        qsms.append(qsm.get_fdata()[:nrows,:ncols,:nslices])\n",
    "\n",
    "        laro = nib.load('/data/Ali/RadDBS-QSM/data/nii/chh/lr_roi_ft/'+laro_filename)\n",
    "        laros.append(1000*laro.get_fdata()[:nrows,:ncols,:nslices])\n",
    "        print('Appending arrays with segmentation',seg_filename,'QSM,',filename,\n",
    "              'LARO,',laro_filename,'and mask',mask_filename)\n",
    "        case_list.append(filename)\n",
    "        n_cases = len(segs)\n",
    "        d_count = d_count+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/Ali/RadDBS-QSM/data/xlxs/updrs_iii_chh_cvs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient IDs\n",
    "subject_id = np.asarray(df[df.columns[0]])[1:]\n",
    "\n",
    "# Only extract ROI if it is present in all cases\n",
    "seg_labels_all = segs[0]\n",
    "case_number = np.zeros_like(np.asarray(s_directory))\n",
    "for i in range(n_cases):\n",
    "    case_number[i] = float(s_directory[i][:2])\n",
    "subject_id_corr = subject_id[np.in1d(subject_id,case_number)]\n",
    "age = np.nan_to_num(np.asarray(df[df.columns[-4]])[1:][np.in1d(subject_id,case_number)].astype(float))\n",
    "sex = np.nan_to_num(np.asarray(df[df.columns[-3]])[1:][np.in1d(subject_id,case_number)].astype(float))\n",
    "dd = np.nan_to_num(np.asarray(df[df.columns[-2]])[1:][np.in1d(subject_id,case_number)].astype(float))\n",
    "ledd = np.nan_to_num(np.asarray(df[df.columns[-1]])[1:][np.in1d(subject_id,case_number)].astype(float))\n",
    "\n",
    "for i in np.arange(n_cases):\n",
    "    try:\n",
    "        print('Found ROIs',str(np.unique(segs[i])),'at segmentation directory file',s_directory[i],'for case',str(subject_id_corr[i]))\n",
    "    except:\n",
    "        print('Case',subject_id[i],'quarantined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_updrs_iii_off =  np.asarray(df[df.columns[3]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])                                \n",
    "pre_updrs_iii_on =  np.asarray(df[df.columns[4]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])\n",
    "post_updrs_iii_off =  np.asarray(df[df.columns[6]][np.hstack((False,np.in1d(subject_id,subject_id_corr)))])\n",
    "\n",
    "per_change = (np.asarray(pre_updrs_iii_off).astype(float)-np.asarray(post_updrs_iii_off).astype(float))/(np.asarray(pre_updrs_iii_off).astype(float))\n",
    "lct_change = (np.asarray(pre_updrs_iii_off).astype(float)-(np.asarray(pre_updrs_iii_on)).astype(float))/(np.asarray(pre_updrs_iii_off).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"radiomics\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "reextract = 0\n",
    "\n",
    "# Assume all voxel sizes are identical\n",
    "voxel_size = (0.9,0.9,0.9)\n",
    "if reextract == 1:\n",
    "    # Generate feature structure Phi from all ROIs and all cases\n",
    "    extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "    extractor.enableAllFeatures()\n",
    "    extractor.enableAllImageTypes()\n",
    "    extractor.enableFeatureClassByName('shape2D',enabled = False)\n",
    "\n",
    "    seg_labels_all = np.unique(np.asarray(segs))\n",
    "    Phi_gt = []\n",
    "    Phi_vd = []\n",
    "    Phi_lr = []\n",
    "    seg_labels = []\n",
    "    reextract = 0\n",
    "    x_row_gt = []\n",
    "    x_row_lr = []\n",
    "\n",
    "    keylib = []\n",
    "    roilib = []\n",
    "    loop_count = 1\n",
    "    n_rois = seg_labels_all[seg_labels_all>0].__len__()\n",
    "    roi_names = np.asarray(['Background','Right substantia nigra','Right subthalamic nucleus',\n",
    "                            'Left subthalamic nucleus', 'Left substantia nigra', 'Right dentate nucleus', 'Left dentate nucleus'])\n",
    "    for i in np.arange(subject_id_corr.__len__()):\n",
    "        seg_sitk = sitk.GetImageFromArray(segs[i])\n",
    "        seg_sitk.SetSpacing(voxel_size)\n",
    "        qsm_sitk_gt = sitk.GetImageFromArray(qsms[i])\n",
    "        qsm_sitk_gt.SetSpacing(voxel_size)\n",
    "        qsm_sitk_lr = sitk.GetImageFromArray(laros[i])\n",
    "        qsm_sitk_lr.SetSpacing(voxel_size)\n",
    "        # Index back since subject 12 is missing ROIs\n",
    "        for j in seg_labels_all:\n",
    "            if j>0:\n",
    "                fv_count = 0\n",
    "                featureVector_gt = extractor.execute(qsm_sitk_gt,seg_sitk,label=int(j));\n",
    "                featureVector_lr = extractor.execute(qsm_sitk_lr,seg_sitk,label=int(j));\n",
    "                Phi_gt.append(featureVector_gt)\n",
    "                Phi_lr.append(featureVector_lr)\n",
    "                for key, value in six.iteritems(featureVector_gt):\n",
    "                    if 'diagnostic' in key:\n",
    "                        next\n",
    "                    else:\n",
    "                        x_row_gt.append(featureVector_gt[key])\n",
    "                        x_row_lr.append(featureVector_lr[key])\n",
    "                        fv_count = fv_count+1\n",
    "                        keylib.append(key)\n",
    "                        roilib.append(roi_names[int(j)])\n",
    "                x_row_gt.append(pre_updrs_iii_off[i])\n",
    "                x_row_lr.append(pre_updrs_iii_off[i])\n",
    "                fv_count = fv_count+1\n",
    "        print('Extracting features for subject',subject_id_corr[i],'and appending feature matrix with vector of length',fv_count,'with UPDRS score',pre_updrs_iii_off[i])\n",
    "                \n",
    "    X0_gt = np.array(x_row_gt)\n",
    "    X0_lr = np.array(x_row_lr)\n",
    "    np.save('/data/Ali/RadDBS-QSM/data/npy/rp/X0_gt_chh_rois_rp.npy',X0_gt)\n",
    "    np.save('/data/Ali/RadDBS-QSM/data/npy/rp/X0_lr_chh_rois_rp.npy',X0_lr)\n",
    "\n",
    "    K = np.asarray(keylib)\n",
    "    R = np.asarray(roi_names)\n",
    "    np.save('/data/Ali/RadDBS-QSM/data/npy/rp/K_chh_rp.npy',K)\n",
    "    np.save('/data/Ali/RadDBS-QSM/data/npy/rp/R_chh_rp.npy',R)\n",
    "\n",
    "    print('Saving ground truth feature vector')\n",
    "    with open('/data/Ali/RadDBS-QSM/data/npy/rp/Phi_mcl_gt_roi_chh_rp', 'wb') as fp:  \n",
    "        pickle.dump(Phi_gt, fp)\n",
    "    \n",
    "    print('Saving undersampled feature vector')\n",
    "    with open('/data/Ali/RadDBS-QSM/data/npy/rp/Phi_mcl_lr_roi_chh_rp', 'wb') as fp:  \n",
    "        pickle.dump(Phi_lr, fp)\n",
    "\n",
    "else:\n",
    "    X0_gt = np.load('/data/Ali/RadDBS-QSM/data/npy/rp/X0_gt_chh_rois_rp.npy')\n",
    "    X0_lr = np.load('/data/Ali/RadDBS-QSM/data/npy/rp/X0_lr_chh_rois_rp.npy')\n",
    "    K = np.load('/data/Ali/RadDBS-QSM/data/npy/rp/K_chh_rp.npy')\n",
    "    R = np.load('/data/Ali/RadDBS-QSM/data/npy/rp/R_chh_rp.npy')\n",
    "    n_rois = R.shape[0]-1\n",
    "    with open('/data/Ali/RadDBS-QSM/data/npy/rp/Phi_mcl_gt_roi_chh_rp', \"rb\") as fp:  \n",
    "        Phi_gt = pickle.load(fp)\n",
    "    \n",
    "    with open('/data/Ali/RadDBS-QSM/data/npy/rp/Phi_mcl_lr_roi_chh_rp', \"rb\") as fp:  \n",
    "        Phi_lr = pickle.load(fp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1596\n",
    "n_rois = 6\n",
    "X_all_c = X0_gt.reshape(n_cases,n_rois,n_features)[:,0:4,:]\n",
    "K_all_c = K.reshape(n_cases,n_rois,n_features-1)[:,0:4,:]\n",
    "K_all_c = np.char.add(K_all_c[0,:,:].reshape(-1,1),' ')\n",
    "R_all_c = np.repeat(R[1:5],n_features-1)\n",
    "K_all_c = np.char.add(np.squeeze(K_all_c),np.squeeze(R_all_c))\n",
    "K_all_c = np.append(K_all_c,['pre updrs']*5)\n",
    "R_all_c = np.append(R_all_c,['pre updrs']*5)\n",
    "K_all_c = np.append(K_all_c,['age'])\n",
    "R_all_c = np.append(R_all_c,['age'])\n",
    "K_all_c = np.append(K_all_c,['disease duration'])\n",
    "R_all_c = np.append(R_all_c,['disease duration'])\n",
    "K_all_c = np.append(K_all_c,['sex'])\n",
    "R_all_c = np.append(R_all_c,['sex'])\n",
    "# K_all_c = np.append(K_all_c,['ledd'])\n",
    "# R_all_c = np.append(R_all_c,['ledd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = len(per_change)\n",
    "n_roisc = Phi_gt.__len__()/n_cases\n",
    "L = int(len(X0_gt)/n_cases)\n",
    "n_features = int(L/n_rois)\n",
    "subsc = subject_id_corr\n",
    "pre_updrs_off = pre_updrs_iii_off\n",
    "results_ls_aug = np.zeros_like(per_change)\n",
    "\n",
    "results_lgr_aug = np.zeros_like(per_change)\n",
    "results_lgrp_aug = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "results_lgr = np.zeros_like(per_change)\n",
    "results_lgrp = np.zeros_like(per_change)\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONWARNINGS']='ignore'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ns = 10\n",
    "results_ls_aug = np.zeros((ns,len(per_change)))\n",
    "results_ls_wbs = np.zeros((ns,len(per_change)))\n",
    "results_ls_smogn = np.zeros((ns,len(per_change)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = 1\n",
    "if retrain == 0:\n",
    "    plt.rcParams['figure.figsize'] = [75, 5]\n",
    "    fs = 32\n",
    "    fig,ax = plt.subplots(1,ns,sharex=True,sharey=True)\n",
    "    col = np.where(per_change <= 0.3,'orangered','blue')\n",
    "for j in np.arange(ns):\n",
    "    if retrain == 1:\n",
    "        results_ls_aug[j,:] = train_estimator(subsc,X_all_c,K_all_c,per_change,pre_updrs_iii_on,age,sex,dd,None,'nc_iid_q',True,True,j,True)\n",
    "        #results_ls_wbs[j,:] = train_estimator(subsc,X_all_c,K_all_c,per_change,pre_updrs_iii_on,age,sex,dd,None,'wbs',True,True,j,True)\n",
    "        #results_ls_smogn[j,:] = train_estimator(subsc,X_all_c,K_all_c,per_change,pre_updrs_iii_on,age,sex,dd,None,'smogn',True,True,j,True)\n",
    "    else:\n",
    "        results_ls_smogn[j,:] = np.load('results_ls_smogn_'+str(j)+'_cvs_puo.npy')\n",
    "        results_ls_aug[j,:] = np.load('results_ls_nc_iid_'+str(j)+'_cvs_puo.npy')\n",
    "        ax[j].scatter(results_ls_aug[j,:],per_change, c=col,linewidth=0)\n",
    "        lr = stats.linregress(results_ls_aug[j,:],per_change)\n",
    "        y_model = results_ls_aug[j,:]*lr.slope+lr.intercept\n",
    "        ax[j].plot(results_ls_aug[j,:],y_model,color='r')\n",
    "        pl = r'$'+latex_sci(lr.pvalue,0)+'$'\n",
    "        ax[j].text(0.5,0,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+pl,\n",
    "                    ha='left', va='bottom', transform=ax[j].transAxes,fontsize=fs,\n",
    "                    bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round')) \n",
    "        ax[j].hlines(0.3,0,1,linestyle='dashed',color='black')\n",
    "        ax[j].vlines(0.3,0,1,linestyle='dashed',color='black')\n",
    "        results_ls_wbs[j,:] = np.load('results_ls_wbs_'+str(j)+'_cvs_puo.npy')\n",
    "        plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = 1.25\n",
    "fs = 32\n",
    "ofx = 0.515\n",
    "ofy = 0.8\n",
    "pre_imp = (np.asarray(pre_updrs_iii_off,dtype=float)-np.asarray(pre_updrs_iii_on,dtype=float))/np.asarray(pre_updrs_iii_off,dtype=float)\n",
    "plt.rcParams['figure.figsize'] = [25, 25]\n",
    "fig,ax = plt.subplots(2,2,sharex=True,sharey=True)\n",
    "col = np.where(per_change <= 0.3,'orangered','blue')\n",
    "ax[0,0].scatter(pre_imp,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(pre_imp,per_change)\n",
    "y_model = pre_imp*lr.slope+lr.intercept\n",
    "ax[0,0].plot(pre_imp,y_model,color='r')\n",
    "ci,pi,x_line,y_line = util.confidence_interval(pre_imp,per_change,ylim)\n",
    "ax[0,0].fill_between(x_line, (y_line+ci), (y_line-ci), color='r', alpha=0.05)\n",
    "ax[0,0].text(ofx,ofy,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,3))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,3))+'\\n'+'$p$ = '+str(('{:.3f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[0,0].transAxes,fontsize=fs,\n",
    "                    bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round')) \n",
    "ax[0,0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0,0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0,0].set_title('LCT',fontsize=fs)\n",
    "ax[0,0].set_xlabel('Prediction',fontsize=fs)\n",
    "ax[0,0].xaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[0,0].set_xlim([0,ylim])\n",
    "ax[0,0].set_ylabel('True UPDRS-III improvement',fontsize=fs)\n",
    "ax[0,0].yaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[0,0].set_ylim([0,ylim])\n",
    "\n",
    "ax[0,1].scatter(np.mean(results_ls_aug,axis=0),per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(np.mean(results_ls_aug,axis=0)),per_change)\n",
    "y_model = np.mean(results_ls_aug,axis=0)*lr.slope+lr.intercept\n",
    "ax[0,1].plot(np.mean(results_ls_aug,axis=0),y_model,color='r')\n",
    "ci,pi,x_line,y_line = util.confidence_interval(np.mean(results_ls_aug,axis=0),per_change,ylim)\n",
    "ax[0,1].fill_between(x_line,y_line+ci,y_line-ci,color = 'r',label = '95% confidence interval',alpha=0.05)\n",
    "pl = r'$'+latex_sci(lr.pvalue,0)+'$'\n",
    "ax[0,1].text(ofx+0.013,ofy-0.01,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+pl,\n",
    "                    ha='left', va='bottom', transform=ax[0,1].transAxes,fontsize=fs,\n",
    "                    bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round')) \n",
    "ax[0,1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0,1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0,1].set_title('Noise Compensated Lasso',fontsize=fs)\n",
    "ax[0,1].set_xlabel('Prediction',fontsize=fs)\n",
    "ax[0,1].xaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[0,1].yaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "\n",
    "ax[1,0].scatter(np.mean(results_ls_smogn,axis=0),per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(np.mean(results_ls_smogn,axis=0)),per_change)\n",
    "y_model = np.mean(results_ls_smogn,axis=0)*lr.slope+lr.intercept\n",
    "ax[1,0].plot(np.mean(results_ls_smogn,axis=0),y_model,color='r')\n",
    "ci,pi,x_line,y_line = util.confidence_interval(np.mean(results_ls_smogn,axis=0),per_change,ylim)\n",
    "ax[1,0].fill_between(x_line,y_line+ci,y_line-ci,color = 'r',label = '95% confidence interval',alpha=0.05)\n",
    "pl = r'$'+latex_sci(lr.pvalue,0)+'$'\n",
    "ax[1,0].text(ofx+0.015,ofy-0.01,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+pl,\n",
    "                    ha='left', va='bottom', transform=ax[1,0].transAxes,fontsize=fs,\n",
    "                    bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round')) \n",
    "ax[1,0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1,0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1,0].set_xlabel('Prediction',fontsize=fs)\n",
    "ax[1,0].xaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[1,0].set_ylabel('True Improvement',fontsize=fs)\n",
    "ax[1,0].yaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[1,0].set_title('SMOGN Lasso',fontsize=fs)\n",
    "\n",
    "ax[1,1].scatter(np.mean(results_ls_wbs,axis=0),per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(np.mean(results_ls_wbs,axis=0)),per_change)\n",
    "y_model = np.mean(results_ls_wbs,axis=0)*lr.slope+lr.intercept\n",
    "ax[1,1].plot(np.mean(results_ls_wbs,axis=0),y_model,color='r')\n",
    "ci,pi,x_line,y_line = util.confidence_interval(np.mean(results_ls_wbs,axis=0),per_change,ylim)\n",
    "ax[1,1].fill_between(x_line,y_line+ci,y_line-ci,color = 'r',label = '95% confidence interval',alpha=0.05)\n",
    "pl = r'$'+latex_sci(lr.pvalue,0)+'$'\n",
    "ax[1,1].text(ofx+0.013,ofy-0.01,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+pl,\n",
    "                    ha='left', va='bottom', transform=ax[1,1].transAxes,fontsize=fs,\n",
    "                    bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round')) \n",
    "\n",
    "ax[1,1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1,1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1,1].set_xlabel('Prediction',fontsize=fs)\n",
    "ax[1,1].xaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[1,1].yaxis.set_tick_params(labelleft=True,labelsize=fs//1.5)\n",
    "ax[1,1].set_title('Wild Boostrap Lasso',fontsize=fs)\n",
    "\n",
    "plt.style.use('default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
