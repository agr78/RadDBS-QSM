{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import preprocessing as skp\n",
    "from sklearn import model_selection as sms\n",
    "from sklearn import feature_selection as skf\n",
    "from sklearn import linear_model as slm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util as util\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch import nn\n",
    "from scipy.spatial import cKDTree\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "def remove_keymap_conflicts(new_keys_set):\n",
    "    for prop in plt.rcParams:\n",
    "        if prop.startswith('keymap.'):\n",
    "            keys = plt.rcParams[prop]\n",
    "            remove_list = set(keys) & new_keys_set\n",
    "            for key in remove_list:\n",
    "                keys.remove(key)\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0]//2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index-1) % volume.shape[0] \n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index+1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping CORNELL ID\n",
      "Keeping Age\n",
      "Keeping Sex\n",
      "Keeping Ethnicity\n",
      "Keeping Race\n",
      "Keeping Disease Duration (year)\n",
      "Keeping Physician\n",
      "Keeping Starkstein Apathy Off\n",
      "Keeping  BDI OFF\n",
      "Keeping  BAI OFF\n",
      "Keeping  QUIP OFF\n",
      "Keeping  QUIP ON\n",
      "Keeping  OFF (pre-dbs updrs)\n",
      "Keeping  pre op levadopa equivalent dose (mg)\n",
      "Keeping  Location\n",
      "Keeping  Target\n",
      "Keeping  Test medication status\n",
      "Keeping  postop quip (on)\n",
      "{' OFF (pre-dbs updrs)', ' BAI OFF', 'Physician', ' Test medication status', 'Disease Duration (year)', ' Location', ' QUIP ON', 'Race', ' postop quip (on)', 'Age', 'CORNELL ID', ' QUIP OFF', 'Starkstein Apathy Off', ' pre op levadopa equivalent dose (mg)', 'Sex', ' Target', 'Ethnicity', ' BDI OFF'}\n",
      "['X_115_01.npy', 'X_115_02.npy', 'X_115_03.npy', 'X_115_04.npy', 'X_115_05.npy', 'X_115_06.npy', 'X_115_07.npy', 'X_115_08.npy', 'X_115_09.npy', 'X_115_10.npy', 'X_115_100.npy', 'X_115_101.npy', 'X_115_102.npy', 'X_115_104.npy', 'X_115_105.npy', 'X_115_106.npy', 'X_115_107.npy', 'X_115_108.npy', 'X_115_109.npy', 'X_115_11.npy', 'X_115_110.npy', 'X_115_111.npy', 'X_115_112.npy', 'X_115_113.npy', 'X_115_114.npy', 'X_115_115.npy', 'X_115_116.npy', 'X_115_12.npy', 'X_115_13.npy', 'X_115_14.npy', 'X_115_15.npy', 'X_115_16.npy', 'X_115_17.npy', 'X_115_18.npy', 'X_115_19.npy', 'X_115_20.npy', 'X_115_22.npy', 'X_115_23.npy', 'X_115_24.npy', 'X_115_25.npy', 'X_115_26.npy', 'X_115_27.npy', 'X_115_29.npy', 'X_115_30.npy', 'X_115_31.npy', 'X_115_32.npy', 'X_115_33.npy', 'X_115_34.npy', 'X_115_36.npy', 'X_115_37.npy', 'X_115_39.npy', 'X_115_40.npy', 'X_115_41.npy', 'X_115_42.npy', 'X_115_44.npy', 'X_115_45.npy', 'X_115_46.npy', 'X_115_48.npy', 'X_115_49.npy', 'X_115_50.npy', 'X_115_51.npy', 'X_115_52.npy', 'X_115_53.npy', 'X_115_55.npy', 'X_115_56.npy', 'X_115_57.npy', 'X_115_58.npy', 'X_115_59.npy', 'X_115_60.npy', 'X_115_61.npy', 'X_115_62.npy', 'X_115_63.npy', 'X_115_64.npy', 'X_115_66.npy', 'X_115_67.npy', 'X_115_68.npy', 'X_115_69.npy', 'X_115_70.npy', 'X_115_71.npy', 'X_115_72.npy', 'X_115_73.npy', 'X_115_74.npy', 'X_115_75.npy', 'X_115_76.npy', 'X_115_77.npy', 'X_115_78.npy', 'X_115_79.npy', 'X_115_80.npy', 'X_115_81.npy', 'X_115_82.npy', 'X_115_83.npy', 'X_115_84.npy', 'X_115_85.npy', 'X_115_86.npy', 'X_115_87.npy', 'X_115_88.npy', 'X_115_89.npy', 'X_115_90.npy', 'X_115_92.npy', 'X_115_93.npy', 'X_115_94.npy', 'X_115_95.npy', 'X_115_97.npy', 'X_115_98.npy', 'X_115_99.npy']\n",
      "Allocated arrays\n",
      "Created feature matrix\n",
      "Created ROI matrix\n",
      "Created feature label matrix\n",
      "['0.0' 'Left red nucleus' 'Left substantia nigra'\n",
      " 'Left subthalamic nucleus' 'Right Substantia nigra' 'Right red nucleus'\n",
      " 'Right subthalamic nucleus']\n",
      "17\n",
      "32\n",
      "['0.0' 'Left substantia nigra' 'Left subthalamic nucleus'\n",
      " 'Right Substantia nigra' 'Right subthalamic nucleus']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ali/anaconda3/envs/pdradenv/lib/python3.7/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "cv_names = {'CORNELL ID',\n",
    "            ' OFF (pre-dbs updrs)',\n",
    "            ' QUIP ON',\n",
    "            ' QUIP OFF',\n",
    "            ' BDI OFF',\n",
    "            'Starkstein Apathy Off',\n",
    "            ' BAI OFF',\n",
    "            ' postop quip (on)',\n",
    "            'Age',\n",
    "            'Sex',\n",
    "            'Ethnicity',\n",
    "            'Race',\n",
    "            'Disease Duration (year)',\n",
    "            'Physician',\n",
    "            ' pre op levadopa equivalent dose (mg)',\n",
    "            ' Location',\n",
    "            ' Target',\n",
    "            ' Test medication status'}\n",
    "\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/dbs_03292024.csv'\n",
    "motor_df = util.filter_data(file_dir,cv_names,True)\n",
    "# Find cases with all required scores\n",
    "cv_dict = util.filter_cases(motor_df,cv_names)\n",
    "subs = cv_dict['CORNELL ID']\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/new/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/new/phi/'\n",
    "roi_path = '/home/ali/RadDBS-QSM/data/xlxs/new_segs.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "print(np.unique(R_all))\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Use cases from only 1 rater\n",
    "phys = cv_dict['Physician']\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(ids).astype(int),np.asarray(cv_dict['CORNELL ID']).astype(int))#[phys==1].astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "# Exclude GPi\n",
    "c_cases_idx[ids == 36] = 0\n",
    "c_cases_idx[ids == 53] = 0\n",
    "c_cases_idx[ids == 98] = 0\n",
    "c_cases_idx[ids == 108] = 0\n",
    "# Exclude infinite BAI\n",
    "c_cases_idx[ids == 16] = 0\n",
    "c_cases_idx[ids == 45] = 0\n",
    "c_cases_idx[ids == 46] = 0\n",
    "# Exclue infinite QUIP\n",
    "c_cases_idx[ids == 2] = 0\n",
    "c_cases_idx[ids == 6] = 0\n",
    "c_cases_idx[ids == 10] = 0\n",
    "c_cases_idx[ids == 11] = 0\n",
    "c_cases_idx[ids == 44] = 0\n",
    "c_cases_idx[ids == 77] = 0\n",
    "c_cases_idx[ids == 78] = 0\n",
    "c_cases_idx[ids == 87] = 0\n",
    "c_cases_idx[ids == 95] = 0\n",
    "\n",
    "subsc[np.isfinite(per_change)]\n",
    "print(np.sum(c_cases_idx))\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "print(len(s_cases_idx))\n",
    "        \n",
    "X_all_c = X_all[c_cases_idx,2:6,:]\n",
    "#X_all_c = (np.load('X2h_sr.npy').T).reshape((31,6381))\n",
    "# print('Applying combat')\n",
    "K_all_c = K_all[c_cases_idx,2:6,:]\n",
    "R_all_c = R_all[c_cases_idx,2:6,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "\n",
    "per_change = ((cv_dict[' QUIP OFF']-cv_dict[' postop quip (on)'])/cv_dict[' QUIP OFF'])[s_cases_idx]\n",
    "pre_imp = ((cv_dict[' QUIP OFF']-cv_dict[' QUIP ON'])/cv_dict[' QUIP OFF'])[s_cases_idx]\n",
    "pre_updrs = cv_dict[' OFF (pre-dbs updrs)'][s_cases_idx]\n",
    "dd = cv_dict['Disease Duration (year)'][s_cases_idx]\n",
    "ledd = cv_dict[' pre op levadopa equivalent dose (mg)'][s_cases_idx]\n",
    "tmed = cv_dict[' Test medication status'][s_cases_idx]\n",
    "pre_bdi = cv_dict[' BDI OFF'][s_cases_idx]\n",
    "pre_sas = cv_dict['Starkstein Apathy Off'][s_cases_idx]\n",
    "pre_bai = cv_dict[' BAI OFF'][s_cases_idx]\n",
    "age = cv_dict['Age'][s_cases_idx]\n",
    "loc = cv_dict[' Location'][s_cases_idx]\n",
    "sex = cv_dict['Sex'][s_cases_idx]\n",
    "rce = cv_dict['Race'][s_cases_idx]\n",
    "eth = cv_dict['Ethnicity'][s_cases_idx]\n",
    "tgt = cv_dict[' Target'][s_cases_idx]\n",
    "phys = cv_dict['Physician'][s_cases_idx]\n",
    "subsc = subs[s_cases_idx]\n",
    "    \n",
    "# Reshape keys and ROIs\n",
    "if all_rois == True:\n",
    "    K_all_cu = np.empty((K_all_c.shape[0],K_all_c.shape[1],K_all_c.shape[2]+1),dtype=object)\n",
    "    K_all_cu[:,:,:-1] = K_all_c\n",
    "    K_all_cu[:,:,-1] = 'pre_updrs'\n",
    "    K_all_cu[:,:,-1] = 'disease_duration'\n",
    "    K_all_cu[:,:,-1] = 'pre op levadopa equivalent dose (mg)'\n",
    "    K_all_cu[:,:,-1] = ' Test medication status'\n",
    "    K_all_cu[:,:,-1] = 'Physician'\n",
    "    K_all_cu[:,:,-1] = 'Age'\n",
    "    K_all_cu[:,:,-1] = 'Location'\n",
    "    K_all_cu[:,:,-1] = 'Sex'\n",
    "    K_all_cu[:,:,-1] = 'Race'\n",
    "    K_all_cu[:,:,-1] = 'Ethnicity'\n",
    "    \n",
    "    K = K_all_cu.reshape((K_all_cu.shape[0],K_all_cu.shape[1]*K_all_cu.shape[2]))[0]\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "else:\n",
    "    K_all_c = K_all_c.reshape((K_all_c.shape[0],K_all_c.shape[1]*K_all_c.shape[2]))[0]\n",
    "    R_all_c = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "\n",
    "print(np.unique(R_all_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = len(per_change)\n",
    "results_ls_aug = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution of: -3.136873196248196 9.299908379131438 -2.841246358608801\n",
      "LassoCV score for 2 is [0.] from dataset of size (16, 4390)\n",
      "LassoCV score for 3 is [0.] from dataset of size (16, 6390)\n",
      "LassoCV score for 4 is [0.] from dataset of size (16, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-94903192ffdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0mlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLassoLarsCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0msel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mX0_sst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0_ss0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m       \u001b[0mX_test_sst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_ss0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0mX0_ss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX0_sst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0;31m# print('First case, returning KFold(cv)')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0;31m# print('Second case:',cv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pdradenv/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34m\"k-fold cross-validation requires at least one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0;34m\" train/test split by setting n_splits=2 or more,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;34m\" got n_splits={0}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=0."
     ]
    }
   ],
   "source": [
    "Js = []\n",
    "aug = False\n",
    "err_var = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "c = 0\n",
    "for j in np.arange(len(subsc)):\n",
    "    best_cv = 2\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    yc = 0.3\n",
    "    y_cat = y_train <= yc\n",
    "    idy = np.where(y_cat==1)\n",
    "    # Cross validation\n",
    "                                          \n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,\n",
    "                                                test_index,pre_bai,pre_bdi,pre_sas,pre_updrs,tmed,ledd,age,dd,loc,phys,False,False,False)\n",
    "    cvn = 5\n",
    "    cv_scores = np.zeros((cvn,1))\n",
    "    rs = 1\n",
    "    rcfs = 1000\n",
    "    (mu, sigma) = stats.norm.fit(y_train)\n",
    "    kappa = stats.skew(y_train)\n",
    "    print('Label distribution of:',mu,sigma,kappa)\n",
    "    for jj in np.arange(2,cvn):\n",
    "      # Resample to avoid stratification errors\n",
    "      while np.sum(y_cat) < cvn:\n",
    "        np.random.seed(rs)\n",
    "        idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "        X0_ss0 = np.append(X0_ss0,X0_ss0[idyr,:].reshape(1,-1),axis=0)\n",
    "        y_train = np.append(y_train,y_train[idyr])\n",
    "        y_cat = y_train <= yc\n",
    "        rs = rs+1\n",
    "        print('Resampled to size',y_train.shape)\n",
    "      if aug == True:\n",
    "        y_train_n = y_train+(1.96*sigma)*np.random.normal(0,1,1)\n",
    "        y_train = np.hstack((y_train,y_train_n))\n",
    "        y_cat = y_train <= yc\n",
    "        X0_ss0 = np.vstack((X0_ss0,X0_ss0))\n",
    "    \n",
    "    for jj in np.arange(2,cvn):\n",
    "      skf_g = sms.StratifiedKFold(n_splits=jj,shuffle=True,random_state=0)\n",
    "      skf_gen = skf_g.split(X0_ss0,y_cat)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Feature selection\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        sel = skf.RFECV(lasso,step=rcfs,cv=skf_gen)\n",
    "        X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "        X0_ss = X0_sst\n",
    "        est_ls = lasso.fit(X0_ss,y_train)\n",
    "        cv_scores[jj] = est_ls.score(X0_ss,y_train)\n",
    "        print('LassoCV score for',jj,'is',cv_scores[jj],'from dataset of size',X0_ss.shape)\n",
    "        \n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):        \n",
    "      best_cv = np.argmax(cv_scores)\n",
    "\n",
    "      # # Break any ties\n",
    "      # if np.sum(cv_scores == best_cv) > 1:\n",
    "      #   cv_scores_tb = np.zeros((np.sum(cv_scores == best_cv),1))\n",
    "      #   for jjj in (cv_scores == cv_scores(best_cv)):\n",
    "      #     if jjj > 0:\n",
    "      #       skf_g = sms.StratifiedKFold(n_splits=np.arange(2,cvn)[jjj],shuffle=True,random_state=1)\n",
    "      #       skf_gen = skf_g.split(X0_ss0,y_cat) \n",
    "      #       X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      #       X0_ss = X0_sst\n",
    "      #       lasso = slm.LassoLarsCV(max_iter=1000,cv=np.arange(2,cvn)[jjj],n_jobs=-1,normalize=False,eps=0.1)\n",
    "      #       est_ls = lasso.fit(X0_ss,y_train)\n",
    "      #       cv_scores_tb[jjj] = est_ls.score(X0_ss,y_train)\n",
    "      #   best_cv = np.argmax(cv_scores_tb)\n",
    "      \n",
    "      # Fit whole dataset with optimal cv\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      sel = skf.RFECV(lasso,step=rcfs,cv=best_cv)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_sst = sel.transform(X_test_ss0)\n",
    "      X0_ss = X0_sst\n",
    "      X_test_ss = X_test_sst\n",
    "\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "      results_ls_aug[c] = est_ls.predict(X_test_ss)\n",
    "      # if results_ls_aug[c] < 0:\n",
    "      #     dx, y_n = cKDTree(X0_ss).query(X_test_ss, k=1)\n",
    "      #     results_ls_aug[c] = y_train[y_n]\n",
    "      #     print('Using nearest neighbor')\n",
    "      print('Lasso predicts',str(np.round(results_ls_aug[c],4)),\n",
    "            'for case with',str(np.round(np.repeat(per_change,r)[c],2)),'compared to LCT',pre_imp[c],'and selected CV',best_cv)\n",
    "      try:\n",
    "        K_nz.append(np.squeeze(K_ss)[est_ls.coef_>0])\n",
    "      except:\n",
    "        print('No features appended')\n",
    "      c=c+1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls_aug,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([-5,2])\n",
    "plt.xlim([-5,2])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = []\n",
    "aug = False\n",
    "err_var = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "c = 0\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    y_cat = y_train <= 0.3\n",
    "    idy = np.where(y_cat==1)\n",
    "    # Cross validation\n",
    "                                          \n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,\n",
    "                                                test_index,pre_updrs,tmed,ledd,None,None,None,None,None,None,None,False,False,False)\n",
    "    # 10\n",
    "    cvn = 5\n",
    "    cv_scores = np.zeros((cvn,1))\n",
    "    rs = 1\n",
    "    rcfs = 1000\n",
    "    (mu, sigma) = stats.norm.fit(y_train)\n",
    "    kappa = stats.skew(y_train)\n",
    "    print('Label distribution of:',mu,sigma,kappa)\n",
    "    for jj in np.arange(2,cvn):\n",
    "      # Resample to avoid stratification errors\n",
    "      while np.sum(y_cat) < cvn:\n",
    "        np.random.seed(rs)\n",
    "        idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "        X0_ss0 = np.append(X0_ss0,X0_ss0[idyr,:].reshape(1,-1),axis=0)\n",
    "        y_train = np.append(y_train,y_train[idyr])\n",
    "        y_cat = y_train <= 0.3\n",
    "        rs = rs+1\n",
    "        print('Resampled to size',y_train.shape)\n",
    "      if aug == True:\n",
    "        y_train_n = y_train+(1.96*sigma)*np.random.normal(0,1,1)\n",
    "        y_train = np.hstack((y_train,y_train_n))\n",
    "        y_cat = y_train <= 0.3\n",
    "        X0_ss0 = np.vstack((X0_ss0,X0_ss0))\n",
    "    \n",
    "    for jj in np.arange(2,cvn):\n",
    "      skf_g = sms.StratifiedKFold(n_splits=jj,shuffle=True,random_state=0)\n",
    "      skf_gen = skf_g.split(X0_ss0,y_cat)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Feature selection\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        sel = skf.RFECV(lasso,step=rcfs,cv=skf_gen)\n",
    "        X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "        X0_ss = X0_sst\n",
    "        est_ls = lasso.fit(X0_ss,y_train)\n",
    "        cv_scores[jj] = est_ls.score(X0_ss,y_train)\n",
    "        print('LassoCV score for',jj,'is',cv_scores[jj],'from dataset of size',X0_ss.shape)\n",
    "        \n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):        \n",
    "      best_cv = np.argmax(cv_scores)\n",
    "\n",
    "      # Break any ties\n",
    "      if np.sum(cv_scores == best_cv) > 1:\n",
    "        cv_scores_tb = np.zeros((np.sum(cv_scores == best_cv),1))\n",
    "        for jjj in (cv_scores == cv_scores(best_cv)):\n",
    "          if jjj > 0:\n",
    "            skf_g = sms.StratifiedKFold(n_splits=np.arange(2,cvn)[jjj],shuffle=True,random_state=1)\n",
    "            skf_gen = skf_g.split(X0_ss0,y_cat) \n",
    "            X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "            X0_ss = X0_sst\n",
    "            lasso = slm.LassoLarsCV(max_iter=1000,cv=np.arange(2,cvn)[jjj],n_jobs=-1,normalize=False,eps=0.1)\n",
    "            est_ls = lasso.fit(X0_ss,y_train)\n",
    "            cv_scores_tb[jjj] = est_ls.score(X0_ss,y_train)\n",
    "        best_cv = np.argmax(cv_scores_tb)\n",
    "      \n",
    "      # Fit whole dataset with optimal cv\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      sel = skf.RFECV(lasso,step=rcfs,cv=best_cv)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_sst = sel.transform(X_test_ss0)\n",
    "      X0_ss = X0_sst\n",
    "      X_test_ss = X_test_sst\n",
    "\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "      results_ls[c] = est_ls.predict(X_test_ss)\n",
    "      if results_ls[c] < 0:\n",
    "          dx, y_n = cKDTree(X0_ss).query(X_test_ss, k=1)\n",
    "          results_ls[c] = y_train[y_n]\n",
    "          print('Using nearest neighbor')\n",
    "      print('Lasso predicts',str(np.round(results_ls[c],4)),\n",
    "            'for case with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cv)\n",
    "      try:\n",
    "        K_nz.append(np.squeeze(K_ss)[est_ls.coef_>0])\n",
    "      except:\n",
    "        print('No features appended')\n",
    "      c=c+1\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_imp = (np.asarray(pre_updrs_off,dtype=float)-np.asarray(pre_updrs_off,dtype=float))/np.asarray(pre_updrs_off,dtype=float)\n",
    "results_ls_aug[results_ls>1] = 1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_imp = ((cv_dict[' OFF (pre-dbs updrs)']-cv_dict[' ON (pre-dbs updrs)'])/cv_dict[' OFF (pre-dbs updrs)'])[s_cases_idx]\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "fig,ax = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "#ax[0].scatter(pre_imp,per_change)\n",
    "col = np.where(per_change <= 0.3,'orange','blue')\n",
    "ax[0].scatter(pre_imp,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(pre_imp.T,per_change)\n",
    "y_model = pre_imp*lr.slope+lr.intercept\n",
    "ax[0].plot(pre_imp,y_model,color='r')\n",
    "ax[0].text(0.60,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.3f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[0].transAxes,fontsize=16)  \n",
    "ax[0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0].set_title('LCT',fontsize=16)\n",
    "ax[0].set_ylabel('True improvement',fontsize=16)\n",
    "\n",
    "col = np.where(per_change <= 0.3,'orange','blue')\n",
    "ax[1].scatter(results_ls_aug,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(results_ls_aug),per_change)\n",
    "y_model = results_ls_aug*lr.slope+lr.intercept\n",
    "ax[1].plot(results_ls_aug,y_model,color='r')\n",
    "ax[1].text(0.60,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.7f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[1].transAxes,fontsize=16) \n",
    "ax[1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1].set_title('Noise Compensated Lasso',fontsize=16)\n",
    "plt.ylim([0,1.5])\n",
    "plt.xlim([0,1.5])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = (30,15)\n",
    "# fig, axes = plt.subplots(1,1,sharey=True)\n",
    "# plt.subplots_adjust(left=0.1,\n",
    "#                     bottom=0.1, \n",
    "#                     right=0.9, \n",
    "#                     top=0.9, \n",
    "#                     wspace=0.4, \n",
    "#                     hspace=0.8)\n",
    "\n",
    "# R = [item for sublist in K_nz for item in sublist]\n",
    "# letter_counts = Counter(R)\n",
    "# lc = { x: count for x, count in letter_counts.items() if count > 1 }\n",
    "# df = pd.DataFrame.from_dict(lc, orient='index')\n",
    "# df.sort_values(0, ascending=False, inplace=True)\n",
    "# df.plot(ax=axes, y=0, kind='bar', legend=False, fontsize=16)\n",
    "# plt.title('Predictive radiomic features',fontsize=16)\n",
    "# plt.ylabel('Frequency',fontsize=16)\n",
    "\n",
    "# plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_imp = np.repeat((np.asarray(pre_updrs_iii_off,dtype=float)-np.asarray(pre_updrs_iii_on,dtype=float))/np.asarray(pre_updrs_iii_off,dtype=float),r)\n",
    "# per_change = np.repeat(per_change,r)\n",
    "# plt.rcParams['figure.figsize'] = [20, 5]\n",
    "# fig,ax = plt.subplots(1,3,sharex=True,sharey=True)\n",
    "# #ax[0].scatter(pre_imp,per_change)\n",
    "# col = np.where(per_change <= 0.3,'orange','blue')\n",
    "# ax[0].scatter(pre_imp,per_change, c=col,linewidth=0)\n",
    "# lr = stats.linregress(pre_imp,per_change)\n",
    "# y_model = pre_imp*lr.slope+lr.intercept\n",
    "# ax[0].plot(pre_imp,y_model,color='r')\n",
    "# ax[0].text(0.6,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.3f}'.format(lr.pvalue))),\n",
    "#                     ha='left', va='bottom', transform=ax[0].transAxes,fontsize=16)  \n",
    "# ax[0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[0].set_title('LCT',fontsize=16)\n",
    "# ax[0].set_ylabel('True improvement',fontsize=16)\n",
    "\n",
    "# col = np.where(per_change <= 0.3,'orange','blue')\n",
    "# ax[1].scatter(results_ls,per_change, c=col,linewidth=0)\n",
    "# lr = stats.linregress(np.squeeze(results_ls),per_change)\n",
    "# y_model = results_ls*lr.slope+lr.intercept\n",
    "# ax[1].plot(results_ls,y_model,color='r')\n",
    "# ax[1].text(0.55,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.7f}'.format(lr.pvalue))),\n",
    "#                     ha='left', va='bottom', transform=ax[1].transAxes,fontsize=16) \n",
    "# ax[1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[1].set_title('Lasso',fontsize=16)\n",
    "# ax[1].set_xlabel('Prediction',fontsize=16)\n",
    "# col = np.where(per_change <= 0.3,'orange','blue')\n",
    "# ax[2].scatter(results_ls_aug,per_change, c=col,linewidth=0)\n",
    "# lr = stats.linregress(np.squeeze(results_ls_aug),per_change)\n",
    "# y_model = results_ls_aug*lr.slope+lr.intercept\n",
    "# ax[2].plot(results_ls_aug,y_model,color='r')\n",
    "# ax[2].text(0.55,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.7f}'.format(lr.pvalue))),\n",
    "#                     ha='left', va='bottom', transform=ax[2].transAxes,fontsize=16) \n",
    "# ax[2].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[2].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "# ax[2].set_title('Noise Compensated Lasso',fontsize=16)\n",
    "# plt.ylim([0,1.25])\n",
    "# plt.xlim([0,1.25])\n",
    "# plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('results_ls_aug_msw.npy',results_ls_aug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
