{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn import preprocessing as skp\n",
    "from sklearn import model_selection as sms\n",
    "from sklearn import feature_selection as skf\n",
    "from sklearn import linear_model as slm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from IPython.display import HTML\n",
    "import util as util\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "from torch import nn\n",
    "import gc\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "def remove_keymap_conflicts(new_keys_set):\n",
    "    for prop in plt.rcParams:\n",
    "        if prop.startswith('keymap.'):\n",
    "            keys = plt.rcParams[prop]\n",
    "            remove_list = set(keys) & new_keys_set\n",
    "            for key in remove_list:\n",
    "                keys.remove(key)\n",
    "\n",
    "def multi_slice_viewer(volume):\n",
    "    remove_keymap_conflicts({'j', 'k'})\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0]//2\n",
    "    ax.imshow(volume[ax.index])\n",
    "    fig.canvas.mpl_connect('key_press_event', process_key)\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == 'j':\n",
    "        previous_slice(ax)\n",
    "    elif event.key == 'k':\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "\n",
    "def previous_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index-1) % volume.shape[0] \n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "def next_slice(ax):\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index+1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set window level\n",
    "level = 0\n",
    "window = 500\n",
    "m1=level-window/2\n",
    "m2=level+window/2\n",
    "visualize = 0\n",
    "# Load data\n",
    "nrows = 512\n",
    "ncols = 512\n",
    "nslices = 352\n",
    "segs = []\n",
    "qsms = []\n",
    "laros = []\n",
    "voxel_sizes = []\n",
    "trackers = []\n",
    "q_directory = '/home/ali/RadDBS-QSM/data/nii/new_qsm/'\n",
    "q_directory = os.listdir(q_directory)\n",
    "q_directory = sorted(q_directory)\n",
    "s_directory = '/home/ali/RadDBS-QSM/data/nii/new_seg/'\n",
    "s_directory = os.listdir(s_directory)\n",
    "s_directory = sorted(s_directory)\n",
    "\n",
    "n_cases = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_names = {'CORNELL ID',\n",
    "            ' OFF (pre-dbs updrs)',\n",
    "            ' ON (pre-dbs updrs)',\n",
    "            ' OFF meds ON stim 6mo',\n",
    "            'Age',\n",
    "            'Sex',\n",
    "            'Ethnicity',\n",
    "            'Race',\n",
    "            'Disease Duration (year)',\n",
    "            'Physician',\n",
    "            ' pre op levadopa equivalent dose (mg)',\n",
    "            ' Location',\n",
    "            ' Target',\n",
    "            ' Test medication status'}\n",
    "\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/dbs_03292024.csv'\n",
    "motor_df = util.filter_data(file_dir,cv_names,True)\n",
    "# Find cases with all required scores\n",
    "cv_dict = util.filter_cases(motor_df,cv_names)\n",
    "subs = cv_dict['CORNELL ID']\n",
    "# Load extracted features\n",
    "npy_dir = '/home/ali/RadDBS-QSM/data/npy/new/'\n",
    "phi_dir = '/home/ali/RadDBS-QSM/data/phi/new/phi/'\n",
    "roi_path = '/home/ali/RadDBS-QSM/data/xlxs/new_segs.csv'\n",
    "n_rois = 6\n",
    "all_rois = False\n",
    "Phi_all, X_all, R_all, K_all, ID_all = util.load_featstruct(phi_dir,npy_dir+'X/',npy_dir+'R/',npy_dir+'K/',n_rois,1595,all_rois)\n",
    "print(np.unique(R_all))\n",
    "ids = np.asarray(ID_all).astype(int)\n",
    "\n",
    "# Use cases from only 1 rater\n",
    "phys = cv_dict['Physician']\n",
    "# Find overlap between scored subjects and feature extraction cases\n",
    "c_cases = np.intersect1d(np.asarray(ids).astype(int),np.asarray(cv_dict['CORNELL ID']).astype(int))\n",
    "# Complete case indices with respect to feature matrix\n",
    "c_cases_idx = np.in1d(ids,c_cases)\n",
    "# Exclude GPi\n",
    "c_cases_idx[ids == 36] = 0\n",
    "c_cases_idx[ids == 53] = 0\n",
    "c_cases_idx[ids == 98] = 0\n",
    "c_cases_idx[ids == 108] = 0\n",
    "print(np.sum(c_cases_idx))\n",
    "s_cases_idx = np.in1d(subs,ids[c_cases_idx])\n",
    "print(len(s_cases_idx))\n",
    "        \n",
    "X_all_c = X_all[c_cases_idx,2:6,:]\n",
    "#X_all_c = (np.load('X2h_sr.npy').T).reshape((31,6381))\n",
    "# print('Applying combat')\n",
    "K_all_c = K_all[c_cases_idx,2:6,:]\n",
    "R_all_c = R_all[c_cases_idx,2:6,:]\n",
    "# Re-index the scored subjects with respect to complete cases\n",
    "\n",
    "per_change = ((cv_dict[' OFF (pre-dbs updrs)']-cv_dict[' OFF meds ON stim 6mo'])/cv_dict[' OFF (pre-dbs updrs)'])[s_cases_idx]\n",
    "pre_imp = ((cv_dict[' OFF (pre-dbs updrs)']-cv_dict[' ON (pre-dbs updrs)'])/cv_dict[' OFF (pre-dbs updrs)'])[s_cases_idx]\n",
    "pre_updrs = cv_dict[' OFF (pre-dbs updrs)'][s_cases_idx]\n",
    "dd = cv_dict['Disease Duration (year)'][s_cases_idx]\n",
    "ledd = cv_dict[' pre op levadopa equivalent dose (mg)'][s_cases_idx]\n",
    "tmed = cv_dict[' Test medication status'][s_cases_idx]\n",
    "phys = cv_dict['Physician'][s_cases_idx]\n",
    "age = cv_dict['Age'][s_cases_idx]\n",
    "loc = cv_dict[' Location'][s_cases_idx]\n",
    "sex = cv_dict['Sex'][s_cases_idx]\n",
    "rce = cv_dict['Race'][s_cases_idx]\n",
    "eth = cv_dict['Ethnicity'][s_cases_idx]\n",
    "tgt = cv_dict[' Target'][s_cases_idx]\n",
    "subsc = subs[s_cases_idx]\n",
    "# Reshape keys and ROIs\n",
    "if all_rois == True:\n",
    "    K_all_cu = np.empty((K_all_c.shape[0],K_all_c.shape[1],K_all_c.shape[2]+1),dtype=object)\n",
    "    K_all_cu[:,:,:-1] = K_all_c\n",
    "    K_all_cu[:,:,-1] = 'pre_updrs'\n",
    "    K_all_cu[:,:,-1] = 'disease_duration'\n",
    "    K_all_cu[:,:,-1] = 'pre op levadopa equivalent dose (mg)'\n",
    "    K_all_cu[:,:,-1] = ' Test medication status'\n",
    "    K_all_cu[:,:,-1] = 'Physician'\n",
    "    K_all_cu[:,:,-1] = 'Age'\n",
    "    K_all_cu[:,:,-1] = 'Location'\n",
    "    K_all_cu[:,:,-1] = 'Sex'\n",
    "    K_all_cu[:,:,-1] = 'Race'\n",
    "    K_all_cu[:,:,-1] = 'Ethnicity'\n",
    "    \n",
    "    K = K_all_cu.reshape((K_all_cu.shape[0],K_all_cu.shape[1]*K_all_cu.shape[2]))[0]\n",
    "    R = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "else:\n",
    "    K_all_c = K_all_c.reshape((K_all_c.shape[0],K_all_c.shape[1]*K_all_c.shape[2]))[0]\n",
    "    R_all_c = R_all_c.reshape((R_all_c.shape[0],R_all_c.shape[1]*R_all_c.shape[2]))\n",
    "\n",
    "print(np.unique(R_all_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(per_change,2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motor_df.insert(0, \"Improvement\", np.round((motor_df[' OFF (pre-dbs updrs)'].values.astype(float)-motor_df[' OFF meds ON stim 6mo'].values.astype(float))/motor_df[' OFF (pre-dbs updrs)'].values.astype(float),2), True)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "#     display(motor_df[s_cases_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = len(per_change)\n",
    "results_ls_aug = np.zeros_like(per_change)\n",
    "results_lgr_aug = np.zeros_like(per_change)\n",
    "results_lgrp_aug = np.zeros_like(per_change)\n",
    "results_ls = np.zeros_like(per_change)\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = 1\n",
    "if retrain == 1:\n",
    "\n",
    "  Js = []\n",
    "  aug = False\n",
    "  err_var = np.zeros_like(per_change)\n",
    "  rerror = np.zeros_like(per_change)\n",
    "  kappa = []\n",
    "  K_nz = []\n",
    "  E_nz = []\n",
    "  c = 0\n",
    "\n",
    "  K_all_c = np.append(K_all_c,['pre updrs']*5)\n",
    "  for j in np.arange(len(subsc)):\n",
    "      test_id = subsc[j]\n",
    "      test_index = subsc == test_id\n",
    "      train_index = subsc != test_id\n",
    "      X_train = X_all_c[train_index,:,:]\n",
    "      X_test = X_all_c[test_index,:,:]\n",
    "      y_train = per_change[train_index]\n",
    "      y_test = per_change[test_index]\n",
    "\n",
    "      y_cat = y_train <= 0.3\n",
    "      idy = np.where(y_cat==1)\n",
    "      # Cross validation\n",
    "                                            \n",
    "      X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,\n",
    "                                                test_index,pre_updrs,None,None,dd,ledd,phys,None,None,None,None,False,False,False)\n",
    "      cvn = 10\n",
    "      cv_scores = np.zeros((cvn,1))\n",
    "      cv_lgr_scores = np.zeros((cvn,1))\n",
    "      rs = 1\n",
    "      rcfs = 1000\n",
    "      (mu, sigma) = stats.norm.fit(y_train)\n",
    "      kappa = stats.skew(y_train)\n",
    "      print('Label distribution of:',mu,sigma,kappa)\n",
    "      for jj in np.arange(2,cvn):\n",
    "        # Resample to avoid stratification errors\n",
    "        while np.sum(y_cat) < 2*(cvn-1):\n",
    "          np.random.seed(rs)\n",
    "          idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "          X0_ss0 = np.append(X0_ss0,X0_ss0[idyr,:].reshape(1,-1),axis=0)\n",
    "          y_train = np.append(y_train,y_train[idyr])\n",
    "          y_cat = y_train <= 0.3\n",
    "          rs = rs+1\n",
    "          print('Resampled to size',y_train.shape)\n",
    "        if aug == True:\n",
    "          # y_train_n = y_train+(1.96*sigma)*np.random.normal(0,1,1)\n",
    "          z_train = (y_train-np.mean(y_train))/(np.std(y_train)/np.sqrt(len(y_train)))\n",
    "          z_train_ns = z_train+1.96*np.std(z_train)*np.random.normal(0,1,1)\n",
    "          y_train_n = z_train_ns*((np.std(y_train)/np.sqrt(len(y_train))))+np.mean(y_train)\n",
    "          y_train = np.hstack((y_train,y_train_n))\n",
    "          y_cat = y_train <= 0.3\n",
    "          X0_ss0 = np.vstack((X0_ss0,X0_ss0))\n",
    "      \n",
    "      for jj in np.arange(2,cvn):\n",
    "        skf_g = sms.StratifiedKFold(n_splits=jj,shuffle=True,random_state=0)\n",
    "        skf_gen = skf_g.split(X0_ss0,y_cat)\n",
    "        lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "        lgr = slm.LogisticRegressionCV(n_jobs=-1,cv=jj,class_weight=None)\n",
    "        with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "          # Feature selection\n",
    "          warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "          sel = skf.SelectKBest(skf.f_regression,k=1500)#skf.RFECV(lasso,step=rcfs,cv=skf_gen,n_jobs=1)\n",
    "          # Stratifies classifiers automatically\n",
    "          #sel_lr = skf.SelectKBest(r_regression,k=1500)#skf.RFECV(lgr,step=rcfs,cv=jj,n_jobs=1)\n",
    "          X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "          # X0_ssl = sel_lr.fit_transform(X0_ss0,y_cat)\n",
    "          est_ls = lasso.fit(X0_ss,y_train)\n",
    "          # est_lgr = lgr.fit(X0_ssl,y_cat)\n",
    "          cv_scores[jj] = est_ls.score(X0_ss,y_train)\n",
    "          # cv_lgr_scores[jj] = est_lgr.score(X0_ssl,y_cat)\n",
    "          print('LassoCV score for',jj,'is',cv_scores[jj],'from dataset of size',X0_ss.shape)\n",
    "          \n",
    "      with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):        \n",
    "        best_cv = np.argmax(cv_scores)\n",
    "        best_cv_lgr = np.argmax(cv_lgr_scores)\n",
    "\n",
    "        # Break any ties\n",
    "        if np.sum(cv_scores == best_cv) > 1:\n",
    "          cv_scores_tb = np.zeros((np.sum(cv_scores == best_cv),1))\n",
    "          cv_lgr_scores_tb = np.zeros((np.sum(cv_scores == best_cv_lgr),1))\n",
    "          for jjj in (cv_scores == cv_scores[best_cv]):\n",
    "            if jjj > 0:\n",
    "              print('Breaking tie')\n",
    "              skf_g = sms.StratifiedKFold(n_splits=np.arange(2,cvn)[jjj],shuffle=True,random_state=1)\n",
    "              skf_gen = skf_g.split(X0_ss0,y_cat) \n",
    "              X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "              X0_ssl = sel_lr.fit_transform(X0_ss0,y_cat)\n",
    "              est_ls = lasso.fit(X0_ss,y_train)\n",
    "              # est_lgr = lgr.fit(X0_ssl,y_cat)\n",
    "              lasso = slm.LassoLarsCV(max_iter=1000,cv=np.arange(2,cvn)[jjj],n_jobs=-1,normalize=False,eps=0.1)\n",
    "              # lgr = slm.LogisticRegressionCV(n_jobs=-1,cv=jj,class_weight=None)\n",
    "              est_ls = lasso.fit(X0_ss,y_train)\n",
    "              # est_lgr = lgr.fit(X0_ssl,y_cat)\n",
    "              cv_scores_tb[jjj] = est_ls.score(X0_ss,y_train)\n",
    "              # cv_lgr_scores_tb[jj] = est_lgr.score(sel_lr.fit_transform(X0_ss0,y_cat),y_cat)\n",
    "          best_cv = np.argmax(cv_scores_tb)\n",
    "          best_cv_lgr = np.argmax(cv_lgr_scores_tb)\n",
    "        \n",
    "        # Fit whole dataset with optimal cv\n",
    "        lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "        lgr = slm.LogisticRegressionCV(n_jobs=-1,cv=jj,class_weight=None)\n",
    "        sel = skf.RFECV(lasso,step=rcfs,cv=best_cv)\n",
    "        sel_lr = skf.RFECV(lgr,step=rcfs,cv=best_cv)\n",
    "        X0_ss = sel.fit_transform(X0_ss0,y_train)\n",
    "        X_test_ss = sel.transform(X_test_ss0)\n",
    "        # X0_ssl = sel_lr.fit_transform(X0_ss0,y_cat)\n",
    "        # X_test_ssl = sel_lr.transform(X_test_ss0)\n",
    "        #K_ss = sel.transform(K_all_c.reshape(1,-1))\n",
    "\n",
    "      # LASSO\n",
    "      with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "        lgr = slm.LogisticRegressionCV(n_jobs=-1,cv=best_cv,class_weight=None)\n",
    "        est_ls = lasso.fit(X0_ss,y_train)\n",
    "        # est_lgr = lgr.fit(X0_ssl,y_cat)\n",
    "      # results_lgr_aug[c] = est_lgr.predict(X_test_ssl)\n",
    "      # results_lgrp_aug[c] = est_lgr.predict_proba(X_test_ssl)[0][0]\n",
    "      results_ls_aug[c] = est_ls.predict(X_test_ss)\n",
    "      print('Lasso predicts',str(np.round(results_ls_aug[c],4)),'and logistic regression predicts',results_lgr_aug[c],\n",
    "                'for case with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cv,'and',sum(y_cat),'minority cases')\n",
    "      # K_nz.append(np.squeeze(K_ss)[est_ls.coef_>0])\n",
    "      E_nz.append(est_ls.coef_[est_ls.coef_>0])\n",
    "      c=c+1\n",
    "\n",
    "  # np.save('results_ls_aug_d.npy',results_ls_aug)\n",
    "  # np.save('results_lgr_aug_d.npy',results_lgr_aug)\n",
    "  # np.save('results_lgrp_aug_d.npy',results_lgrp_aug)\n",
    "\n",
    "else:\n",
    "  print('Loading')\n",
    "  # results_ls_aug = np.load('results_ls_aug_d.npy')\n",
    "  # results_lgr_aug = np.load('results_lgr_aug_d.npy')\n",
    "  #results_lgrp_aug = np.load('results_lgr_aug_d.npy')\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X0_ss0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(X0_ss[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls_aug[results_ls_aug>1]=1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls_aug,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Js = []\n",
    "# aug = True\n",
    "# err_var = np.zeros_like(per_change)\n",
    "# rerror = np.zeros_like(per_change)\n",
    "# kappa = []\n",
    "# c = 0\n",
    "# for j in np.arange(len(subsc)):\n",
    "#     test_id = subsc[j]\n",
    "#     test_index = subsc == test_id\n",
    "#     train_index = subsc != test_id\n",
    "#     X_train = X_all_c[train_index,:]\n",
    "#     X_test = X_all_c[test_index,:]\n",
    "#     y_train = per_change[train_index]\n",
    "#     y_test = per_change[test_index]\n",
    "\n",
    "#     y_cat = y_train <= 0.3\n",
    "#     N = np.sum(y_cat)\n",
    "#     idy = np.where(y_cat==1)\n",
    "#     # Cross validation\n",
    "                                          \n",
    "#     X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "#                                                 X_train,train_index,X_test,\n",
    "#                                                 test_index,pre_updrs,loc,tmed,dd,ledd,phys,eth,rce,sex,tgt,False,False,False)\n",
    "#     # X0_ss0 = X_train\n",
    "#     # X_test_ss0 = X_test\n",
    "\n",
    "#     cvn = 10\n",
    "#     cv_scores = np.zeros((cvn,1))\n",
    "#     rs = 1\n",
    "#     rcfs = 1000\n",
    "#     (mu, sigma) = stats.norm.fit(y_train)\n",
    "#     kappa = stats.skew(y_train)\n",
    "#     print('Label distribution of:',mu,sigma,kappa)\n",
    "#     np.random.seed(rs)\n",
    "#     for jj in np.arange(2,cvn):\n",
    "#       # Resample to avoid stratification errors\n",
    "#       while np.sum(y_cat) < 2*N-1: #2*np.sum(y_cat)-1\n",
    "#         np.random.seed(rs)\n",
    "#         idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "#         X0_ss0 = np.append(X0_ss0,X0_ss0[idyr,:].reshape(1,-1),axis=0)\n",
    "#         y_train = np.append(y_train,y_train[idyr])\n",
    "#         y_cat = y_train <= 0.3\n",
    "#         rs = rs+1\n",
    "#         print('Resampled to size',y_train.shape)\n",
    "#       if aug == True:\n",
    "#         y_train_n = y_train+(sigma/mu)*np.random.normal(0,4*sigma,1)\n",
    "#         y_train = np.hstack((y_train,y_train_n))\n",
    "#         y_cat = y_train <= 0.3\n",
    "#         X0_ss0 = np.vstack((X0_ss0,X0_ss0))\n",
    "\n",
    "    \n",
    "#     for jj in np.arange(2,cvn):\n",
    "#       skf_g = sms.StratifiedKFold(n_splits=jj,shuffle=True,random_state=0)\n",
    "#       skf_gen = skf_g.split(X0_ss0,y_cat)\n",
    "#       lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "#       with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "#         # Feature selection\n",
    "#         warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "#         sel = skf.RFECV(lasso,step=rcfs,cv=skf_gen)\n",
    "#         X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "#         X0_ss = X0_sst\n",
    "#         est_ls = lasso.fit(X0_ss,y_train)\n",
    "#         cv_scores[jj] = est_ls.score(X0_ss,y_train)\n",
    "#         print('LassoCV score for',jj,'is',cv_scores[jj],'from dataset of size',X0_ss.shape)\n",
    "        \n",
    "#     with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):        \n",
    "#       best_cv = np.argmax(cv_scores)\n",
    "\n",
    "#       # Break any ties\n",
    "#       if np.sum(cv_scores == best_cv) > 1:\n",
    "#         cv_scores_tb = np.zeros((np.sum(cv_scores == best_cv),1))\n",
    "#         for jjj in (cv_scores == cv_scores(best_cv)):\n",
    "#           if jjj > 0:\n",
    "#             skf_g = sms.StratifiedKFold(n_splits=np.arange(2,cvn)[jjj],shuffle=True,random_state=1)\n",
    "#             skf_gen = skf_g.split(X0_ss0,y_cat) \n",
    "#             X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "#             X0_ss = X0_sst\n",
    "#             lasso = slm.LassoLarsCV(max_iter=1000,cv=np.arange(2,cvn)[jjj],n_jobs=-1,normalize=False,eps=0.1)\n",
    "#             est_ls = lasso.fit(X0_ss,y_train)\n",
    "#             cv_scores_tb[jjj] = est_ls.score(X0_ss,y_train)\n",
    "#         best_cv = np.argmax(cv_scores_tb)\n",
    "      \n",
    "#       # Fit whole dataset with optimal cv\n",
    "#       lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "#       sel = skf.RFECV(lasso,step=rcfs,cv=best_cv)\n",
    "#       X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "#       X_test_sst = sel.transform(X_test_ss0)\n",
    "#       X0_ss = X0_sst\n",
    "#       X_test_ss = X_test_sst\n",
    "\n",
    "#     # LASSO\n",
    "#     with warnings.catch_warnings():\n",
    "#       warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "#       lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "#       est_ls = lasso.fit(X0_ss,y_train)\n",
    "#     results_ls_aug[c] = est_ls.predict(X_test_ss)\n",
    "#     print('Lasso predicts',str(np.round(results_ls_aug[c],4)),\n",
    "#               'for case',subsc[j], 'with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cv)\n",
    "  \n",
    "#     c=c+1\n",
    "\n",
    "      \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls_aug[results_ls_aug>1]=1\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls_aug,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = []\n",
    "aug = False\n",
    "err_var = np.zeros_like(per_change)\n",
    "rerror = np.zeros_like(per_change)\n",
    "kappa = []\n",
    "c = 0\n",
    "for j in np.arange(len(subsc)):\n",
    "    test_id = subsc[j]\n",
    "    test_index = subsc == test_id\n",
    "    train_index = subsc != test_id\n",
    "    X_train = X_all_c[train_index,:,:]\n",
    "    X_test = X_all_c[test_index,:,:]\n",
    "    y_train = per_change[train_index]\n",
    "    y_test = per_change[test_index]\n",
    "\n",
    "    y_cat = y_train <= 0.3\n",
    "    idy = np.where(y_cat==1)\n",
    "    # Cross validation\n",
    "                                          \n",
    "    X0_ss0,scaler_ss,X_test_ss0 = util.model_scale(skp.StandardScaler(),\n",
    "                                                X_train,train_index,X_test,\n",
    "                                                test_index,pre_updrs,None,None,None,None,None,None,None,None,None,False,False,False)\n",
    "    # X0_ss0 = X_train\n",
    "    # X_test_ss0 = X_test\n",
    "\n",
    "    cvn = 5\n",
    "    cv_scores = np.zeros((cvn,1))\n",
    "    rs = 1\n",
    "    rcfs = 1000\n",
    "    (mu, sigma) = stats.norm.fit(y_train)\n",
    "    kappa = stats.skew(y_train)\n",
    "    print('Label distribution of:',mu,sigma,kappa)\n",
    "    np.random.seed(rs)\n",
    "    # for jj in np.arange(2,cvn):\n",
    "      # # Resample to avoid stratification errors\n",
    "      # while np.sum(y_cat) < cvn: #2*np.sum(y_cat)-1\n",
    "      #   np.random.seed(rs)\n",
    "      #   idyr = np.random.choice(np.asarray(idy).ravel())\n",
    "      #   X0_ss0 = np.append(X0_ss0,X0_ss0[idyr,:].reshape(1,-1),axis=0)\n",
    "      #   y_train = np.append(y_train,y_train[idyr])\n",
    "      #   y_cat = y_train <= 0.3\n",
    "      #   rs = rs+1\n",
    "      #   print('Resampled to size',y_train.shape)\n",
    "      # if aug == True:\n",
    "      #   y_train_n = y_train+(sigma/mu)*np.random.normal(0,4*sigma,1)\n",
    "      #   y_train = np.hstack((y_train,y_train_n))\n",
    "      #   y_cat = y_train <= 0.3\n",
    "      #   X0_ss0 = np.vstack((X0_ss0,X0_ss0))\n",
    "\n",
    "    \n",
    "    for jj in np.arange(2,cvn):\n",
    "      skf_g = sms.StratifiedKFold(n_splits=jj,shuffle=True,random_state=0)\n",
    "      skf_gen = skf_g.split(X0_ss0,y_cat)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=jj,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      # with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):\n",
    "      #   # Feature selection\n",
    "      #   warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      sel = skf.RFECV(lasso,step=rcfs,cv=skf_gen,min_features_to_select=100)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      print(sel.score(X0_ss0,y_train))\n",
    "      X0_ss = X0_sst\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "      cv_scores[jj] = est_ls.score(X0_ss,y_train)\n",
    "      print('LassoCV score for',jj,'is',cv_scores[jj],'from dataset of size',X0_ss.shape)\n",
    "        \n",
    "    with warnings.catch_warnings() and np.errstate(divide='ignore', invalid='ignore'):        \n",
    "      best_cv = np.argmax(cv_scores)\n",
    "\n",
    "      # # Break any ties\n",
    "      # if np.sum(cv_scores == best_cv) > 1:\n",
    "      #   cv_scores_tb = np.zeros((np.sum(cv_scores == best_cv),1))\n",
    "      #   for jjj in (cv_scores == cv_scores[best_cv]):\n",
    "      #     if jjj > 0:\n",
    "      #       skf_g = sms.StratifiedKFold(n_splits=np.arange(2,cvn)[jjj],shuffle=True,random_state=1)\n",
    "      #       skf_gen = skf_g.split(X0_ss0,y_cat) \n",
    "      #       X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      #       X0_ss = X0_sst\n",
    "      #       lasso = slm.LassoLarsCV(max_iter=1000,cv=np.arange(2,cvn)[jjj],n_jobs=-1,normalize=False,eps=0.1)\n",
    "      #       est_ls = lasso.fit(X0_ss,y_train)\n",
    "      #       cv_scores_tb[jjj] = est_ls.score(X0_ss,y_train)\n",
    "      #   best_cv = np.argmax(cv_scores_tb)\n",
    "      \n",
    "      # Fit whole dataset with optimal cv\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      sel = skf.RFECV(lasso,step=rcfs,cv=best_cv)\n",
    "      X0_sst = sel.fit_transform(X0_ss0,y_train)\n",
    "      X_test_sst = sel.transform(X_test_ss0)\n",
    "      X0_ss = X0_sst\n",
    "      X_test_ss = X_test_sst\n",
    "\n",
    "    # LASSO\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "      lasso = slm.LassoLarsCV(max_iter=1000,cv=best_cv,n_jobs=-1,normalize=False,eps=0.1)\n",
    "      est_ls = lasso.fit(X0_ss,y_train)\n",
    "    results_ls_aug[c] = est_ls.predict(X_test_ss)\n",
    "    print('Lasso predicts',str(np.round(results_ls_aug[c],4)),\n",
    "              'for case',subsc[j], 'with',str(np.round(np.repeat(per_change,r)[c],2)),'and selected CV',best_cv)\n",
    "  \n",
    "    c=c+1\n",
    "\n",
    "      \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "util.eval_prediction(np.vstack((pre_imp,\n",
    "                               results_ls,\n",
    "                               )),\n",
    "                               per_change,\n",
    "                               ['LCT',\n",
    "                                'Lasso',\n",
    "                                ],(15,5))\n",
    "plt.ylim([0,2])\n",
    "plt.xlim([0,2])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_imp = np.repeat((np.asarray(pre_updrs_iii_off,dtype=float)-np.asarray(pre_updrs_iii_on,dtype=float))/np.asarray(pre_updrs_iii_off,dtype=float),r)\n",
    "per_change = np.repeat(per_change,r)\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "fig,ax = plt.subplots(1,3,sharex=True,sharey=True)\n",
    "#ax[0].scatter(pre_imp,per_change)\n",
    "col = np.where(per_change <= 0.3,'orange','blue')\n",
    "ax[0].scatter(pre_imp,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(pre_imp,per_change)\n",
    "y_model = pre_imp*lr.slope+lr.intercept\n",
    "ax[0].plot(pre_imp,y_model,color='r')\n",
    "ax[0].text(0.6,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.3f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[0].transAxes,fontsize=16)  \n",
    "ax[0].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[0].set_title('LCT',fontsize=16)\n",
    "ax[0].set_ylabel('True improvement',fontsize=16)\n",
    "\n",
    "col = np.where(per_change <= 0.3,'orange','blue')\n",
    "ax[1].scatter(results_ls,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(results_ls),per_change)\n",
    "y_model = results_ls*lr.slope+lr.intercept\n",
    "ax[1].plot(results_ls,y_model,color='r')\n",
    "ax[1].text(0.55,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.7f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[1].transAxes,fontsize=16) \n",
    "ax[1].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[1].set_title('Lasso',fontsize=16)\n",
    "ax[1].set_xlabel('Prediction',fontsize=16)\n",
    "col = np.where(per_change <= 0.3,'orange','blue')\n",
    "ax[2].scatter(results_ls_aug,per_change, c=col,linewidth=0)\n",
    "lr = stats.linregress(np.squeeze(results_ls_aug),per_change)\n",
    "y_model = results_ls_aug*lr.slope+lr.intercept\n",
    "ax[2].plot(results_ls_aug,y_model,color='r')\n",
    "ax[2].text(0.55,0.75,'$y$ = '+str(np.round(lr.slope,2))+'$x$ + '+str(np.round(lr.intercept,2))+'\\n'+'$r$ = '+str(np.round(lr.rvalue,2))+'\\n'+'$p$ = '+str(('{:.7f}'.format(lr.pvalue))),\n",
    "                    ha='left', va='bottom', transform=ax[2].transAxes,fontsize=16) \n",
    "ax[2].hlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[2].vlines(0.3,0,2,linestyle='dashed',color='black')\n",
    "ax[2].set_title('Noise Compensated Lasso',fontsize=16)\n",
    "plt.ylim([0,1.25])\n",
    "plt.xlim([0,1.25])\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('results_ls_aug_msw.npy',results_ls_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# best fit of data\n",
    "(mu, sigma) = stats.norm.fit(per_change)\n",
    "\n",
    "# the histogram of the data\n",
    "# zn, zbins, zpatches = plt.hist(per_change, bins=16, density=True)\n",
    "\n",
    "n, bins, patches = plt.hist(per_change, bins='auto', density=True)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = norm.pdf(zbins, mu, sigma)\n",
    "l = plt.plot(zbins, y, 'r', linewidth=2)\n",
    "\n",
    "#plot\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('f(y)')\n",
    "plt.title(r'$\\mathrm{Label \\ distribution}\\ \\mu=%.3f,\\ \\sigma=%.3f$' %(mu, sigma))\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
