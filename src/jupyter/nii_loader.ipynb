{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import util\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchio as tio\n",
    "import os\n",
    "import sklearn.model_selection as skm\n",
    "from imbalanced_regression.qsm.datasets import QSM\n",
    "from imbalanced_regression.utils import get_lds_kernel_window\n",
    "import logging\n",
    "from scipy.ndimage import convolve1d\n",
    "from torch.utils import data\n",
    "import torchio.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case IDs\n",
    "case_list = open('/home/ali/RadDBS-QSM/data/docs/cases_90','r')\n",
    "lines = case_list.read()\n",
    "lists = np.loadtxt(case_list.name,comments=\"#\", delimiter=\",\",unpack=False,dtype=str)\n",
    "case_id = []\n",
    "for lines in lists:     \n",
    "    case_id.append(lines[-9:-7])\n",
    "\n",
    "# Load scores\n",
    "file_dir = '/home/ali/RadDBS-QSM/data/docs/QSM anonymus- 6.22.2023-1528.csv'\n",
    "motor_df = util.filter_scores(file_dir,'pre-dbs updrs','stim','CORNELL ID')\n",
    "# Find cases with all required scores\n",
    "subs,pre_imp,post_imp,pre_updrs_off = util.get_full_cases(motor_df,\n",
    "                                                          'CORNELL ID',\n",
    "                                                          'OFF (pre-dbs updrs)',\n",
    "                                                          'ON (pre-dbs updrs)',\n",
    "                                                          'OFF meds ON stim 6mo')\n",
    "# Find overlap between scored subjects and nii\n",
    "ids = np.asarray(case_id).astype(int)\n",
    "ids = ids[ids != 62]\n",
    "cases_idx = np.in1d(subs,ids)\n",
    "ccases = subs[cases_idx]\n",
    "per_change = post_imp[cases_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_paths = []\n",
    "seg_nii_paths = []\n",
    "qsm_dir = '/home/ali/RadDBS-QSM/data/nii/qsm/'\n",
    "seg_dir = '/home/ali/RadDBS-QSM/data/nii/seg/'\n",
    "qsm_niis = sorted(os.listdir(qsm_dir))\n",
    "seg_niis = sorted(os.listdir(seg_dir))\n",
    "for k in np.arange(len(ccases)):\n",
    "    for file in qsm_niis:\n",
    "        if int(ccases[k]) == int(file[18:20]):\n",
    "            nii_paths.append(qsm_dir+file)\n",
    "            seg_nii_paths.append(seg_dir+'labels_2iMag'+file[18:20]+'.nii.gz')\n",
    "\n",
    "train_dir, test_dir, train_seg, test_seg, y_train, y_test = skm.train_test_split(nii_paths, seg_nii_paths, per_change, test_size=0.2, random_state=1)\n",
    "train_dir, val_dir, train_seg, val_seg, y_train, y_val = skm.train_test_split(train_dir, train_seg, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, test_dir, y_train, y_test = skm.train_test_split(nii_paths, per_change, test_size=0.33, random_state=1)\n",
    "train_dir, val_dir, y_train, y_val = skm.train_test_split(train_dir, y_train, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchio as tio\n",
    "from imbalanced_regression.utils import get_lds_kernel_window\n",
    "import logging\n",
    "from scipy.ndimage import convolve1d\n",
    "from torch.utils import data\n",
    "import torchio.transforms as transforms\n",
    "\n",
    "class QSM(data.Dataset):\n",
    "    def __init__(self, data_dir, mask_dir, targets, nz, nx, split='train', reweight='none',\n",
    "                 lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
    "        self.images_list = [nib.load(image_path) for image_path in data_dir]\n",
    "        self.masks_list = [nib.load(mask_path) for mask_path in mask_dir]\n",
    "        self.data_dir = data_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.targets = targets\n",
    "        self.nz = nz\n",
    "        self.nx = nx\n",
    "        self.split = split\n",
    "        self.weights = self._prepare_weights(reweight=reweight, lds=lds, lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        case_dir = self.data_dir[index]\n",
    "        nx = self.nx\n",
    "        nz = self.nz\n",
    "        #print('nz is ',nz, ' and nx is ',nx)\n",
    "        nii_image = self.images_list[index]\n",
    "        nii_mask = self.masks_list[index]\n",
    "        data = np.asarray(nii_image.dataobj)\n",
    "        mask = np.asarray(nii_mask.dataobj)\n",
    "        print('Applying mask of shape ',str(mask.shape),' to image of size ',str(data.shape),' for ',case_dir)#,' with size ',str(self.img_size)+' before transform')\n",
    "        img = torch.from_numpy(data[:,:,~(mask==0).all((0,1))])\n",
    "        self.img_size = img.shape\n",
    "        target = self.targets[index]\n",
    "        transform = self.get_transform(img,nx,nz)\n",
    "        img = torch.squeeze(transform(torch.unsqueeze(img,axis=0)))\n",
    "        #print(case_dir+' has size ',str(img.shape)+' after transform')\n",
    "        label = target\n",
    "        weight = np.asarray([self.weights[index]]).astype('float32') if self.weights is not None else np.asarray([np.float32(1.)])\n",
    "\n",
    "        return img, label, weight\n",
    "\n",
    "    def get_transform(self,img,nx,nz):\n",
    "        self.img = img\n",
    "        self.img_size = (self.img).shape\n",
    "        if self.img_size[2]>nz:\n",
    "            self.img = self.img[:,:,(self.img_size[2]//2)-(nz//2):(self.img_size[2]//2)+(nz//2)]\n",
    "            tpad = transforms.Pad((0,0,0))\n",
    "        else:\n",
    "            if (nz-self.img_size[2])/2 == (nz-self.img_size[2])//2:\n",
    "                tpad = transforms.Pad((0,0,(nz-self.img_size[2])//2))\n",
    "            else:\n",
    "                #print('Padding an odd number of slices with ',str((nz-self.img_size[2])//2),' and ',str(((nz-self.img_size[2])//2)+1))                      \n",
    "                tpad = transforms.Pad((0,0,0,0,\n",
    "                                    (nz-self.img_size[2])//2,\n",
    "                                    ((nz-self.img_size[2])//2)+1))\n",
    "        if self.split == 'train':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Crop((nx,nx,nx,nx,0,0)),\n",
    "                tpad,\n",
    "                transforms.RandomFlip(axes=['LR', 'AP', 'IS']),\n",
    "                transforms.RescaleIntensity(out_min_max=(0, 1)),\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Crop((nx,nx,nx,nx,0,0)),\n",
    "                tpad,\n",
    "                transforms.RescaleIntensity(out_min_max=(0, 1)),\n",
    "            ])\n",
    "        return transform\n",
    "\n",
    "    def _prepare_weights(self, reweight, max_target=1, lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
    "        assert reweight in {'none', 'inverse', 'sqrt_inv'}\n",
    "        assert reweight != 'none' if lds else True, \\\n",
    "            \"Set reweight to \\'sqrt_inv\\' (default) or \\'inverse\\' when using LDS\"\n",
    "\n",
    "        value_dict = {x: 0 for x in range(max_target)}\n",
    "        labels = self.targets\n",
    "        for label in labels:\n",
    "            value_dict[min(max_target - 1, int(label))] += 1\n",
    "        if reweight == 'sqrt_inv':\n",
    "            value_dict = {k: np.sqrt(v) for k, v in value_dict.items()}\n",
    "        elif reweight == 'inverse':\n",
    "            value_dict = {k: np.clip(v, 5, 1000) for k, v in value_dict.items()}  # clip weights for inverse re-weight\n",
    "        num_per_label = [value_dict[min(max_target - 1, int(label))] for label in labels]\n",
    "        if not len(num_per_label) or reweight == 'none':\n",
    "            return None\n",
    "        print(f\"Using re-weighting: [{reweight.upper()}]\")\n",
    "\n",
    "        if lds:\n",
    "            lds_kernel_window = get_lds_kernel_window(lds_kernel, lds_ks, lds_sigma)\n",
    "            print(f'Using LDS: [{lds_kernel.upper()}] ({lds_ks}/{lds_sigma})')\n",
    "            smoothed_value = convolve1d(\n",
    "                np.asarray([v for _, v in value_dict.items()]), weights=lds_kernel_window, mode='constant')\n",
    "            num_per_label = [smoothed_value[min(max_target - 1, int(label))] for label in labels]\n",
    "\n",
    "        weights = [np.float32(1 / x) for x in num_per_label]\n",
    "        scaling = len(weights) / np.sum(weights)\n",
    "        weights = [scaling * x for x in weights]\n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QSM(data_dir=train_dir, mask_dir=train_seg, targets=y_train, nz=128, nx=128, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=5, shuffle=True,\n",
    "                              num_workers=1, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying mask of shape  (512, 512, 352)  to image of size  (512, 512, 352)  for  /home/ali/RadDBS-QSM/data/nii/qsm/QSM_e10_imaginary_44.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for idx, (inputs, targets, weights) in enumerate(train_loader):\n",
    "    print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
