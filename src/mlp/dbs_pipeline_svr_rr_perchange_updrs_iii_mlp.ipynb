{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary data notebook for\n",
    "# NIH: Imaging Guided Intervention Surgery Study Section\n",
    "\n",
    "# Exploratory aim: evaluate presurgical scans between STN and GPi targets\n",
    "#   Given retrospective GPi acquisitions?\n",
    "#   Search for radiomic differentiators for STN versus GPi selection in presurgical scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import nibabel as nib\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "from radiomics import featureextractor \n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 01\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 02\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 03\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 04\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 05\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 06\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 07\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 08\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 09\n",
      "F:\\dbs\\stn-dbs\\Cornell_anonymized\\Anonymized - 10\n"
     ]
    }
   ],
   "source": [
    "# Set window level\n",
    "level = 0\n",
    "window = 500\n",
    "m1=level-window/2\n",
    "m2=level+window/2\n",
    "rextract = 0\n",
    "# Load data\n",
    "# fig, ax = plt.subplots(2,5)\n",
    "segs = []\n",
    "qsms = []\n",
    "voxel_sizes = []\n",
    "trackers = []\n",
    "directory = 'F:\\dbs\\stn-dbs\\Cornell_anonymized'\n",
    "case_list = []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory,filename)\n",
    "    print(f)\n",
    " \n",
    "    seg = nib.load(f+'/Rh Mri Brain With Without Contrast/seg.nii.gz')\n",
    "                \n",
    "    voxel_size = seg.header['pixdim'][0:3]\n",
    "    voxel_sizes.append(voxel_size)\n",
    "    segs.append(seg.get_fdata())\n",
    "\n",
    "    qsm = nib.load(f+'/Rh Mri Brain With Without Contrast/qsm.nii.gz')\n",
    "    qsms.append(qsm.get_fdata())\n",
    "        \n",
    "    case_list.append(filename)\n",
    "    n_cases = len(segs)\n",
    "\n",
    "    label_min = np.partition(np.unique(seg.get_fdata().ravel()), 1)[1]\n",
    "    label_max = np.amax(seg.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.enableAllFeatures()\n",
    "extractor.enableAllImageTypes()\n",
    "\n",
    "# Generate feature structure Phi from all ROIs and all cases\n",
    "if rextract == 1:\n",
    "    Phi = []\n",
    "\n",
    "    # Training cases\n",
    "    for i in range(n_cases):\n",
    "        seg_sitk = sitk.GetImageFromArray(segs[i])\n",
    "        seg_sitk.SetSpacing(voxel_sizes[i].tolist())\n",
    "        qsm_sitk = sitk.GetImageFromArray(qsms[i])\n",
    "        qsm_sitk.SetSpacing(voxel_sizes[i].tolist())\n",
    "        for j in range(int(label_min),int(label_max+1)):\n",
    "            featureVector = extractor.execute(qsm_sitk,seg_sitk,label=j)\n",
    "            Phi.append(featureVector)\n",
    "    # Save feature vector\n",
    "    with open('../features/Phi_57', 'wb') as fp:  \n",
    "        pickle.dump(Phi, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../features/Phi_57', \"rb\") as fp:  \n",
    "    Phi = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "   background-color: transparent !important;\n",
    "}\n",
    ".jp-OutputArea-output {\n",
    "   background-color: transparent;\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDRS features\n",
    "subject_id = np.array((1,2,3,6,9,10,11,12,13,15,16,20,25,26,27,28,29,34,35,41,43,44,45,46,52,54))\n",
    "pre_updrs_iii_off = np.array((65,22,45,63,63,27,57,42,54,67,33,27,50,77,43,31,56,81,40,28,52,32,33,18,58,63))\n",
    "pre_updrs_iii_on = np.array((54,7,13,32,21,14,11,14,28,65,9,4,26,55,14,8,24,20,17,0,29,13,26,0,27,36))\n",
    "post_updrs_iii_off = np.array((11,2,20,3,7,11,15,21,16,21,4,9,15,9,11,4,8,25,13,16,7,26,2,8,19,8))\n",
    "per_change = (pre_updrs_iii_off-post_updrs_iii_off)/pre_updrs_iii_off\n",
    "lct_change = (pre_updrs_iii_off-pre_updrs_iii_on)/(pre_updrs_iii_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id = np.repeat(subject_id,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cases = subject_id.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut = np.zeros((subject_id.__len__()))\n",
    "for j in np.arange(1,np.max(subject_id)):\n",
    "    if j in subject_id:\n",
    "        # Extract numeric feature values\n",
    "        n_ROIs = 2\n",
    "        x_row = []\n",
    "        x_row_t = []\n",
    "        keys = []\n",
    "        per_change_train = []\n",
    "        for i in range(Phi.__len__()//2+1):\n",
    "            if i in subject_id:\n",
    "                for ii in range(0,n_ROIs-1):\n",
    "                    featureVector = Phi[i+ii]\n",
    "                    for key, value in six.iteritems(featureVector):\n",
    "                        if 'diagnostic' in key:\n",
    "                            next\n",
    "                        else:\n",
    "                            try:\n",
    "                                x_row.append(value.ravel())\n",
    "                            except:\n",
    "                                x_row.append(value)\n",
    "                            keys.append(key)\n",
    "                    if ii == 0 and pre_updrs_iii_off[subject_id == i].__len__()>0:\n",
    "                        x_row.append((pre_updrs_iii_off[subject_id == i]))\n",
    "                        x_row.append(post_updrs_iii_off[subject_id == i])\n",
    "                        x_row.append(pre_updrs_iii_on[subject_id == i])\n",
    "                        keys.append('pre_updrs_iii_off')\n",
    "                        keys.append('post_updrs_iii_off')\n",
    "                        keys.append('pre_updrs_iii_on')\n",
    "                        per_change_train.append(per_change[subject_id == i])\n",
    "                        \n",
    "        jj = int(np.where(subject_id==j)[0])\n",
    "        X0 = np.array(x_row)\n",
    "        X = X0.reshape((n_cases,int(len(X0)/(n_cases))))\n",
    "        X0_t = X[jj,:]\n",
    "        # Remove the test case\n",
    "        X = np.delete(X,jj,0)\n",
    "        per_change_train = np.delete(per_change_train,jj,0)\n",
    "        # Normalize testing and training cases together\n",
    "        #   Set with_mean=False to preserve data sparsity\n",
    "        #   And with_std=False \n",
    "        #   However, need a significant number of samples to do this\n",
    "        scaler = StandardScaler()\n",
    "        X_all = np.vstack((X,X0_t))\n",
    "        X_all_t = scaler.fit_transform(X_all)\n",
    "        X_t = X_all_t[X.shape[0]:,:]\n",
    "        X = X_all_t[:X.shape[0]]\n",
    "\n",
    "        if (sum(sum(np.isnan(X))))>0:\n",
    "            print('NaN detected in feature vector')\n",
    "\n",
    "        # Cross-validation for model selection\n",
    "        cv = KFold(X.shape[0]//2)\n",
    "        # Identify most important features\n",
    "        # Do not assume data is centered, fit_intercept=True\n",
    "        clf_in = LassoCV(fit_intercept=True,cv=cv,max_iter=10000).fit(X,np.ravel(per_change_train))\n",
    "        sfm = SelectFromModel(clf_in,max_features=100,threshold=min(abs(clf_in.coef_[abs(clf_in.coef_)>0])))\n",
    "        # Initialize pipeline\n",
    "        clf = Pipeline([('LassoSelect',sfm),('SVR',MLPRegressor(C=0,epsilon=0,kernel='rbf'))])\n",
    "        # Select the optimal SVR parameters with grid search\n",
    "        Cs = ((1e-1,1,10))\n",
    "        epsilons = ((0.01,0.1))\n",
    "        clf_nsvr = GridSearchCV(clf,{'SVR__C':Cs,'SVR__epsilon':epsilons},n_jobs=-1,cv=cv,scoring='neg_mean_squared_error',error_score='raise')\n",
    "        clf_nsvr.fit(X,np.ravel(per_change_train))\n",
    "        ut[jj] = clf_nsvr.best_estimator_.predict(X_t)\n",
    "        print('Predicted percentage change of',ut[jj],'for case',j)\n",
    "        print('True percentage change',per_change_train[jj])\n",
    "        #print(clf_nsvr.best_estimator_.get_params('SVR__epsilon'))\n",
    "        #print(clf_nsvr.best_estimator_.get_params('SVR__C'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "[fig,ax] = plt.subplots(1,2,sharex=True, sharey=True)\n",
    "ax[0].scatter(per_change,lct_change)\n",
    "z = np.polyfit(per_change,lct_change,1)\n",
    "p = np.poly1d(z)\n",
    "r2_score(per_change,p(per_change))\n",
    "ax[0].set_title('Medication response')\n",
    "ax[0].set_xlabel(\"UPDRS-III pre/post DBS percent improvement\")\n",
    "ax[0].set_ylabel(\"UPDRS-III percent improvement\")\n",
    "ax[1].scatter(per_change,ut)\n",
    "z = np.polyfit(per_change,ut,1)\n",
    "p = np.poly1d(z)\n",
    "ax[1].plot(per_change,p(per_change),\"r--\")\n",
    "ax[1].set_title('Lasso prediction')\n",
    "ax[1].set_xlabel(\"UPDRS-III pre/post DBS percent improvement\")\n",
    "ax[1].set_ylabel(\"Predicted UPDRS-III percent improvement\")\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(per_change,p(per_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.polyfit(per_change,lct_change,1)\n",
    "p = np.poly1d(z)\n",
    "r2_score(per_change,p(per_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = clf_nsvr.best_estimator_.steps[0][1].get_support()\n",
    "for k in range(feats.__len__()-1):\n",
    "    if feats[k] == True:\n",
    "        print(keys[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "plt.plot(feats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nsvr.best_estimator_.steps[1][1].support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(clf_nsvr.best_estimator_.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = np.linspace(1,n_cases-1,n_cases-1)\n",
    "fig,ax = plt.subplots(1,1)\n",
    "sv_ind = clf_nsvr.best_estimator_.steps[1][1].support_\n",
    "# Plot remaining data\n",
    "plt.scatter(cases, per_change_train, label=\"data\", zorder=2, c=\"c\", edgecolors=(0, 0, 0))\n",
    "# Plot support vectors\n",
    "plt.scatter(\n",
    "    cases[sv_ind],\n",
    "    per_change[sv_ind],\n",
    "    s=50,\n",
    "    c=\"m\",\n",
    "    label=\"SVR support vectors\",\n",
    "    zorder=2,\n",
    "    edgecolors=(0, 0, 0))\n",
    "\n",
    "\n",
    "plt.plot(cases,np.array(clf_nsvr.best_estimator_.predict(X))),\n",
    "plt.style.use('dark_background')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SVR = clf_nsvr.best_estimator_.steps[1][1].support_vectors_\n",
    "fig,ax = plt.subplots(1,1)\n",
    "im_svr = plt.imshow(X_SVR)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('Selected feature index')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Support vectors weights');\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "plt.colorbar(im_svr,cax=cax,orientation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Lasso = clf_nsvr.best_estimator_.steps[0][1]._transform(X_t)\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plt.stem(X_Lasso.ravel())\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('Selected feature index')\n",
    "plt.ylabel('Feature weight index')\n",
    "plt.title('Lasso feature weights');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdradenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14732b5bb7ad6abfe54a083b8d194ae3941adfb1b18321b588b21cb8f420fced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
